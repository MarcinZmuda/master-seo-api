"""
===============================================================================
ðŸ” MOE BATCH VALIDATOR v1.2 - Mixture of Experts Post-Batch Validation
===============================================================================
Kompleksowa walidacja batcha po wygenerowaniu przez GPT.

EKSPERCI (MoE):
1. STRUCTURE EXPERT - rÃ³Å¼na liczba akapitÃ³w, anty-monotonnoÅ›Ä‡
2. SEO EXPERT - BASIC/EXTENDED keywords, encje, n-gramy
3. LANGUAGE EXPERT - gramatyka polska (LanguageTool), styl
4. AI DETECTION EXPERT - burstiness, TTR, rozkÅ‚ad zdaÅ„
5. UNIFIED BRIDGE EXPERT - mostek do unified_validator (optional)
6. ðŸ†• CORPUS INSIGHTS - metryki NKJP (informacyjne, nie blokuje!)

ðŸ†• v1.2 ZMIANY:
- Dodano integracjÄ™ z polish_corpus_metrics_v41 (NKJP insights)
- Corpus insights NIE blokujÄ… walidacji - tylko informacyjne
- Dodano pole corpus_insights do ValidationResult
- Dodano naturalness_hints do response

TRYBY:
- SOFT: tylko warnings, batch zapisuje siÄ™
- STRICT: critical errors blokujÄ… batch
- AUTO_FIX: prÃ³buje naprawiÄ‡ automatycznie

UÅ¼ycie:
    from moe_batch_validator import validate_batch_moe
    result = validate_batch_moe(batch_text, project_data, batch_number)
===============================================================================
"""

import re
import statistics
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field, asdict
from collections import Counter
from enum import Enum

# ================================================================
# IMPORTY ZEWNÄ˜TRZNE
# ================================================================
try:
    from grammar_middleware import validate_batch_grammar
    LANGUAGETOOL_AVAILABLE = True
except ImportError:
    LANGUAGETOOL_AVAILABLE = False
    print("[MOE_VALIDATOR] âš ï¸ LanguageTool not available")

try:
    from ai_detection_metrics import (
        calculate_burstiness, 
        calculate_burstiness_dynamic,
        calculate_vocabulary_richness,
        analyze_sentence_distribution,
        check_word_repetition_detailed,
        AIDetectionConfig
    )
    AI_METRICS_AVAILABLE = True
except ImportError:
    AI_METRICS_AVAILABLE = False
    print("[MOE_VALIDATOR] âš ï¸ AI Detection Metrics not available")

try:
    from keyword_synonyms import get_synonyms
    SYNONYMS_AVAILABLE = True
except ImportError:
    SYNONYMS_AVAILABLE = False
    def get_synonyms(kw): return []

try:
    from keyword_counter import count_keywords_for_state
    KEYWORD_COUNTER_AVAILABLE = True
except ImportError:
    KEYWORD_COUNTER_AVAILABLE = False
    print("[MOE_VALIDATOR] âš ï¸ Keyword Counter not available")

# UNIFIED VALIDATOR BRIDGE (optional)
try:
    from unified_validator import (
        validate_content,
        quick_validate,
        calculate_entity_density,
        validate_semantic_enhancement,
        check_template_patterns,
        ValidationConfig as UnifiedValidationConfig
    )
    UNIFIED_VALIDATOR_AVAILABLE = True
    print("[MOE_VALIDATOR] âœ… Unified Validator bridge enabled")
except (ImportError, NameError, Exception) as e:
    UNIFIED_VALIDATOR_AVAILABLE = False
    print(f"[MOE_VALIDATOR] âš ï¸ Unified Validator not available: {e}")

# DYNAMIC CV THRESHOLDS
try:
    from humanness_weights_v41 import (
        get_dynamic_cv_thresholds,
        evaluate_cv_dynamic
    )
    DYNAMIC_CV_AVAILABLE = True
except ImportError:
    DYNAMIC_CV_AVAILABLE = False
    print("[MOE_VALIDATOR] âš ï¸ Dynamic CV thresholds not available")

# ðŸ†• v1.2: POLISH CORPUS INSIGHTS (optional, NEVER blocks!)
try:
    from polish_corpus_metrics_v41 import (
        get_corpus_insights_for_moe,
        get_naturalness_hints,
        analyze_corpus_metrics,
        ENABLE_CORPUS_INSIGHTS
    )
    CORPUS_INSIGHTS_AVAILABLE = True
    print("[MOE_VALIDATOR] âœ… Polish Corpus Insights enabled")
except ImportError:
    CORPUS_INSIGHTS_AVAILABLE = False
    ENABLE_CORPUS_INSIGHTS = False
    print("[MOE_VALIDATOR] â„¹ï¸ Polish Corpus Insights not available (optional)")
    
    # Fallback functions - zwracajÄ… puste wyniki, NIGDY nie blokujÄ…
    def get_corpus_insights_for_moe(text: str, **kwargs) -> dict:
        return {
            "enabled": False, 
            "affects_validation": False,
            "is_blocking": False,
            "blocks_action": False
        }
    
    def get_naturalness_hints(text: str) -> list:
        return []
    
    def analyze_corpus_metrics(text: str, **kwargs):
        return None


# ================================================================
# KONFIGURACJA
# ================================================================
class ValidationMode(Enum):
    SOFT = "soft"       # Tylko warnings
    STRICT = "strict"   # Critical errors blokujÄ…
    AUTO_FIX = "auto_fix"  # PrÃ³buje naprawiÄ‡


@dataclass
class ValidationConfig:
    """Konfiguracja progÃ³w walidacji."""
    
    # STRUKTURA - rÃ³Å¼norodnoÅ›Ä‡ akapitÃ³w
    min_paragraph_count: int = 3
    max_paragraph_count: int = 8
    paragraph_variance_min: float = 0.3  # Min rÃ³Å¼norodnoÅ›Ä‡ miÄ™dzy sekcjami
    
    # SEO - keywords
    basic_coverage_min: float = 0.7      # 70% BASIC musi byÄ‡ uÅ¼yte
    entity_coverage_min: float = 0.5     # 50% encji
    
    # JÄ˜ZYK - gramatyka
    max_grammar_errors: int = 3          # Max bÅ‚Ä™dÃ³w gramatycznych
    max_critical_grammar: int = 1        # Max bÅ‚Ä™dÃ³w krytycznych
    
    # AI DETECTION
    burstiness_min: float = 2.2          # CV * 5 >= 2.2 (CV >= 0.44)
    burstiness_max: float = 4.5
    ttr_min: float = 0.42
    ttr_max: float = 0.65
    short_sentence_pct_min: int = 15     # % krÃ³tkich zdaÅ„
    short_sentence_pct_max: int = 30
    
    # POWTÃ“RZENIA
    max_word_repetition: int = 6         # Max powtÃ³rzeÅ„ jednego sÅ‚owa
    
    # ðŸ†• v1.2: CORPUS INSIGHTS
    include_corpus_insights: bool = True  # Czy dodawaÄ‡ corpus insights


@dataclass
class ValidationIssue:
    """Pojedynczy problem znaleziony przez walidator."""
    expert: str           # structure, seo, language, ai_detection
    severity: str         # critical, warning, info
    code: str            # np. PARAGRAPH_MONOTONY, MISSING_BASIC
    message: str
    fix_instruction: str = ""
    auto_fixable: bool = False
    context: Dict = field(default_factory=dict)


@dataclass
class ValidationResult:
    """Wynik walidacji MoE."""
    passed: bool
    status: str          # APPROVED, WARNING, REJECTED, AUTO_FIXED
    issues: List[ValidationIssue]
    experts_summary: Dict[str, Dict]
    fix_instructions: List[str]
    auto_fixes_applied: List[str] = field(default_factory=list)
    corrected_text: Optional[str] = None
    # ðŸ†• v1.2: Corpus insights (NIGDY nie wpÅ‚ywa na passed/status!)
    corpus_insights: Optional[Dict] = None
    naturalness_hints: List[Dict] = field(default_factory=list)
    
    def to_dict(self) -> Dict:
        result = {
            "passed": self.passed,
            "status": self.status,
            "issues": [asdict(i) for i in self.issues],
            "experts_summary": self.experts_summary,
            "fix_instructions": self.fix_instructions,
            "auto_fixes_applied": self.auto_fixes_applied,
            "has_corrected_text": self.corrected_text is not None
        }
        
        # ðŸ†• v1.2: Dodaj corpus insights (jeÅ›li dostÄ™pne)
        if self.corpus_insights:
            result["corpus_insights"] = self.corpus_insights
        if self.naturalness_hints:
            result["naturalness_hints"] = self.naturalness_hints
            
        return result


# ================================================================
# 1ï¸âƒ£ STRUCTURE EXPERT - RÃ³Å¼norodnoÅ›Ä‡ struktury
# ================================================================
class StructureExpert:
    """
    Sprawdza strukturÄ™ tekstu:
    - RÃ³Å¼na liczba akapitÃ³w miÄ™dzy sekcjami H2
    - RÃ³Å¼na dÅ‚ugoÅ›Ä‡ akapitÃ³w
    - Anty-monotonnoÅ›Ä‡
    """
    
    def __init__(self, config: ValidationConfig):
        self.config = config
    
    def validate(
        self, 
        batch_text: str, 
        previous_batches: List[Dict],
        current_h2: str = ""
    ) -> Tuple[List[ValidationIssue], Dict]:
        """Walidacja struktury batcha."""
        issues = []
        
        # Policz akapity w bieÅ¼Ä…cym batchu
        paragraphs = self._split_paragraphs(batch_text)
        current_para_count = len(paragraphs)
        
        # Policz akapity w poprzednich batchach
        previous_para_counts = []
        for batch in previous_batches:
            text = batch.get("text", "")
            prev_paras = self._split_paragraphs(text)
            previous_para_counts.append(len(prev_paras))
        
        # SprawdÅº czy liczba akapitÃ³w jest inna niÅ¼ w poprzednim batchu
        if previous_para_counts:
            last_para_count = previous_para_counts[-1]
            
            # CRITICAL: Identyczna liczba akapitÃ³w jak poprzedni batch
            if current_para_count == last_para_count and current_para_count > 2:
                issues.append(ValidationIssue(
                    expert="structure",
                    severity="warning",
                    code="PARAGRAPH_MONOTONY",
                    message=f"Ta sekcja ma {current_para_count} akapitÃ³w - IDENTYCZNIE jak poprzednia! "
                            f"ZmieÅ„ strukturÄ™ dla naturalnoÅ›ci.",
                    fix_instruction=f"ZmieÅ„ liczbÄ™ akapitÃ³w z {current_para_count} na {current_para_count + 1} lub {max(2, current_para_count - 1)}. "
                                   f"MoÅ¼esz: poÅ‚Ä…czyÄ‡ 2 krÃ³tkie akapity w 1 dÅ‚uÅ¼szy LUB podzieliÄ‡ 1 dÅ‚ugi na 2 krÃ³tsze.",
                    context={
                        "current_count": current_para_count,
                        "previous_count": last_para_count
                    }
                ))
            
            # SprawdÅº ostatnie 3 batche - czy nie sÄ… monotonne
            if len(previous_para_counts) >= 2:
                last_three = previous_para_counts[-2:] + [current_para_count]
                if len(set(last_three)) == 1:  # Wszystkie identyczne
                    issues.append(ValidationIssue(
                        expert="structure",
                        severity="critical",
                        code="STRUCTURE_PATTERN_DETECTED",
                        message=f"Ostatnie 3 sekcje majÄ… identycznÄ… strukturÄ™ ({last_three[0]} akapitÃ³w). "
                                f"AI pattern detected!",
                        fix_instruction="MUSISZ zmieniÄ‡ liczbÄ™ akapitÃ³w w tej sekcji. "
                                       f"UÅ¼yj {last_three[0] + 2} lub {max(2, last_three[0] - 1)} akapitÃ³w.",
                        context={"pattern": last_three}
                    ))
        
        # SprawdÅº dÅ‚ugoÅ›ci akapitÃ³w (rÃ³Å¼norodnoÅ›Ä‡)
        para_lengths = [len(p.split()) for p in paragraphs]
        if para_lengths and len(para_lengths) > 1:
            mean_len = statistics.mean(para_lengths)
            std_len = statistics.stdev(para_lengths) if len(para_lengths) > 1 else 0
            cv = std_len / mean_len if mean_len > 0 else 0
            
            if cv < self.config.paragraph_variance_min:
                issues.append(ValidationIssue(
                    expert="structure",
                    severity="warning",
                    code="PARAGRAPH_LENGTH_UNIFORM",
                    message=f"Akapity sÄ… zbyt podobnej dÅ‚ugoÅ›ci (CV={cv:.2f}). "
                            f"DÅ‚ugoÅ›ci: {para_lengths}",
                    fix_instruction="ZrÃ³Å¼nicuj dÅ‚ugoÅ›Ä‡ akapitÃ³w. NiektÃ³re powinny byÄ‡ krÃ³tkie (2-3 zdania), "
                                   "inne dÅ‚uÅ¼sze (5-6 zdaÅ„).",
                    context={"lengths": para_lengths, "cv": cv}
                ))
        
        # SprawdÅº minimalnÄ… i maksymalnÄ… liczbÄ™ akapitÃ³w
        if current_para_count < self.config.min_paragraph_count:
            issues.append(ValidationIssue(
                expert="structure",
                severity="warning",
                code="TOO_FEW_PARAGRAPHS",
                message=f"Za maÅ‚o akapitÃ³w: {current_para_count} (min: {self.config.min_paragraph_count})",
                fix_instruction=f"Podziel tekst na wiÄ™cej akapitÃ³w (min {self.config.min_paragraph_count})."
            ))
        
        if current_para_count > self.config.max_paragraph_count:
            issues.append(ValidationIssue(
                expert="structure",
                severity="info",
                code="MANY_PARAGRAPHS",
                message=f"DuÅ¼o akapitÃ³w: {current_para_count} (sugerowane max: {self.config.max_paragraph_count})",
                fix_instruction="RozwaÅ¼ poÅ‚Ä…czenie niektÃ³rych krÃ³tkich akapitÃ³w."
            ))
        
        summary = {
            "paragraph_count": current_para_count,
            "paragraph_lengths": para_lengths,
            "previous_counts": previous_para_counts,
            "issues_count": len(issues)
        }
        
        return issues, summary
    
    def _split_paragraphs(self, text: str) -> List[str]:
        """Dzieli tekst na akapity."""
        # UsuÅ„ HTML
        clean = re.sub(r'<[^>]+>', '\n', text)
        # Podziel na podwÃ³jne newline
        paragraphs = re.split(r'\n\s*\n', clean)
        # Filtruj puste
        return [p.strip() for p in paragraphs if p.strip() and len(p.strip()) > 20]


# ================================================================
# 2ï¸âƒ£ SEO EXPERT - Keywords i encje
# ================================================================
class SEOExpert:
    """
    Sprawdza SEO:
    - BASIC keywords coverage
    - EXTENDED keywords (info)
    - Encje z S1
    - N-gramy
    """
    
    def __init__(self, config: ValidationConfig):
        self.config = config
    
    def validate(
        self,
        batch_text: str,
        keywords_state: Dict,
        batch_counts: Dict,
        s1_entities: List = None,
        assigned_keywords: List[str] = None,
        batch_number: int = 1
    ) -> Tuple[List[ValidationIssue], Dict]:
        """Walidacja SEO batcha."""
        issues = []
        
        # === BASIC KEYWORDS ===
        basic_missing = []
        basic_used = []
        basic_exceeded = []
        
        for rid, meta in keywords_state.items():
            if meta.get("type", "BASIC").upper() not in ["BASIC", "MAIN"]:
                continue
            
            keyword = meta.get("keyword", "")
            target_min = meta.get("target_min", 1)
            target_max = meta.get("target_max", 999)
            actual = meta.get("actual_uses", 0)
            batch_use = batch_counts.get(rid, 0)
            
            # Frazy PRZYPISANE do tego batcha ktÃ³re nie zostaÅ‚y uÅ¼yte
            if assigned_keywords and keyword.lower() in [k.lower() for k in assigned_keywords]:
                if batch_use == 0:
                    synonyms = get_synonyms(keyword) if SYNONYMS_AVAILABLE else []
                    issues.append(ValidationIssue(
                        expert="seo",
                        severity="warning",
                        code="ASSIGNED_KEYWORD_MISSING",
                        message=f"Fraza '{keyword}' byÅ‚a PRZYPISANA do tej sekcji, ale nie zostaÅ‚a uÅ¼yta!",
                        fix_instruction=f"Dodaj frazÄ™ '{keyword}' do tekstu (min 1x). "
                                       f"Synonimy: {', '.join(synonyms[:2]) if synonyms else 'brak'}",
                        context={"keyword": keyword, "assigned": True, "synonyms": synonyms}
                    ))
                    basic_missing.append(keyword)
            
            # Frazy ktÃ³re sÄ… UNDER i powinny byÄ‡ uÅ¼yte
            if actual < target_min and batch_use == 0:
                remaining_batches = 7 - batch_number  # ZakÅ‚adamy 7 batchÃ³w
                if remaining_batches <= 2 and actual == 0:
                    issues.append(ValidationIssue(
                        expert="seo",
                        severity="critical" if meta.get("type") == "MAIN" else "warning",
                        code="BASIC_STILL_ZERO",
                        message=f"BASIC '{keyword}' ma 0 uÅ¼yÄ‡! ZostaÅ‚y {remaining_batches} batche.",
                        fix_instruction=f"MUSISZ uÅ¼yÄ‡ '{keyword}' w tym lub nastÄ™pnym batchu (cel: {target_min}-{target_max}x)."
                    ))
                    basic_missing.append(keyword)
            
            if batch_use > 0:
                basic_used.append({"keyword": keyword, "count": batch_use})
        
        # === ENCJE ===
        coverage = 0
        entities_missing = []
        if s1_entities:
            text_lower = batch_text.lower()
            entities_in_batch = []
            
            for entity in s1_entities[:15]:  # Top 15 encji
                name = entity.get("name", "") if isinstance(entity, dict) else str(entity)
                if name.lower() in text_lower:
                    entities_in_batch.append(name)
                else:
                    entities_missing.append(name)
            
            coverage = len(entities_in_batch) / len(s1_entities[:15]) if s1_entities else 0
            
            if coverage < 0.2 and batch_number <= 3:  # Pierwsze 3 batche powinny mieÄ‡ wiÄ™cej encji
                issues.append(ValidationIssue(
                    expert="seo",
                    severity="warning",
                    code="LOW_ENTITY_COVERAGE",
                    message=f"Niskie pokrycie encji: {coverage:.0%}. UÅ¼yte: {len(entities_in_batch)}/{len(s1_entities[:15])}",
                    fix_instruction=f"Dodaj wzmianki o: {', '.join(entities_missing[:3])}",
                    context={"entities_missing": entities_missing[:5]}
                ))
        
        summary = {
            "basic_used": basic_used,
            "basic_missing": basic_missing,
            "entity_coverage": coverage if s1_entities else None,
            "issues_count": len(issues)
        }
        
        return issues, summary


# ================================================================
# 3ï¸âƒ£ LANGUAGE EXPERT - Gramatyka polska
# ================================================================
class LanguageExpert:
    """
    Sprawdza jÄ™zyk polski:
    - LanguageTool (bÅ‚Ä™dy gramatyczne)
    - ZgodnoÅ›Ä‡ przypadkÃ³w
    - Interpunkcja
    """
    
    def __init__(self, config: ValidationConfig):
        self.config = config
    
    def validate(self, batch_text: str) -> Tuple[List[ValidationIssue], Dict]:
        """Walidacja jÄ™zyka polskiego."""
        issues = []
        grammar_errors = []
        
        if LANGUAGETOOL_AVAILABLE:
            try:
                lt_result = validate_batch_grammar(batch_text)
                grammar_errors = lt_result.errors if hasattr(lt_result, 'errors') else []
                critical_errors = [e for e in grammar_errors if e.get("rule", {}).get("category", {}).get("id") in ["GRAMMAR", "TYPOS"]] if grammar_errors else []
                
                # Critical grammar errors
                for err in critical_errors[:self.config.max_critical_grammar + 1]:
                    issues.append(ValidationIssue(
                        expert="language",
                        severity="critical",
                        code="GRAMMAR_CRITICAL",
                        message=f"BÅ‚Ä…d gramatyczny: {err.get('message', 'nieznany')}",
                        fix_instruction=f"Popraw: '{err.get('context', '')}' â†’ {err.get('suggestions', ['?'])[0] if err.get('suggestions') else '?'}",
                        auto_fixable=bool(err.get("suggestions")),
                        context=err
                    ))
                
                # Warning grammar errors
                for err in grammar_errors[len(critical_errors):self.config.max_grammar_errors + 1]:
                    issues.append(ValidationIssue(
                        expert="language",
                        severity="warning",
                        code="GRAMMAR_WARNING",
                        message=f"Sugestia: {err.get('message', 'nieznany')}",
                        fix_instruction=f"RozwaÅ¼ zmianÄ™: '{err.get('context', '')}'",
                        context=err
                    ))
                    
            except Exception as e:
                print(f"[MOE_VALIDATOR] LanguageTool error: {e}")
        
        # Dodatkowe sprawdzenia polskiego
        polish_issues = self._check_polish_rules(batch_text)
        issues.extend(polish_issues)
        
        summary = {
            "grammar_errors": len(grammar_errors),
            "critical_errors": len([i for i in issues if i.severity == "critical"]),
            "languagetool_available": LANGUAGETOOL_AVAILABLE
        }
        
        return issues, summary
    
    def _check_polish_rules(self, text: str) -> List[ValidationIssue]:
        """Dodatkowe reguÅ‚y polskie."""
        issues = []
        
        # SprawdÅº czÄ™ste bÅ‚Ä™dy
        common_errors = [
            (r'\bw miÄ™dzy\b', 'w miÄ™dzy â†’ wÅ›rÃ³d/miÄ™dzy', 'BÅ‚Ä™dna konstrukcja "w miÄ™dzy"'),
            (r'\bw skutek\b', 'w skutek â†’ wskutek', 'Pisownia Å‚Ä…czna "wskutek"'),
            (r'\bz pod\b', 'z pod â†’ spod', 'Pisownia Å‚Ä…czna "spod"'),
            (r'\bz\s+nad\b', 'z nad â†’ znad', 'Pisownia Å‚Ä…czna "znad"'),
            (r'\bpo mimo\b', 'po mimo â†’ pomimo', 'Pisownia Å‚Ä…czna "pomimo"'),
        ]
        
        text_lower = text.lower()
        for pattern, fix, msg in common_errors:
            if re.search(pattern, text_lower):
                issues.append(ValidationIssue(
                    expert="language",
                    severity="warning",
                    code="POLISH_SPELLING",
                    message=msg,
                    fix_instruction=fix,
                    auto_fixable=True
                ))
        
        return issues


# ================================================================
# 4ï¸âƒ£ AI DETECTION EXPERT - Wykrywanie AI patterns
# ================================================================
class AIDetectionExpert:
    """
    Sprawdza metryki anty-AI:
    - Burstiness (zmiennoÅ›Ä‡ zdaÅ„)
    - TTR (bogactwo sÅ‚ownictwa)
    - RozkÅ‚ad dÅ‚ugoÅ›ci zdaÅ„
    - PowtÃ³rzenia sÅ‚Ã³w
    """
    
    def __init__(self, config: ValidationConfig):
        self.config = config
    
    def validate(self, batch_text: str) -> Tuple[List[ValidationIssue], Dict]:
        """Walidacja anty-AI."""
        issues = []
        metrics = {}
        
        if not AI_METRICS_AVAILABLE:
            return issues, {"available": False}
        
        # === BURSTINESS ===
        try:
            burstiness_result = calculate_burstiness(batch_text)
            burstiness = burstiness_result.get("value", 0)
            cv = burstiness_result.get("cv", 0)
            metrics["burstiness"] = burstiness
            metrics["cv"] = cv
            
            if burstiness < self.config.burstiness_min:
                issues.append(ValidationIssue(
                    expert="ai_detection",
                    severity="critical" if burstiness < 1.5 else "warning",
                    code="LOW_BURSTINESS",
                    message=f"Niski burstiness: {burstiness} (CV={cv:.2f}). AI pattern!",
                    fix_instruction="Dodaj wiÄ™cej KRÃ“TKICH zdaÅ„ (2-8 sÅ‚Ã³w). "
                                   "Np. 'To waÅ¼ne.', 'Warto wiedzieÄ‡.', 'Co to oznacza?'",
                    context=burstiness_result
                ))
        except Exception as e:
            print(f"[MOE_VALIDATOR] Burstiness error: {e}")
        
        # === ROZKÅAD ZDAÅƒ ===
        try:
            dist_result = analyze_sentence_distribution(batch_text)
            distribution = dist_result.get("distribution", [0, 0, 0])
            metrics["sentence_distribution"] = distribution
            
            short_pct = distribution[0] if distribution else 0
            
            if short_pct < self.config.short_sentence_pct_min:
                issues.append(ValidationIssue(
                    expert="ai_detection",
                    severity="warning",
                    code="TOO_FEW_SHORT_SENTENCES",
                    message=f"Za maÅ‚o krÃ³tkich zdaÅ„: {short_pct}% (cel: {self.config.short_sentence_pct_min}-{self.config.short_sentence_pct_max}%)",
                    fix_instruction="Dodaj zdania 2-10 sÅ‚Ã³w. PrzykÅ‚ady: 'To kluczowe.', 'Warto pamiÄ™taÄ‡.', 'Jak to dziaÅ‚a?'",
                    context=dist_result
                ))
            
            # Wykryj AI concentration (60%+ w przedziale 15-22)
            ai_concentration = dist_result.get("ai_concentration", 0)
            if ai_concentration > 60:
                issues.append(ValidationIssue(
                    expert="ai_detection",
                    severity="critical",
                    code="AI_SENTENCE_PATTERN",
                    message=f"AI pattern: {ai_concentration:.0f}% zdaÅ„ ma 15-22 sÅ‚Ã³w (monotonna dÅ‚ugoÅ›Ä‡)",
                    fix_instruction="ZrÃ³Å¼nicuj dÅ‚ugoÅ›Ä‡ zdaÅ„! Dodaj krÃ³tkie (5-8 sÅ‚Ã³w) i dÅ‚ugie (25-30 sÅ‚Ã³w).",
                    context={"ai_concentration": ai_concentration}
                ))
        except Exception as e:
            print(f"[MOE_VALIDATOR] Sentence distribution error: {e}")
        
        # === POWTÃ“RZENIA SÅÃ“W ===
        try:
            repetition_result = check_word_repetition_detailed(batch_text)
            repeated_words = repetition_result.get("repeated_words", [])
            metrics["repeated_words"] = repeated_words[:5]
            
            for word_info in repeated_words[:3]:
                word = word_info.get("word", "")
                count = word_info.get("count", 0)
                if count > self.config.max_word_repetition:
                    synonyms = word_info.get("synonyms", [])
                    issues.append(ValidationIssue(
                        expert="ai_detection",
                        severity="warning",
                        code="WORD_REPETITION",
                        message=f"SÅ‚owo '{word}' powtÃ³rzone {count}x",
                        fix_instruction=f"ZamieÅ„ niektÃ³re '{word}' na: {', '.join(synonyms[:3]) if synonyms else 'synonimy'}",
                        auto_fixable=bool(synonyms),
                        context=word_info
                    ))
        except Exception as e:
            print(f"[MOE_VALIDATOR] Repetition check error: {e}")
        
        summary = {
            "metrics": metrics,
            "issues_count": len(issues)
        }
        
        return issues, summary


# ================================================================
# 5ï¸âƒ£ UNIFIED BRIDGE EXPERT (optional)
# ================================================================
class UnifiedBridgeExpert:
    """
    Ekspert mostkowy do unified_validator.
    
    Nie duplikuje logiki - WYWOÅUJE funkcje z unified_validator
    i tÅ‚umaczy wyniki na format MoE.
    """
    
    def __init__(self, config: ValidationConfig):
        self.config = config
        self.enabled = UNIFIED_VALIDATOR_AVAILABLE
    
    def validate(
        self, 
        batch_text: str,
        keywords_state: Dict,
        s1_data: Dict = None,
        main_keyword: str = ""
    ) -> Tuple[List[ValidationIssue], Dict]:
        """Waliduje batch uÅ¼ywajÄ…c unified_validator."""
        issues = []
        metrics = {
            "enabled": self.enabled,
            "checks_performed": []
        }
        
        if not self.enabled:
            return issues, {"enabled": False, "reason": "unified_validator not available"}
        
        try:
            # 1. Quick validate
            quick_result = quick_validate(batch_text, keywords_state)
            metrics["quick_score"] = quick_result.get("score", 0)
            metrics["checks_performed"].append("quick_validate")
            
            # Konwertuj issues z quick_validate
            for issue in quick_result.get("issues", []):
                if isinstance(issue, dict):
                    severity = issue.get("severity", "WARNING")
                else:
                    severity = getattr(issue, "severity", "WARNING")
                    if hasattr(severity, "value"):
                        severity = severity.value
                
                issues.append(ValidationIssue(
                    expert="unified_bridge",
                    severity=severity.lower() if severity != "CRITICAL" else "critical",
                    code=issue.get("code", "UNIFIED_ISSUE") if isinstance(issue, dict) else getattr(issue, "code", "UNIFIED_ISSUE"),
                    message=issue.get("message", str(issue)) if isinstance(issue, dict) else getattr(issue, "message", str(issue)),
                    fix_instruction="",
                    context={"source": "unified_validator.quick_validate"}
                ))
            
            # 2. Entity density
            if s1_data:
                entities = s1_data.get("entity_seo", {}).get("entities", [])
                density_result = calculate_entity_density(batch_text, entities)
                metrics["entity_density"] = density_result.get("density", 0)
                metrics["checks_performed"].append("entity_density")
                
                if density_result.get("status") == "CRITICAL":
                    issues.append(ValidationIssue(
                        expert="unified_bridge",
                        severity="warning",
                        code="ENTITY_DENSITY_LOW",
                        message=f"Niska gÄ™stoÅ›Ä‡ encji: {density_result.get('density', 0):.2f}",
                        fix_instruction="Dodaj wiÄ™cej encji z S1 Analysis",
                        context=density_result
                    ))
            
            # 3. Template patterns
            template_issues = check_template_patterns(batch_text)
            metrics["template_patterns_found"] = len(template_issues)
            metrics["checks_performed"].append("template_patterns")
            
            for t_issue in template_issues[:2]:
                issues.append(ValidationIssue(
                    expert="unified_bridge",
                    severity="warning",
                    code="TEMPLATE_PATTERN",
                    message=t_issue.message if hasattr(t_issue, "message") else str(t_issue),
                    fix_instruction="Przepisz fragment unikajÄ…c powtarzalnych struktur",
                    context={"source": "unified_validator.check_template_patterns"}
                ))
            
            # 4. Semantic enhancement
            if s1_data:
                semantic_result = validate_semantic_enhancement(batch_text, s1_data)
                metrics["semantic_score"] = semantic_result.get("score", 0)
                metrics["checks_performed"].append("semantic_enhancement")
                
                if semantic_result.get("score", 100) < 50:
                    issues.append(ValidationIssue(
                        expert="unified_bridge",
                        severity="info",
                        code="SEMANTIC_LOW",
                        message=f"Niski semantic score: {semantic_result.get('score', 0)}",
                        fix_instruction="Wzmocnij powiÄ…zania semantyczne z encjami S1",
                        context=semantic_result
                    ))
            
        except Exception as e:
            print(f"[MOE_VALIDATOR] UnifiedBridgeExpert error: {e}")
            metrics["error"] = str(e)
        
        summary = {
            "enabled": True,
            "metrics": metrics,
            "issues_count": len(issues)
        }
        
        return issues, summary


# ================================================================
# ðŸŽ¯ GÅÃ“WNA FUNKCJA WALIDACJI MOE
# ================================================================
def validate_batch_moe(
    batch_text: str,
    project_data: Dict,
    batch_number: int = 1,
    mode: ValidationMode = ValidationMode.SOFT,
    config: Optional[ValidationConfig] = None,
    include_corpus_insights: bool = True  # ðŸ†• v1.2
) -> ValidationResult:
    """
    GÅ‚Ã³wna funkcja walidacji MoE.
    
    Args:
        batch_text: Tekst batcha do walidacji
        project_data: Dane projektu (keywords_state, batches, s1_data, etc.)
        batch_number: Numer batcha (1-7)
        mode: Tryb walidacji (SOFT, STRICT, AUTO_FIX)
        config: Opcjonalna konfiguracja (domyÅ›lna jeÅ›li None)
        include_corpus_insights: Czy dodaÄ‡ corpus insights (default: True)
    
    Returns:
        ValidationResult z wynikami wszystkich ekspertÃ³w
    """
    if config is None:
        config = ValidationConfig()
    
    all_issues = []
    experts_summary = {}
    fix_instructions = []
    
    # Pobierz dane z projektu
    keywords_state = project_data.get("keywords_state", {})
    previous_batches = project_data.get("batches", [])
    s1_data = project_data.get("s1_data", {})
    s1_entities = s1_data.get("entity_seo", {}).get("entities", [])
    semantic_plan = project_data.get("semantic_keyword_plan", {})
    
    # Pobierz assigned keywords dla tego batcha
    assigned_keywords = []
    for bp in semantic_plan.get("batch_plans", []):
        if bp.get("batch_number") == batch_number:
            assigned_keywords = bp.get("assigned_keywords", [])
            break
    
    # Policz keywords w batchu
    batch_counts = {}
    if KEYWORD_COUNTER_AVAILABLE:
        try:
            batch_counts = count_keywords_for_state(batch_text, keywords_state, use_exclusive_for_nested=False)
        except Exception as e:
            print(f"[MOE_VALIDATOR] Keyword counting error: {e}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1ï¸âƒ£ STRUCTURE EXPERT
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    structure_expert = StructureExpert(config)
    current_h2 = ""
    structure_issues, structure_summary = structure_expert.validate(
        batch_text, previous_batches, current_h2
    )
    all_issues.extend(structure_issues)
    experts_summary["structure"] = structure_summary
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2ï¸âƒ£ SEO EXPERT
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    seo_expert = SEOExpert(config)
    seo_issues, seo_summary = seo_expert.validate(
        batch_text, keywords_state, batch_counts, s1_entities, assigned_keywords, batch_number
    )
    all_issues.extend(seo_issues)
    experts_summary["seo"] = seo_summary
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3ï¸âƒ£ LANGUAGE EXPERT
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    language_expert = LanguageExpert(config)
    language_issues, language_summary = language_expert.validate(batch_text)
    all_issues.extend(language_issues)
    experts_summary["language"] = language_summary
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4ï¸âƒ£ AI DETECTION EXPERT
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    ai_expert = AIDetectionExpert(config)
    ai_issues, ai_summary = ai_expert.validate(batch_text)
    all_issues.extend(ai_issues)
    experts_summary["ai_detection"] = ai_summary
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 5ï¸âƒ£ UNIFIED BRIDGE EXPERT (optional)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if UNIFIED_VALIDATOR_AVAILABLE:
        try:
            unified_expert = UnifiedBridgeExpert(config)
            main_keyword = project_data.get("main_keyword", "")
            unified_issues, unified_summary = unified_expert.validate(
                batch_text=batch_text,
                keywords_state=keywords_state,
                s1_data=s1_data,
                main_keyword=main_keyword
            )
            existing_codes = {i.code for i in all_issues}
            for issue in unified_issues:
                if issue.code not in existing_codes:
                    all_issues.append(issue)
            experts_summary["unified_bridge"] = unified_summary
        except Exception as e:
            print(f"[MOE_VALIDATOR] UnifiedBridgeExpert skipped: {e}")
            experts_summary["unified_bridge"] = {"enabled": False, "error": str(e)}
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ðŸ†• v1.2: 6ï¸âƒ£ CORPUS INSIGHTS (NIGDY nie blokuje!)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    corpus_insights = None
    naturalness_hints = []
    
    if include_corpus_insights and CORPUS_INSIGHTS_AVAILABLE:
        try:
            corpus_insights = get_corpus_insights_for_moe(batch_text)
            
            # WyodrÄ™bnij hints do osobnego pola
            if corpus_insights.get("enabled"):
                naturalness_hints = corpus_insights.get("suggestions", [])
                
                # Dodaj do summary (ale NIE do issues!)
                experts_summary["corpus_insights"] = {
                    "enabled": True,
                    "naturalness_score": corpus_insights.get("naturalness_score", 100),
                    "style_detected": corpus_insights.get("style_detected", "unknown"),
                    "suggestions_count": len(naturalness_hints),
                    # WAÅ»NE: Jawne oznaczenie Å¼e NIE wpÅ‚ywa na walidacjÄ™
                    "affects_validation": False,
                }
        except Exception as e:
            print(f"[MOE_VALIDATOR] Corpus insights error (non-blocking): {e}")
            corpus_insights = {
                "enabled": False,
                "error": str(e)[:100],
                "affects_validation": False
            }
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # AGREGACJA WYNIKÃ“W
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    critical_issues = [i for i in all_issues if i.severity == "critical"]
    warning_issues = [i for i in all_issues if i.severity == "warning"]
    
    # Zbierz fix instructions
    for issue in all_issues:
        if issue.fix_instruction and issue.severity in ["critical", "warning"]:
            fix_instructions.append(f"[{issue.expert.upper()}] {issue.fix_instruction}")
    
    # Ustal status (corpus insights NIGDY nie wpÅ‚ywa na status!)
    if mode == ValidationMode.STRICT and critical_issues:
        status = "REJECTED"
        passed = False
    elif critical_issues:
        status = "WARNING"
        passed = True  # W SOFT mode przepuszczamy z warning
    elif warning_issues:
        status = "WARNING"
        passed = True
    else:
        status = "APPROVED"
        passed = True
    
    return ValidationResult(
        passed=passed,
        status=status,
        issues=all_issues,
        experts_summary=experts_summary,
        fix_instructions=fix_instructions[:10],
        auto_fixes_applied=[],
        corrected_text=None,
        corpus_insights=corpus_insights,
        naturalness_hints=naturalness_hints
    )


# ================================================================
# HELPER: Format dla GPT
# ================================================================
def format_validation_for_gpt(result: ValidationResult) -> str:
    """
    Formatuje wynik walidacji jako instrukcje dla GPT do przepisania batcha.
    """
    if result.status == "APPROVED":
        return ""
    
    lines = []
    lines.append("=" * 60)
    lines.append("âš ï¸ WALIDACJA MOE - WYMAGANE POPRAWKI")
    lines.append("=" * 60)
    
    # Pogrupuj po ekspertach
    by_expert = {}
    for issue in result.issues:
        if issue.severity in ["critical", "warning"]:
            by_expert.setdefault(issue.expert, []).append(issue)
    
    for expert, issues in by_expert.items():
        lines.append(f"\nðŸ” {expert.upper()}:")
        for issue in issues[:3]:
            severity_icon = "âŒ" if issue.severity == "critical" else "âš ï¸"
            lines.append(f"  {severity_icon} {issue.message}")
            if issue.fix_instruction:
                lines.append(f"     â†’ FIX: {issue.fix_instruction}")
    
    # ðŸ†• v1.2: Dodaj naturalness hints (informacyjnie)
    if result.naturalness_hints:
        lines.append(f"\nðŸ’¡ SUGESTIE NATURALNOÅšCI (informacyjne):")
        for hint in result.naturalness_hints[:3]:
            lines.append(f"  â„¹ï¸ [{hint.get('metric', '?')}] {hint.get('suggestion', hint.get('message', ''))}")
    
    lines.append("\n" + "=" * 60)
    
    return "\n".join(lines)


# ================================================================
# ðŸ†• v1.2: HELPER - Extract naturalness suggestions
# ================================================================
def extract_naturalness_suggestions(result: ValidationResult) -> List[Dict]:
    """
    WyciÄ…ga sugestie naturalnoÅ›ci z corpus_insights.
    
    UÅ¼yteczne do dodania do response API.
    """
    if not result.corpus_insights:
        return []
    
    if not result.corpus_insights.get("enabled"):
        return []
    
    return result.corpus_insights.get("suggestions", [])


# ================================================================
# TEST
# ================================================================
if __name__ == "__main__":
    test_text = """
    UbezwÅ‚asnowolnienie to waÅ¼na instytucja prawa cywilnego. SÄ…d moÅ¼e orzec ubezwÅ‚asnowolnienie caÅ‚kowite lub czÄ™Å›ciowe.
    
    Wniosek o ubezwÅ‚asnowolnienie skÅ‚ada siÄ™ do sÄ…du okrÄ™gowego. PostÄ™powanie wymaga opinii biegÅ‚ego psychiatry.
    
    Skutki ubezwÅ‚asnowolnienia sÄ… powaÅ¼ne. Osoba ubezwÅ‚asnowolniona traci zdolnoÅ›Ä‡ do czynnoÅ›ci prawnych.
    """
    
    # Symulacja project_data
    project_data = {
        "keywords_state": {
            "k1": {"keyword": "ubezwÅ‚asnowolnienie", "type": "MAIN", "target_min": 5, "target_max": 15, "actual_uses": 2},
            "k2": {"keyword": "sÄ…d", "type": "BASIC", "target_min": 3, "target_max": 10, "actual_uses": 1},
        },
        "batches": [],
        "s1_data": {"entity_seo": {"entities": [{"name": "Kodeks cywilny"}, {"name": "sÄ…d okrÄ™gowy"}]}}
    }
    
    result = validate_batch_moe(test_text, project_data, batch_number=1)
    
    print(f"Status: {result.status}")
    print(f"Passed: {result.passed}")
    print(f"Issues: {len(result.issues)}")
    for issue in result.issues:
        print(f"  [{issue.expert}] {issue.severity}: {issue.message}")
    
    # ðŸ†• v1.2: PokaÅ¼ corpus insights
    if result.corpus_insights and result.corpus_insights.get("enabled"):
        print(f"\nðŸ“Š Corpus Insights:")
        print(f"   Naturalness: {result.corpus_insights.get('naturalness_score', 'N/A')}")
        print(f"   Style: {result.corpus_insights.get('style_detected', 'N/A')}")
        print(f"   Suggestions: {len(result.naturalness_hints)}")
        for hint in result.naturalness_hints:
            print(f"     ðŸ’¡ {hint.get('metric')}: {hint.get('suggestion', hint.get('message', ''))}")
    
    print("\n" + format_validation_for_gpt(result))
