"""
===============================================================================
üéØ DYNAMIC HUMANIZATION MODULE v40.1
===============================================================================
Zastƒôpuje s≈Çabe SHORT_INSERTS_LIBRARY dynamicznym systemem.

PROBLEMY ZE STARYM SYSTEMEM:
1. Tylko 9 fraz statycznych
2. Generyczne - nie pasujƒÖ do tematu
3. Sztuczne - "Efekt? Natychmiastowy." brzmi jak reklama

NOWE PODEJ≈öCIE:
1. Dynamiczne kr√≥tkie zdania generowane na podstawie TEMATU
2. Wzorce gramatyczne zamiast gotowych fraz
3. Tematyczne biblioteki (prawo, medycyna, tech, etc.)

ZMIANY v40.1:
- Integracja z synonym_service.py (plWordNet + Firestore cache + LLM fallback)
- CONTEXTUAL_SYNONYMS jako pierwsza warstwa, synonym_service jako fallback
- Wsparcie dla get_synonyms_batch() dla wielu s≈Ç√≥w

Autor: BRAJEN SEO Master API v40.1
===============================================================================
"""

from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
import re

# ============================================================================
# üÜï v40.1: INTEGRACJA Z SYNONYM_SERVICE
# ============================================================================

SYNONYM_SERVICE_AVAILABLE = False

try:
    from synonym_service import (
        get_synonyms as _get_synonyms_external,
        get_synonyms_batch as _get_synonyms_batch_external,
        suggest_synonym_for_repetition
    )
    SYNONYM_SERVICE_AVAILABLE = True
    print("[DYNAMIC_HUMANIZATION] ‚úÖ synonym_service loaded (plWordNet + cache)")
except ImportError as e:
    print(f"[DYNAMIC_HUMANIZATION] ‚ö†Ô∏è synonym_service not available: {e}")
    print("[DYNAMIC_HUMANIZATION] ‚ÑπÔ∏è Using local CONTEXTUAL_SYNONYMS only")
    
    # Fallback funkcje
    def _get_synonyms_external(word: str, context: str = "", use_cache: bool = True) -> Dict:
        return {"word": word, "synonyms": [], "source": "none", "count": 0}
    
    def _get_synonyms_batch_external(words: List[str], context: str = "") -> Dict[str, List[str]]:
        return {}
    
    def suggest_synonym_for_repetition(word: str, count: int, context: str = "") -> Dict:
        return {"word": word, "suggestions": [], "source": "none"}


# ============================================================================
# WZORCE KR√ìTKICH ZDA≈É (3-8 S≈Å√ìW) - UNIWERSALNE
# ============================================================================

SHORT_SENTENCE_PATTERNS = {
    # Wzorce z placeholderem {TEMAT}
    "statement": [
        "To {kluczowe}.",
        "{Podmiot} decyduje.",
        "Procedura trwa.",
        "To wymaga {czego}.",
        "Prawo to reguluje.",
        "Warto to wiedzieƒá.",
    ],
    "question": [
        "Co dalej?",
        "A jak to wyglƒÖda?",
        "Dlaczego to wa≈ºne?",
        "Kiedy to nastƒôpuje?",
        "Jak to dzia≈Ça?",
    ],
    "transition": [
        "Ale uwaga.",
        "Jest wyjƒÖtek.",
        "To nie koniec.",
        "Id≈∫my dalej.",
        "Wr√≥ƒámy do tematu.",
    ],
    "emphasis": [
        "To kluczowe.",
        "Zapamiƒôtaj to.",
        "Wa≈ºna uwaga.",
        "Kluczowy punkt.",
    ]
}


# ============================================================================
# BIBLIOTEKI TEMATYCZNE - KR√ìTKIE ZDANIA DOPASOWANE DO TEMATU
# ============================================================================

TOPIC_SHORT_SENTENCES = {
    # PRAWO / LEGAL
    "prawo": {
        "patterns": [
            "SƒÖd orzeka.",
            "Prawo to reguluje.",
            "Ustawa wymaga.",
            "Termin mija.",
            "Dowody decydujƒÖ.",
            "Procedura trwa.",
            "To wymaga dowod√≥w.",
            "Apelacja mo≈ºliwa.",
            "Koszty rosnƒÖ.",
            "Wyrok zapad≈Ç.",
        ],
        "keywords": ["sƒÖd", "ustawa", "kodeks", "prawo", "wyrok", "pozew", 
                     "ubezw≈Çasnowolnienie", "kuratela", "opiekun", "prawny"]
    },
    
    # MEDYCYNA / ZDROWIE
    "medycyna": {
        "patterns": [
            "Lekarz decyduje.",
            "Badanie wyka≈ºe.",
            "Objawy mogƒÖ siƒô r√≥≈ºniƒá.",
            "To wymaga diagnostyki.",
            "Leczenie trwa.",
            "Rokowania dobre.",
            "Konsultacja konieczna.",
            "Efekty widoczne.",
        ],
        "keywords": ["lekarz", "choroba", "leczenie", "diagnoza", "objawy",
                     "terapia", "pacjent", "zdrowie", "psychiczny", "psychiatra"]
    },
    
    # FINANSE
    "finanse": {
        "patterns": [
            "Koszty rosnƒÖ.",
            "Podatek obowiƒÖzuje.",
            "Termin p≈Çatno≈õci.",
            "Op≈Çaty sta≈Çe.",
            "Bud≈ºet ograniczony.",
            "Zwrot mo≈ºliwy.",
        ],
        "keywords": ["podatek", "op≈Çata", "koszt", "bud≈ºet", "finanse", 
                     "pieniƒÖdze", "kredyt", "rata"]
    },
    
    # TECHNOLOGIA
    "technologia": {
        "patterns": [
            "System dzia≈Ça.",
            "Aktualizacja konieczna.",
            "Dane bezpieczne.",
            "Proces automatyczny.",
            "Integracja prosta.",
        ],
        "keywords": ["system", "aplikacja", "software", "kod", "program",
                     "technologia", "digital", "online"]
    },
    
    # EDUKACJA / DZIECI
    "edukacja": {
        "patterns": [
            "Dziecko siƒô uczy.",
            "Postƒôpy widoczne.",
            "ƒÜwiczenia pomagajƒÖ.",
            "Efekty przyjdƒÖ.",
            "Cierpliwo≈õƒá kluczowa.",
        ],
        "keywords": ["dziecko", "nauka", "szko≈Ça", "rozw√≥j", "edukacja",
                     "terapia", "ƒáwiczenia", "przedszkole"]
    },
    
    # UNIWERSALNE (fallback)
    "universal": {
        "patterns": [
            "To wa≈ºne.",
            "Warto wiedzieƒá.",
            "Sprawd≈∫ to.",
            "Pamiƒôtaj.",
            "Uwaga na to.",
            "To istotne.",
            "Czas na decyzjƒô.",
        ],
        "keywords": []
    }
}


# ============================================================================
# G≈Å√ìWNA FUNKCJA - GENEROWANIE KR√ìTKICH ZDA≈É
# ============================================================================

def detect_topic_domain(main_keyword: str, h2_titles: List[str] = None) -> str:
    """
    Wykrywa domenƒô tematycznƒÖ na podstawie s≈Ç√≥w kluczowych.
    
    Returns:
        Nazwa domeny: "prawo", "medycyna", "finanse", "technologia", "edukacja", "universal"
    """
    text_to_check = main_keyword.lower()
    if h2_titles:
        text_to_check += " " + " ".join(h2_titles).lower()
    
    # Sprawd≈∫ ka≈ºdƒÖ domenƒô
    domain_scores = {}
    for domain, config in TOPIC_SHORT_SENTENCES.items():
        if domain == "universal":
            continue
        score = 0
        for keyword in config["keywords"]:
            if keyword in text_to_check:
                score += 1
        domain_scores[domain] = score
    
    # Zwr√≥ƒá domenƒô z najwy≈ºszym score (lub universal)
    if domain_scores:
        best_domain = max(domain_scores, key=domain_scores.get)
        if domain_scores[best_domain] > 0:
            return best_domain
    
    return "universal"


def get_dynamic_short_sentences(
    main_keyword: str,
    h2_titles: List[str] = None,
    count: int = 8,
    include_questions: bool = True
) -> Dict[str, any]:
    """
    Generuje dynamiczne kr√≥tkie zdania dopasowane do tematu.
    
    Args:
        main_keyword: G≈Ç√≥wna fraza kluczowa
        h2_titles: Lista tytu≈Ç√≥w H2 (opcjonalnie)
        count: Ile zda≈Ñ zwr√≥ciƒá
        include_questions: Czy do≈ÇƒÖczyƒá pytania retoryczne
        
    Returns:
        Dict z:
        - domain: wykryta domena
        - sentences: lista kr√≥tkich zda≈Ñ
        - patterns: wzorce do u≈ºycia
        - instruction: instrukcja dla GPT
    """
    # Wykryj domenƒô
    domain = detect_topic_domain(main_keyword, h2_titles)
    
    # Pobierz zdania z domeny
    domain_sentences = TOPIC_SHORT_SENTENCES.get(domain, {}).get("patterns", [])
    universal_sentences = TOPIC_SHORT_SENTENCES["universal"]["patterns"]
    
    # Po≈ÇƒÖcz (priorytet dla domenowych)
    all_sentences = domain_sentences.copy()
    
    # Dodaj pytania je≈õli w≈ÇƒÖczone
    if include_questions:
        all_sentences.extend(SHORT_SENTENCE_PATTERNS["question"])
    
    # Dodaj tranzycje
    all_sentences.extend(SHORT_SENTENCE_PATTERNS["transition"][:3])
    
    # Uzupe≈Çnij uniwersalnymi je≈õli za ma≈Ço
    if len(all_sentences) < count:
        all_sentences.extend(universal_sentences)
    
    # Ogranicz do ≈ºƒÖdanej liczby
    selected_sentences = all_sentences[:count]
    
    return {
        "domain": domain,
        "sentences": selected_sentences,
        "patterns": SHORT_SENTENCE_PATTERNS,
        "instruction": f"""
üéØ KR√ìTKIE ZDANIA ({domain.upper()}) - u≈ºyj 2-4 w batchu:

PRZYK≈ÅADY:
{chr(10).join(f"‚Ä¢ {s}" for s in selected_sentences[:6])}

ZASADY:
1. Wstaw po d≈Çugim zdaniu (>25 s≈Ç√≥w)
2. U≈ºywaj przed zmianƒÖ tematu
3. NIE POWTARZAJ tych samych fraz!
4. Mo≈ºesz tworzyƒá W≈ÅASNE kr√≥tkie zdania (3-8 s≈Ç√≥w)
"""
    }


# ============================================================================
# SYNONIMY DYNAMICZNE - zamiast s≈Çabego SYNONYM_MAP
# ============================================================================

# Synonimy kontekstowe - u≈ºywane gdy fraza jest nadu≈ºywana
CONTEXTUAL_SYNONYMS = {
    # Czasowniki - najczƒô≈õciej powtarzane
    "mo≈ºna": ["da siƒô", "istnieje mo≈ºliwo≈õƒá", "jest opcja"],
    "nale≈ºy": ["trzeba", "wymaga siƒô", "konieczne jest"],
    "wymaga": ["potrzebuje", "niezbƒôdne jest", "konieczne"],
    "pozwala": ["umo≈ºliwia", "daje mo≈ºliwo≈õƒá", "otwiera drogƒô do"],
    "dotyczy": ["odnosi siƒô do", "obejmuje", "tyczy siƒô"],
    "stanowi": ["jest", "reprezentuje", "tworzy"],
    
    # Przymiotniki - ≈Çatwe do nadu≈ºycia
    "wa≈ºny": ["istotny", "znaczƒÖcy", "kluczowy", "zasadniczy"],
    "dobry": ["skuteczny", "warto≈õciowy", "odpowiedni", "w≈Ça≈õciwy"],
    "g≈Ç√≥wny": ["podstawowy", "kluczowy", "centralny", "nadrzƒôdny"],
    "odpowiedni": ["w≈Ça≈õciwy", "stosowny", "adekwatny"],
    
    # Rzeczowniki - kontekstowe
    "osoba": ["cz≈Çowiek", "jednostka", "indywiduum"],
    "sprawa": ["kwestia", "zagadnienie", "przypadek"],
    "spos√≥b": ["metoda", "forma", "droga"],
    "proces": ["procedura", "przebieg", "tok"],
    "warunek": ["wym√≥g", "kryterium", "przes≈Çanka"],
    
    # Frazy do zamiany
    "w przypadku": ["gdy", "je≈õli", "kiedy"],
    "w celu": ["aby", "≈ºeby", "dla"],
    "ze wzglƒôdu na": ["z powodu", "przez", "wskutek"],
    "w kontek≈õcie": ["przy", "podczas", "w ramach"],
}


def get_synonyms_for_word(word: str, context: str = "") -> List[str]:
    """
    Zwraca synonimy dla s≈Çowa.
    
    v40.1: Hierarchia ≈∫r√≥de≈Ç:
    1. CONTEXTUAL_SYNONYMS (lokalna mapa - najszybsze)
    2. synonym_service (plWordNet API + Firestore cache + LLM fallback)
    
    Args:
        word: S≈Çowo do znalezienia synonim√≥w
        context: Opcjonalny kontekst (np. "artyku≈Ç prawniczy")
        
    Returns:
        Lista synonim√≥w (max 5)
    """
    word_lower = word.lower().strip()
    
    # 1. NAJPIERW: lokalna mapa CONTEXTUAL_SYNONYMS (najszybsze)
    local_synonyms = CONTEXTUAL_SYNONYMS.get(word_lower, [])
    if local_synonyms:
        return local_synonyms[:5]
    
    # 2. FALLBACK: synonym_service (plWordNet + cache + LLM)
    if SYNONYM_SERVICE_AVAILABLE:
        try:
            result = _get_synonyms_external(word_lower, context=context, use_cache=True)
            external_synonyms = result.get("synonyms", [])
            if external_synonyms:
                source = result.get("source", "unknown")
                print(f"[DYNAMIC_HUMANIZATION] üìö Synonyms for '{word}' from {source}: {external_synonyms[:3]}")
                return external_synonyms[:5]
        except Exception as e:
            print(f"[DYNAMIC_HUMANIZATION] ‚ö†Ô∏è synonym_service error for '{word}': {e}")
    
    return []


def get_synonyms_batch(words: List[str], context: str = "") -> Dict[str, List[str]]:
    """
    üÜï v40.1: Pobiera synonimy dla wielu s≈Ç√≥w naraz.
    
    Optymalizacja - jedno zapytanie zamiast wielu.
    
    Args:
        words: Lista s≈Ç√≥w
        context: Kontekst artyku≈Çu
        
    Returns:
        Dict {s≈Çowo: [synonimy]}
    """
    result = {}
    words_to_fetch_external = []
    
    # 1. Sprawd≈∫ lokalnƒÖ mapƒô
    for word in words:
        word_lower = word.lower().strip()
        local = CONTEXTUAL_SYNONYMS.get(word_lower, [])
        if local:
            result[word] = local[:5]
        else:
            words_to_fetch_external.append(word)
    
    # 2. Pobierz brakujƒÖce z synonym_service
    if words_to_fetch_external and SYNONYM_SERVICE_AVAILABLE:
        try:
            external_results = _get_synonyms_batch_external(words_to_fetch_external, context)
            for word, synonyms in external_results.items():
                if synonyms:
                    result[word] = synonyms[:5]
        except Exception as e:
            print(f"[DYNAMIC_HUMANIZATION] ‚ö†Ô∏è Batch synonym fetch error: {e}")
    
    return result


def get_synonym_instructions(overused_words: List[str] = None, context: str = "") -> Dict[str, any]:
    """
    Generuje instrukcje synonim√≥w dla GPT.
    
    v40.1: U≈ºywa batch fetch dla wydajno≈õci + kontekst dla lepszych wynik√≥w.
    
    Args:
        overused_words: Lista s≈Ç√≥w kt√≥re sƒÖ nadu≈ºywane w artykule
        context: Kontekst artyku≈Çu (np. "prawo", "medycyna")
        
    Returns:
        Dict z instrukcjami i mapƒÖ synonim√≥w
    """
    # Je≈õli podano nadu≈ºywane s≈Çowa, priorytetyzuj je
    if overused_words:
        # v40.1: U≈ºyj batch fetch dla wydajno≈õci
        all_synonyms = get_synonyms_batch(overused_words, context=context)
        
        priority_synonyms = {}
        for word in overused_words:
            syns = all_synonyms.get(word, [])
            if not syns:
                # Fallback do pojedynczego zapytania
                syns = get_synonyms_for_word(word, context=context)
            if syns:
                priority_synonyms[word] = syns[:3]
        
        if priority_synonyms:
            # Informacja o ≈∫r√≥dle
            source_info = "plWordNet + cache" if SYNONYM_SERVICE_AVAILABLE else "local"
            
            return {
                "priority": "HIGH",
                "instruction": "‚ö†Ô∏è TE S≈ÅOWA SƒÑ NADU≈ªYWANE - u≈ºyj synonim√≥w:",
                "synonyms": priority_synonyms,
                "warning": "Nie powtarzaj tego samego s≈Çowa >3x w batchu!",
                "source": source_info
            }
    
    # Domy≈õlne - og√≥lne wskaz√≥wki
    return {
        "priority": "NORMAL",
        "instruction": "Unikaj powt√≥rze≈Ñ - u≈ºywaj synonim√≥w:",
        "synonyms": {
            "mo≈ºna/nale≈ºy": ["trzeba", "warto", "da siƒô"],
            "wa≈ºny/istotny": ["kluczowy", "znaczƒÖcy", "zasadniczy"],
            "w przypadku": ["gdy", "je≈õli", "kiedy"],
        },
        "tip": "Sprawd≈∫ czy nie powtarzasz s≈Ç√≥w >3x",
        "source": "defaults"
    }


# ============================================================================
# BURSTINESS - SPRAWDZANIE I INSTRUKCJE
# ============================================================================

@dataclass
class BurstinessMetrics:
    """Metryki burstiness (zr√≥≈ºnicowania d≈Çugo≈õci zda≈Ñ)."""
    cv: float  # Wsp√≥≈Çczynnik zmienno≈õci (target > 0.40)
    short_pct: float  # % kr√≥tkich zda≈Ñ (3-8 s≈Ç√≥w) - target 20-25%
    medium_pct: float  # % ≈õrednich (10-18 s≈Ç√≥w) - target 50-60%
    long_pct: float  # % d≈Çugich (22-35 s≈Ç√≥w) - target 15-25%
    ai_pattern_pct: float  # % zda≈Ñ 15-22 s≈Ç√≥w (AI pattern) - target <30%
    is_healthy: bool
    issues: List[str]


def analyze_burstiness(text: str) -> BurstinessMetrics:
    """
    Analizuje burstiness tekstu.
    """
    # Podziel na zdania
    sentences = re.split(r'[.!?]+', text)
    sentences = [s.strip() for s in sentences if s.strip()]
    
    if len(sentences) < 3:
        return BurstinessMetrics(
            cv=0.0, short_pct=0, medium_pct=0, long_pct=0,
            ai_pattern_pct=0, is_healthy=False, 
            issues=["Za ma≈Ço zda≈Ñ do analizy"]
        )
    
    # Policz s≈Çowa w ka≈ºdym zdaniu
    lengths = [len(s.split()) for s in sentences]
    
    # Oblicz metryki
    import statistics
    mean_len = statistics.mean(lengths)
    std_len = statistics.stdev(lengths) if len(lengths) > 1 else 0
    cv = std_len / mean_len if mean_len > 0 else 0
    
    total = len(lengths)
    short_count = sum(1 for l in lengths if 3 <= l <= 8)
    medium_count = sum(1 for l in lengths if 10 <= l <= 18)
    long_count = sum(1 for l in lengths if 22 <= l <= 35)
    ai_pattern_count = sum(1 for l in lengths if 15 <= l <= 22)
    
    short_pct = (short_count / total) * 100
    medium_pct = (medium_count / total) * 100
    long_pct = (long_count / total) * 100
    ai_pattern_pct = (ai_pattern_count / total) * 100
    
    # Sprawd≈∫ problemy
    issues = []
    if cv < 0.35:
        issues.append(f"CV={cv:.2f} za niskie (target >0.40) - zdania za podobne!")
    if short_pct < 15:
        issues.append(f"Za ma≈Ço kr√≥tkich zda≈Ñ: {short_pct:.0f}% (target 20-25%)")
    if ai_pattern_pct > 40:
        issues.append(f"Za du≈ºo zda≈Ñ 15-22 s≈Ç√≥w: {ai_pattern_pct:.0f}% (AI pattern!)")
    
    is_healthy = len(issues) == 0
    
    return BurstinessMetrics(
        cv=round(cv, 3),
        short_pct=round(short_pct, 1),
        medium_pct=round(medium_pct, 1),
        long_pct=round(long_pct, 1),
        ai_pattern_pct=round(ai_pattern_pct, 1),
        is_healthy=is_healthy,
        issues=issues
    )


def get_burstiness_instructions(previous_batch_text: str = None) -> Dict[str, any]:
    """
    Generuje instrukcje burstiness dla GPT.
    
    Args:
        previous_batch_text: Tekst poprzedniego batcha (opcjonalnie, do analizy)
        
    Returns:
        Dict z instrukcjami i metrykami
    """
    base_instruction = {
        "critical": True,
        "what": "BURSTINESS = zr√≥≈ºnicowanie d≈Çugo≈õci zda≈Ñ",
        "why": "Monotonne zdania 15-20 s≈Ç√≥w = wykrycie AI!",
        "target_cv": ">0.40",
        "distribution": {
            "short_3_8_words": "20-25%",
            "medium_10_18_words": "50-60%",
            "long_22_35_words": "15-25%"
        },
        "example_sequence": "5, 18, 8, 25, 12, 6, 30, 14 s≈Ç√≥w",
        "avoid": "‚ùå NIE PISZ wszystkich zda≈Ñ 15-22 s≈Ç√≥w!"
    }
    
    # Je≈õli mamy poprzedni batch, analizuj go
    if previous_batch_text:
        metrics = analyze_burstiness(previous_batch_text)
        
        if not metrics.is_healthy:
            base_instruction["previous_batch_analysis"] = {
                "cv": metrics.cv,
                "short_pct": metrics.short_pct,
                "issues": metrics.issues,
                "fix_instruction": "‚ö†Ô∏è Poprzedni batch ma problemy z burstiness - POPRAW!"
            }
    
    return base_instruction


# ============================================================================
# G≈Å√ìWNA FUNKCJA - PE≈ÅNE INSTRUKCJE HUMANIZACJI
# ============================================================================

def get_humanization_instructions(
    main_keyword: str,
    h2_titles: List[str] = None,
    previous_batch_text: str = None,
    overused_words: List[str] = None
) -> Dict[str, any]:
    """
    Generuje kompletne instrukcje humanizacji dla GPT.
    
    Args:
        main_keyword: G≈Ç√≥wna fraza kluczowa
        h2_titles: Lista H2 (opcjonalnie)
        previous_batch_text: Poprzedni batch do analizy (opcjonalnie)
        overused_words: Nadu≈ºywane s≈Çowa (opcjonalnie)
        
    Returns:
        Dict z pe≈Çnymi instrukcjami humanizacji
    """
    return {
        "version": "v40.0",
        
        # Kr√≥tkie zdania
        "short_sentences": get_dynamic_short_sentences(
            main_keyword, h2_titles, count=8
        ),
        
        # Burstiness
        "burstiness": get_burstiness_instructions(previous_batch_text),
        
        # Synonimy
        "synonyms": get_synonym_instructions(overused_words),
        
        # AI patterns do unikania
        "avoid_ai_patterns": {
            "instruction": "‚ùå UNIKAJ tych fraz (typowe AI):",
            "patterns": {
                "warto podkre≈õliƒá": "‚Üí usu≈Ñ lub 'Zwr√≥ƒá uwagƒô:'",
                "nale≈ºy pamiƒôtaƒá": "‚Üí 'Pamiƒôtaj:' lub usu≈Ñ",
                "w kontek≈õcie": "‚Üí 'przy', 'podczas'",
                "istotne jest": "‚Üí 'Wa≈ºne:'",
                "kluczowym aspektem jest": "‚Üí usu≈Ñ ca≈Ço≈õƒá",
                "warto zauwa≈ºyƒá": "‚Üí usu≈Ñ",
                "nie bez znaczenia jest": "‚Üí 'Wa≈ºne:'",
            }
        },
        
        # Styl
        "style_tips": {
            "instruction": "Pisz jak ekspert rozmawiajƒÖcy ze znajomym",
            "tips": [
                "U≈ºywaj pyta≈Ñ retorycznych",
                "Nie ka≈ºde zdanie musi byƒá 'mƒÖdre'",
                "Dodawaj kr√≥tkie reakcje (To wa≈ºne. Uwaga na to.)",
                "Mieszaj zdania proste ze z≈Ço≈ºonymi"
            ]
        }
    }


# ============================================================================
# EXPORTS
# ============================================================================

__all__ = [
    # G≈Ç√≥wne funkcje
    'get_dynamic_short_sentences',
    'get_synonym_instructions',
    'get_burstiness_instructions',
    'get_humanization_instructions',
    
    # Funkcje pomocnicze
    'detect_topic_domain',
    'analyze_burstiness',
    'get_synonyms_for_word',
    'get_synonyms_batch',  # üÜï v40.1
    
    # Klasy
    'BurstinessMetrics',
    
    # Sta≈Çe
    'CONTEXTUAL_SYNONYMS',
    'TOPIC_SHORT_SENTENCES',
    'SHORT_SENTENCE_PATTERNS',
    
    # Status integracji
    'SYNONYM_SERVICE_AVAILABLE',  # üÜï v40.1
]


# ============================================================================
# TEST / DEMO
# ============================================================================

if __name__ == "__main__":
    # Test detekcji domeny
    print("=" * 60)
    print("TEST: Detekcja domeny")
    print("=" * 60)
    
    test_cases = [
        ("ubezw≈Çasnowolnienie czƒô≈õciowe", ["Przes≈Çanki prawne", "Procedura sƒÖdowa"]),
        ("terapia integracji sensorycznej", ["ƒÜwiczenia dla dzieci"]),
        ("rozliczenie podatku PIT", ["Ulgi podatkowe"]),
        ("programowanie w Python", ["Podstawy kodu"]),
    ]
    
    for main_kw, h2s in test_cases:
        domain = detect_topic_domain(main_kw, h2s)
        print(f"'{main_kw}' ‚Üí {domain}")
    
    print("\n" + "=" * 60)
    print("TEST: Kr√≥tkie zdania dla tematu prawnego")
    print("=" * 60)
    
    result = get_dynamic_short_sentences(
        "ubezw≈Çasnowolnienie ca≈Çkowite",
        ["Procedura sƒÖdowa", "Skutki prawne"]
    )
    print(f"Domena: {result['domain']}")
    print("Zdania:")
    for s in result['sentences']:
        print(f"  ‚Ä¢ {s}")
    
    print("\n" + "=" * 60)
    print("TEST: Analiza burstiness")
    print("=" * 60)
    
    test_text = """
    Ubezw≈Çasnowolnienie to powa≈ºna decyzja. SƒÖd orzeka. Wymaga to odpowiednich 
    przes≈Çanek prawnych okre≈õlonych w kodeksie cywilnym. To wa≈ºne. Procedura 
    jest skomplikowana i wymaga udzia≈Çu bieg≈Çych psychiatr√≥w oraz psycholog√≥w 
    w celu oceny stanu zdrowia osoby, kt√≥ra ma byƒá ubezw≈Çasnowolniona. 
    Termin mija. Nale≈ºy pamiƒôtaƒá o terminach.
    """
    
    metrics = analyze_burstiness(test_text)
    print(f"CV: {metrics.cv}")
    print(f"Kr√≥tkie: {metrics.short_pct}%")
    print(f"≈örednie: {metrics.medium_pct}%")
    print(f"D≈Çugie: {metrics.long_pct}%")
    print(f"AI pattern: {metrics.ai_pattern_pct}%")
    print(f"Zdrowe: {metrics.is_healthy}")
    if metrics.issues:
        print(f"Problemy: {metrics.issues}")
    
    # üÜï v40.1: Test integracji z synonym_service
    print("\n" + "=" * 60)
    print("TEST: Synonimy (v40.1 - z integracjƒÖ synonym_service)")
    print("=" * 60)
    print(f"SYNONYM_SERVICE_AVAILABLE: {SYNONYM_SERVICE_AVAILABLE}")
    
    test_words = ["mo≈ºna", "wa≈ºny", "procedura", "ubezw≈Çasnowolnienie"]
    for word in test_words:
        syns = get_synonyms_for_word(word, context="prawo")
        source = "local" if word in CONTEXTUAL_SYNONYMS else ("external" if syns else "none")
        print(f"'{word}' ‚Üí {syns[:3] if syns else '(brak)'} [source: {source}]")
    
    print("\n" + "=" * 60)
    print("TEST: Batch synonym fetch")
    print("=" * 60)
    
    batch_result = get_synonyms_batch(["mo≈ºna", "nale≈ºy", "sƒÖd"], context="prawo")
    for word, syns in batch_result.items():
        print(f"'{word}' ‚Üí {syns[:3]}")

