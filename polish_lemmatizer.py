"""
===============================================================================
ðŸ‡µðŸ‡± POLISH LEMMATIZER v29.1 - UÅ¼ywa wspÃ³Å‚dzielonego spaCy
===============================================================================
v29.1: 
- Normalizacja myÅ›lnikÃ³w i symboli w frazach
- Bidirectional matching (terapii â†” terapia)
- ObsÅ‚uga fraz typu "integracja sensoryczna â€“ pomoce"

v26.1: UÅ¼ywa shared_nlp.py + rozszerzone wzorce polskich form
===============================================================================
"""

import re
from typing import Dict, List, Set

# Import wspÃ³Å‚dzielonego spaCy
try:
    from shared_nlp import get_nlp
    _SPACY_OK = True
    print("[LEMMATIZER] âœ… Using shared spaCy from shared_nlp.py")
except ImportError:
    _SPACY_OK = False
    print("[LEMMATIZER] âš ï¸ shared_nlp not available, using fallback")

# Cache dla wydajnoÅ›ci
_lemma_cache = {}
_forms_cache = {}

BACKEND = "SPACY" if _SPACY_OK else "FALLBACK"


# ============================================================================
# v29.1: NORMALIZACJA FRAZ Z MYÅšLNIKAMI I SYMBOLAMI
# ============================================================================
def normalize_phrase(phrase: str) -> str:
    """
    v29.1: Normalizuje frazÄ™ do porÃ³wnania.
    
    - Zamienia wszystkie typy myÅ›lnikÃ³w na spacjÄ™
    - Usuwa wielokrotne spacje
    - Zamienia em dash (â€“), en dash (â€“), hyphen (-) na spacjÄ™
    
    "integracja sensoryczna â€“ pomoce" â†’ "integracja sensoryczna pomoce"
    """
    if not phrase:
        return ""
    
    # ZamieÅ„ rÃ³Å¼ne typy myÅ›lnikÃ³w na spacjÄ™
    normalized = phrase
    normalized = normalized.replace('â€“', ' ')  # em dash
    normalized = normalized.replace('â€”', ' ')  # em dash (longer)
    normalized = normalized.replace('-', ' ')   # hyphen
    normalized = normalized.replace('âˆ’', ' ')  # minus sign
    
    # UsuÅ„ wielokrotne spacje
    normalized = ' '.join(normalized.split())
    
    return normalized.lower().strip()


def normalize_text_for_matching(text: str) -> str:
    """
    v29.1: Normalizuje tekst do wyszukiwania fraz.
    """
    if not text:
        return ""
    
    normalized = text.lower()
    # ZamieÅ„ myÅ›lniki na spacje
    normalized = normalized.replace('â€“', ' ')
    normalized = normalized.replace('â€”', ' ')
    normalized = normalized.replace('-', ' ')
    normalized = normalized.replace('âˆ’', ' ')
    # UsuÅ„ wielokrotne spacje
    normalized = ' '.join(normalized.split())
    
    return normalized


def init_backend():
    """Inicjalizuje backend (spaCy przez shared_nlp)."""
    global BACKEND
    if _SPACY_OK:
        try:
            nlp = get_nlp()
            BACKEND = "SPACY"
            print(f"[LEMMATIZER] âœ… Backend: SPACY ({nlp.meta.get('name', 'unknown')})")
            return True
        except Exception as e:
            print(f"[LEMMATIZER] âš ï¸ spaCy error: {e}")
            BACKEND = "FALLBACK"
    return False


def get_backend_info() -> Dict:
    """Zwraca info o backendzie."""
    return {
        "backend": BACKEND,
        "spacy_available": _SPACY_OK
    }


def get_lemma(word: str) -> str:
    """Zwraca lemat sÅ‚owa uÅ¼ywajÄ…c spaCy."""
    word_lower = word.lower().strip()
    
    if word_lower in _lemma_cache:
        return _lemma_cache[word_lower]
    
    lemma = word_lower
    
    if _SPACY_OK:
        try:
            nlp = get_nlp()
            doc = nlp(word_lower)
            if doc and len(doc) > 0:
                lemma = doc[0].lemma_.lower()
        except:
            pass
    
    _lemma_cache[word_lower] = lemma
    return lemma


def get_all_forms(word: str) -> Set[str]:
    """Zwraca wszystkie rozpoznawane formy sÅ‚owa."""
    word_lower = word.lower().strip()
    
    if word_lower in _forms_cache:
        return _forms_cache[word_lower]
    
    forms = {word_lower}
    
    # Dodaj lemat
    lemma = get_lemma(word_lower)
    forms.add(lemma)
    
    # Generuj typowe polskie formy
    forms.update(_generate_forms_from_lemma(lemma))
    if lemma != word_lower:
        forms.update(_generate_forms_from_lemma(word_lower))
    
    _forms_cache[word_lower] = forms
    return forms


def _generate_forms_from_lemma(word: str) -> Set[str]:
    """Generuje typowe polskie formy sÅ‚owa."""
    forms = {word}
    
    if not word or len(word) < 2:
        return forms
    
    # === RZECZOWNIKI Å»EÅƒSKIE ===
    
    # -ia (terapia, integracja) - WAÅ»NE!
    if word.endswith('ia') and len(word) > 3:
        base = word[:-2]
        forms.update([word, base + 'ii', base + 'iÄ™', base + 'iÄ…', base + 'io',
                     base + 'ie', base + 'ij', base + 'iom', base + 'iami', base + 'iach'])
        return forms
    
    # -ka (Å›cieÅ¼ka, podrÃ³Å¼ka) - BARDZO WAÅ»NE!
    if word.endswith('ka') and len(word) > 3:
        base = word[:-2]
        forms.update([word, base + 'ki', base + 'kÄ™', base + 'kÄ…', base + 'ce',
                     base + 'ek', base + 'kom', base + 'kami', base + 'kach'])
        return forms
    
    # -a (droga, mama) - rzeczowniki Å¼eÅ„skie
    if word.endswith('a') and len(word) > 2 and not word.endswith('ca'):
        base = word[:-1]
        forms.update([word, base + 'y', base + 'Ä™', base + 'Ä…', base + 'ie', base + 'o',
                     base, base + 'om', base + 'ami', base + 'ach'])
        return forms
    
    # -enie, -anie (uzaleÅ¼nienie)
    if word.endswith('enie') or word.endswith('anie'):
        base = word[:-1]
        forms.update([word, base + 'a', base + 'u', base + 'em', base + 'ami', base + 'ach', base + 'om'])
        return forms
    
    # -oÅ›Ä‡ (wolnoÅ›Ä‡)
    if word.endswith('oÅ›Ä‡'):
        base = word[:-1]
        forms.update([word, base + 'i', base + 'iÄ…', base + 'iom', base + 'iami', base + 'iach'])
        return forms
    
    # -acja (sytuacja)
    if word.endswith('acja'):
        base = word[:-1]
        forms.update([word, base + 'i', base + 'Ä™', base + 'Ä…', base + 'e', base + 'om', base + 'ami', base + 'ach'])
        return forms
    
    # -Ä…d (sÄ…d)
    if word.endswith('Ä…d'):
        base = word[:-2]
        forms.update([word, base + 'Ä…du', base + 'Ä…dowi', base + 'Ä…dem', base + 'Ä…dzie',
                     base + 'Ä…dy', base + 'Ä…dÃ³w', base + 'Ä…dom', base + 'Ä…dami', base + 'Ä…dach'])
        return forms
    
    # -Ã³d (rozwÃ³d) - alternacja Ã³/o
    if word.endswith('Ã³d'):
        base = word[:-2]
        forms.update([word, base + 'odu', base + 'odowi', base + 'odem', base + 'odzie',
                     base + 'ody', base + 'odÃ³w', base + 'odom', base + 'odami', base + 'odach'])
        return forms
    
    # -Ã³g (naÅ‚Ã³g) - alternacja Ã³/o
    if word.endswith('Ã³g'):
        base = word[:-2]
        forms.update([word, base + 'ogu', base + 'ogowi', base + 'ogiem',
                     base + 'ogi', base + 'ogÃ³w', base + 'ogom', base + 'ogami', base + 'ogach'])
        return forms
    
    # -yk (narkotyk)
    if word.endswith('yk'):
        base = word[:-2]
        forms.update([word, base + 'yku', base + 'ykowi', base + 'ykiem',
                     base + 'yki', base + 'ykÃ³w', base + 'ykom', base + 'ykami', base + 'ykach'])
        return forms
    
    # -nik (prawnik)
    if word.endswith('nik'):
        base = word[:-3]
        forms.update([word, base + 'nika', base + 'nikowi', base + 'nikiem', base + 'niku',
                     base + 'nicy', base + 'nikÃ³w', base + 'nikom', base + 'nikami', base + 'nikach'])
        return forms
    
    # -ek (maÅ‚Å¼onek)
    if word.endswith('ek') and len(word) > 3:
        base = word[:-2]
        forms.update([word, base + 'ka', base + 'kowi', base + 'kiem', base + 'ku',
                     base + 'kowie', base + 'kÃ³w', base + 'kom', base + 'kami', base + 'kach'])
        return forms
    
    # -ca (radca)
    if word.endswith('ca'):
        base = word[:-2]
        forms.update([word, base + 'cy', base + 'cÄ™', base + 'cÄ…',
                     base + 'cÃ³w', base + 'com', base + 'cami', base + 'cach'])
        return forms
    
    # -at (adwokat)
    if word.endswith('at') and len(word) > 3:
        base = word[:-2]
        forms.update([word, base + 'ata', base + 'atowi', base + 'atem', base + 'acie',
                     base + 'aci', base + 'atÃ³w', base + 'atom', base + 'atami', base + 'atach'])
        return forms
    
    # === PRZYMIOTNIKI ===
    
    # -yczny (sensoryczny, techniczny) - BARDZO WAÅ»NE!
    if word.endswith('yczny'):
        base = word[:-5]
        forms.update([
            word,  # sensoryczny
            base + 'yczna', base + 'yczne',  # sensoryczna, sensoryczne
            base + 'ycznego', base + 'ycznej',  # sensorycznego, sensorycznej
            base + 'ycznemu',  # sensorycznemu
            base + 'ycznym', base + 'ycznÄ…',  # sensorycznym, sensorycznÄ…
            base + 'yczni', base + 'ycznych', base + 'ycznymi'  # sensoryczni, sensorycznych
        ])
        return forms
    
    # -owy (rozwodowy, kolorowy)
    if word.endswith('owy'):
        base = word[:-3]
        forms.update([word, base + 'owa', base + 'owe', base + 'owego', base + 'owej',
                     base + 'owemu', base + 'owym', base + 'owÄ…', base + 'owi', base + 'owych', base + 'owymi'])
        return forms
    
    # -ny (prawny, ciemny)
    if word.endswith('ny'):
        base = word[:-2]
        forms.update([word, base + 'na', base + 'ne', base + 'nego', base + 'nej',
                     base + 'nemu', base + 'nym', base + 'nÄ…', base + 'ni', base + 'nych', base + 'nymi'])
        return forms
    
    # -ski, -cki (maÅ‚Å¼eÅ„ski, miejski)
    if word.endswith('ski') or word.endswith('cki'):
        base = word[:-2]
        forms.update([word, base + 'ka', base + 'kie', base + 'kiego', base + 'kiej',
                     base + 'kiemu', base + 'kim', base + 'kÄ…', base + 'cy', base + 'kich', base + 'kimi'])
        return forms
    
    # -Å‚y (maÅ‚y, biaÅ‚y)
    if word.endswith('Å‚y'):
        base = word[:-2]
        forms.update([word, base + 'Å‚a', base + 'Å‚e', base + 'Å‚ego', base + 'Å‚ej',
                     base + 'Å‚emu', base + 'Å‚ym', base + 'Å‚Ä…', base + 'li', base + 'Å‚ych', base + 'Å‚ymi'])
        return forms
    
    # === DOMYÅšLNE ===
    if len(word) >= 3:
        forms.update([word, word + 'a', word + 'u', word + 'owi', word + 'em', word + 'ie',
                     word + 'y', word + 'Ã³w', word + 'om', word + 'ami', word + 'ach',
                     word + 'Ä…', word + 'Ä™'])  # dodane formy Å¼eÅ„skie
    
    return forms


def lemmatize_text(text: str) -> List[str]:
    """Zwraca listÄ™ lematÃ³w z tekstu."""
    if not text:
        return []
    
    if _SPACY_OK:
        try:
            nlp = get_nlp()
            doc = nlp(text.lower())
            return [token.lemma_.lower() for token in doc if token.is_alpha]
        except:
            pass
    
    words = re.findall(r'\b\w+\b', text.lower())
    return [get_lemma(w) for w in words]


def get_phrase_lemmas(phrase: str) -> List[str]:
    """Zwraca lematy dla frazy."""
    words = phrase.lower().split()
    return [get_lemma(w) for w in words]


def count_phrase_occurrences(text: str, phrase: str) -> Dict:
    """
    v29.1: PRAWIDÅOWA LEMMATYZACJA + NORMALIZACJA MYÅšLNIKÃ“W
    
    NAJPIERW normalizuje frazÄ™ i tekst (usuwa myÅ›lniki),
    POTEM liczy z lemmatyzacjÄ….
    
    "integracja sensoryczna â€“ pomoce" â†’ szuka "integracja sensoryczna pomoce"
    """
    if not text or not phrase:
        return {"count": 0, "method": "empty", "matches": []}
    
    # v29.1: NORMALIZACJA - zamieÅ„ myÅ›lniki na spacje
    phrase_normalized = normalize_phrase(phrase)
    text_normalized = normalize_text_for_matching(text)
    
    if not phrase_normalized:
        return {"count": 0, "method": "empty_after_normalize", "matches": []}
    
    # SprawdÅº czy spaCy dziaÅ‚a (czy lematy sÄ… rÃ³Å¼ne od oryginaÅ‚u)
    test_word = "sensorycznÄ…"
    test_lemma = get_lemma(test_word)
    spacy_works = (test_lemma != test_word)  # JeÅ›li zlemmatyzowaÅ‚, to dziaÅ‚a
    
    if spacy_works:
        # METODA 1: PorÃ³wnanie lematÃ³w (spaCy dziaÅ‚a)
        phrase_lemmas = get_phrase_lemmas(phrase_normalized)
        text_lemmas = lemmatize_text(text_normalized)
        
        if not phrase_lemmas or not text_lemmas:
            return {"count": 0, "method": "spacy_empty", "matches": []}
        
        count = 0
        matches = []
        phrase_len = len(phrase_lemmas)
        
        for i in range(len(text_lemmas) - phrase_len + 1):
            if text_lemmas[i:i + phrase_len] == phrase_lemmas:
                count += 1
                matches.append(f"pos:{i}")
        
        return {
            "count": count,
            "method": "SPACY_LEMMA",
            "phrase_normalized": phrase_normalized,
            "phrase_lemmas": phrase_lemmas,
            "matches": matches[:10]
        }
    else:
        # METODA 2: Generowanie form (fallback)
        return _count_multi_word_with_forms(text_normalized, phrase_normalized)


def _count_multi_word_with_forms(text: str, phrase: str) -> Dict:
    """
    Fallback: dla kaÅ¼dego sÅ‚owa frazy i tekstu generuj formy,
    sprawdÅº czy siÄ™ przecinajÄ… (match w dowolnÄ… stronÄ™).
    
    "terapii" ma formy: [terapii, terapia, terapiÄ…...]
    "terapia" ma formy: [terapia, terapii, terapiÄ…...]
    â†’ PrzeciÄ™cie niepuste = MATCH!
    """
    words = phrase.split()
    text_words = re.findall(r'\b\w+\b', text.lower())
    
    # Dla kaÅ¼dego sÅ‚owa frazy, pobierz WSZYSTKIE moÅ¼liwe formy (wÅ‚Ä…cznie z formÄ… bazowÄ…)
    forms_per_phrase_word = []
    for w in words:
        # Pobierz formy od tego sÅ‚owa
        forms_from_word = get_all_forms(w)
        # ZnajdÅº teÅ¼ formÄ™ bazowÄ… (lemat) i pobierz jej formy
        # Heurystyka: jeÅ›li sÅ‚owo koÅ„czy siÄ™ na -ii, -Ä…, -Ä™, sprÃ³buj znaleÅºÄ‡ bazÄ™
        base = _guess_lemma(w)
        if base != w:
            forms_from_word.update(get_all_forms(base))
        forms_per_phrase_word.append(forms_from_word)
    
    count = 0
    matches = []
    
    for i in range(len(text_words) - len(words) + 1):
        match = True
        matched_phrase = []
        
        for j, phrase_forms in enumerate(forms_per_phrase_word):
            text_word = text_words[i + j]
            # SprawdÅº czy sÅ‚owo tekstu jest w formach sÅ‚owa frazy
            # LUB czy formy sÅ‚owa tekstu przecinajÄ… siÄ™ z formami sÅ‚owa frazy
            text_word_forms = get_all_forms(text_word)
            
            if text_word not in phrase_forms and not phrase_forms.intersection(text_word_forms):
                match = False
                break
            matched_phrase.append(text_word)
        
        if match:
            count += 1
            matches.append(" ".join(matched_phrase))
    
    return {
        "count": count,
        "method": "FORMS_BIDIRECTIONAL",
        "phrase_words": words,
        "matches": matches[:10]
    }


def _guess_lemma(word: str) -> str:
    """
    Heurystyka: zgadnij formÄ™ podstawowÄ… (lemat) bez spaCy.
    UÅ¼ywane gdy spaCy niedostÄ™pny.
    """
    word = word.lower()
    
    # Rzeczowniki Å¼eÅ„skie w dopeÅ‚niaczu/celowniku
    if word.endswith('ii'):
        return word[:-1] + 'a'  # terapii â†’ terapia
    if word.endswith('ji'):
        return word[:-2] + 'ja'  # integracji â†’ integracja
    if word.endswith('cji'):
        return word[:-1] + 'a'  # integracji â†’ integracja
    
    # Przymiotniki w rÃ³Å¼nych przypadkach
    if word.endswith('ycznej'):
        return word[:-2] + 'y'  # sensorycznej â†’ sensoryczny
    if word.endswith('ycznÄ…'):
        return word[:-1] + 'y'  # sensorycznÄ… â†’ sensoryczny  
    if word.endswith('ycznego'):
        return word[:-3] + 'y'  # sensorycznego â†’ sensoryczny
    if word.endswith('ycznym'):
        return word[:-2] + 'y'  # sensorycznym â†’ sensoryczny
    
    # Rzeczowniki Å¼eÅ„skie
    if word.endswith('kÄ…'):
        return word[:-1] + 'a'  # Å›cieÅ¼kÄ… â†’ Å›cieÅ¼ka
    if word.endswith('kÄ™'):
        return word[:-1] + 'a'  # Å›cieÅ¼kÄ™ â†’ Å›cieÅ¼ka
    if word.endswith('ce') and len(word) > 3:
        return word[:-1] + 'a'  # Å›cieÅ¼ce â†’ Å›cieÅ¼ka (przybliÅ¼enie)
    if word.endswith('ki') and len(word) > 3:
        return word[:-1] + 'a'  # Å›cieÅ¼ki â†’ Å›cieÅ¼ka
    
    # Rzeczowniki mÄ™skie w dopeÅ‚niaczu
    if word.endswith('Ã³w'):
        return word[:-2]  # terapeutÃ³w â†’ terapeut
    if word.endswith('ach'):
        return word[:-3]  # przedszkolach â†’ przedszkol? (nie idealne)
    
    return word


def _count_single_word(text: str, word: str) -> Dict:
    """Liczy pojedyncze sÅ‚owo z formami."""
    forms = get_all_forms(word)
    
    count = 0
    matches = []
    
    for form in forms:
        pattern = r'\b' + re.escape(form) + r'\b'
        found = re.findall(pattern, text, re.IGNORECASE)
        count += len(found)
        if found:
            matches.extend(found)
    
    return {
        "count": count,
        "method": BACKEND,
        "forms_checked": list(forms)[:15],
        "matches": matches[:10]
    }


def _count_multi_word(text: str, words: List[str]) -> Dict:
    """Liczy frazÄ™ wielowyrazowÄ… z formami."""
    forms_per_word = [get_all_forms(w) for w in words]
    
    text_words = re.findall(r'\b\w+\b', text.lower())
    
    count = 0
    matches = []
    
    for i in range(len(text_words) - len(words) + 1):
        match = True
        matched_phrase = []
        
        for j, word_forms in enumerate(forms_per_word):
            if text_words[i + j] not in word_forms:
                match = False
                break
            matched_phrase.append(text_words[i + j])
        
        if match:
            count += 1
            matches.append(" ".join(matched_phrase))
    
    return {
        "count": count,
        "method": BACKEND,
        "phrase_words": words,
        "matches": matches[:10]
    }


# ============================================================================
# TEST
# ============================================================================
if __name__ == "__main__":
    init_backend()
    print(f"\nBackend: {BACKEND}")
    
    print("\n=== TEST FORM ===")
    for word in ['sÄ…d', 'rozwÃ³d', 'uzaleÅ¼nienie', 'prawny', 'maÅ‚Å¼eÅ„ski', 'narkotyk']:
        forms = get_all_forms(word)
        print(f"  '{word}' â†’ {len(forms)} form: {sorted(list(forms))[:8]}...")
    
    print("\n=== TEST LICZENIA ===")
    text = "SÄ…d orzekÅ‚ rozwÃ³d. W sÄ…dzie odbyÅ‚a siÄ™ rozprawa rozwodowa. SÄ…dy czÄ™sto orzekajÄ…."
    for phrase in ['sÄ…d', 'rozwÃ³d', 'rozwodowy']:
        result = count_phrase_occurrences(text, phrase)
        print(f"  '{phrase}' w tekÅ›cie: {result['count']}x")
