# concept_map_extractor.py
# BRAJEN v34.0 - Semantic Entity SEO
# Ekstrakcja Mapy Pojƒôƒá (Concept Map) z Gemini AI

import json
import re
import os
from typing import Dict, List, Any

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("[CONCEPT_MAP] ‚ö†Ô∏è google-generativeai not installed")

# Konfiguracja Gemini
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if GEMINI_API_KEY and GEMINI_AVAILABLE:
    genai.configure(api_key=GEMINI_API_KEY)
    print("[CONCEPT_MAP] ‚úÖ Gemini configured")


# ============================================================================
# PROMPT DO EKSTRAKCJI CONCEPT MAP
# ============================================================================

CONCEPT_MAP_PROMPT = """Analizujesz temat: "{main_keyword}"

Na podstawie tekst√≥w konkurencji, stw√≥rz MAPƒò POJƒòƒÜ (Concept Map) dla tego tematu.

TEKSTY KONKURENCJI:
{competitor_texts}

ZADANIE:
Zidentyfikuj strukturƒô semantycznƒÖ tematu:

1. ENCJA G≈Å√ìWNA (Main Entity)
   - Co jest PRZEDMIOTEM us≈Çugi/artyku≈Çu? (nie s≈Çowo kluczowe, ale KONCEPT)
   - Typ encji wg schema.org (Service, Product, Place, Organization, Person, Event, etc.)

2. ENCJE WSPIERAJƒÑCE (Supporting Entities)
   - Pojƒôcia kt√≥re MUSZƒÑ wystƒÖpiƒá ≈ºeby tekst by≈Ç ekspercki
   - Podziel na: tools (narzƒôdzia), processes (procesy), attributes (cechy), 
     locations (miejsca), certifications (certyfikaty), related_services

3. RELACJE SEMANTYCZNE
   - ZwiƒÖzki miƒôdzy encjƒÖ g≈Ç√≥wnƒÖ a wspierajƒÖcymi
   - Format: subject -> predicate -> object

4. TR√ìJKA KLASYFIKACYJNA (Classification Triplet)
   - 3 s≈Çowa kt√≥re MUSZƒÑ byƒá w pierwszych 100 s≈Çowach artyku≈Çu
   - [Typ us≈Çugi/produktu] + [Kontekst/Lokalizacja] + [G≈Ç√≥wny atrybut]

5. PROXIMITY CLUSTERS (Grupy Blisko≈õci)
   - Kt√≥re s≈Çowa MUSZƒÑ wystƒôpowaƒá blisko siebie?
   - Je≈õli piszesz o "fortepianie" - blisko muszƒÖ byƒá "pasy", "wnoszenie", "ciƒô≈ºar"

6. SEMANTIC CONFIDENCE TERMS
   - Frazy kt√≥re potwierdzajƒÖ ekspertyzƒô (np. "ubezpieczenie OCP do 100 000 z≈Ç")

Zwr√≥ƒá TYLKO JSON:
{{
  "main_entity": {{
    "name": "nazwa encji (np. 'Us≈Çuga transportowa' nie 'przeprowadzki')",
    "type": "typ schema.org",
    "definition": "kr√≥tka definicja w kontek≈õcie artyku≈Çu"
  }},
  "supporting_entities": {{
    "tools": ["narzƒôdzie1", "narzƒôdzie2"],
    "processes": ["proces1", "proces2"],
    "attributes": ["atrybut1", "atrybut2"],
    "locations": ["lokalizacja1"],
    "certifications": ["certyfikat1"],
    "related_services": ["us≈Çuga1"]
  }},
  "relationships": [
    {{"subject": "encja1", "predicate": "wymaga", "object": "encja2"}},
    {{"subject": "encja1", "predicate": "oferuje", "object": "encja3"}}
  ],
  "classification_triplet": {{
    "service_type": "s≈Çowo opisujƒÖce typ",
    "context": "lokalizacja lub kontekst",
    "main_attribute": "g≈Ç√≥wna cecha"
  }},
  "proximity_clusters": [
    {{
      "anchor": "s≈Çowo_kluczowe",
      "must_have_nearby": ["kontekst1", "kontekst2", "kontekst3"],
      "max_distance": 25
    }}
  ],
  "semantic_confidence_terms": [
    "fraza ekspercka 1",
    "fraza ekspercka 2"
  ]
}}

PRZYK≈ÅAD dla "przeprowadzki warszawa":
- main_entity: "Us≈Çuga transportowa" (nie "przeprowadzki")
- supporting_entities.tools: ["winda meblowa", "pasy transportowe", "folia bƒÖbelkowa"]
- proximity_cluster: {{"anchor": "fortepian", "must_have_nearby": ["pasy", "wnoszenie", "ciƒô≈ºar"]}}
- classification_triplet: {{"service_type": "przeprowadzki", "context": "Warszawa", "main_attribute": "profesjonalne"}}
"""


# ============================================================================
# FUNKCJE EKSTRAKCJI
# ============================================================================

def extract_concept_map(
    main_keyword: str,
    competitor_texts: List[str],
    gemini_model: str = "gemini-2.0-flash"
) -> Dict[str, Any]:
    """
    Ekstrahuje mapƒô pojƒôƒá (Concept Map) dla tematu.
    
    Args:
        main_keyword: G≈Ç√≥wna fraza kluczowa
        competitor_texts: Lista tekst√≥w konkurencji
        gemini_model: Model Gemini do u≈ºycia
        
    Returns:
        Dict z kluczami: status, concept_map
    """
    if not GEMINI_AVAILABLE or not GEMINI_API_KEY:
        print("[CONCEPT_MAP] ‚ö†Ô∏è Gemini not available, using fallback")
        return {
            "status": "FALLBACK",
            "concept_map": get_fallback_concept_map(main_keyword)
        }
    
    # Po≈ÇƒÖcz teksty konkurencji (max 15k znak√≥w)
    combined_texts = "\n\n---ARTYKU≈Å---\n\n".join([t[:3000] for t in competitor_texts[:5]])
    
    prompt = CONCEPT_MAP_PROMPT.format(
        main_keyword=main_keyword,
        competitor_texts=combined_texts[:15000]
    )
    
    try:
        model = genai.GenerativeModel(gemini_model)
        response = model.generate_content(prompt)
        
        # WyciƒÖgnij JSON z odpowiedzi
        text = response.text.strip()
        
        # Usu≈Ñ markdown code blocks je≈õli sƒÖ
        if "```json" in text:
            match = re.search(r'```json\s*(.*?)\s*```', text, re.DOTALL)
            if match:
                text = match.group(1)
        elif "```" in text:
            match = re.search(r'```\s*(.*?)\s*```', text, re.DOTALL)
            if match:
                text = match.group(1)
        
        concept_map = json.loads(text)
        
        # Walidacja i uzupe≈Çnienie brakujƒÖcych kluczy
        concept_map = validate_concept_map(concept_map, main_keyword)
        
        print(f"[CONCEPT_MAP] ‚úÖ Extracted for '{main_keyword}': "
              f"{len(concept_map.get('relationships', []))} relationships, "
              f"{len(concept_map.get('proximity_clusters', []))} clusters")
        
        return {
            "status": "OK",
            "concept_map": concept_map
        }
        
    except json.JSONDecodeError as e:
        print(f"[CONCEPT_MAP] ‚ö†Ô∏è JSON parse error: {e}")
        return {
            "status": "JSON_ERROR",
            "error": str(e),
            "concept_map": get_fallback_concept_map(main_keyword)
        }
    except Exception as e:
        print(f"[CONCEPT_MAP] ‚ö†Ô∏è Error: {e}")
        return {
            "status": "ERROR",
            "error": str(e),
            "concept_map": get_fallback_concept_map(main_keyword)
        }


def validate_concept_map(concept_map: Dict, main_keyword: str) -> Dict:
    """Waliduje i uzupe≈Çnia brakujƒÖce pola w concept_map."""
    
    # Wymagane klucze z domy≈õlnymi warto≈õciami
    defaults = {
        "main_entity": {
            "name": main_keyword,
            "type": "Thing",
            "definition": f"Artyku≈Ç o temacie: {main_keyword}"
        },
        "supporting_entities": {
            "tools": [],
            "processes": [],
            "attributes": [],
            "locations": [],
            "certifications": [],
            "related_services": []
        },
        "relationships": [],
        "classification_triplet": {
            "service_type": main_keyword.split()[0] if main_keyword else "",
            "context": main_keyword.split()[-1] if len(main_keyword.split()) > 1 else "",
            "main_attribute": "profesjonalny"
        },
        "proximity_clusters": [],
        "semantic_confidence_terms": []
    }
    
    # Uzupe≈Çnij brakujƒÖce klucze
    for key, default_value in defaults.items():
        if key not in concept_map:
            concept_map[key] = default_value
        elif isinstance(default_value, dict):
            for sub_key, sub_default in default_value.items():
                if sub_key not in concept_map[key]:
                    concept_map[key][sub_key] = sub_default
    
    return concept_map


def get_fallback_concept_map(main_keyword: str) -> Dict:
    """Fallback gdy Gemini zawiedzie - generuje podstawowƒÖ mapƒô."""
    
    words = main_keyword.lower().split()
    
    return {
        "main_entity": {
            "name": main_keyword,
            "type": "Thing",
            "definition": f"Artyku≈Ç o temacie: {main_keyword}"
        },
        "supporting_entities": {
            "tools": [],
            "processes": [],
            "attributes": ["profesjonalny", "do≈õwiadczony"],
            "locations": [w for w in words if len(w) > 4],
            "certifications": [],
            "related_services": []
        },
        "relationships": [],
        "classification_triplet": {
            "service_type": words[0] if words else "",
            "context": words[-1] if len(words) > 1 else "",
            "main_attribute": "profesjonalny"
        },
        "proximity_clusters": [],
        "semantic_confidence_terms": []
    }


def flatten_supporting_entities(supporting_entities: Dict) -> List[str]:
    """Sp≈Çaszcza s≈Çownik encji wspierajƒÖcych do listy."""
    all_entities = []
    for category, entities in supporting_entities.items():
        if isinstance(entities, list):
            all_entities.extend(entities)
    return list(set(all_entities))  # usu≈Ñ duplikaty


# ============================================================================
# DODATKOWE FUNKCJE POMOCNICZE
# ============================================================================

def get_proximity_instructions(proximity_clusters: List[Dict]) -> List[str]:
    """Generuje instrukcje tekstowe dla GPT na podstawie proximity_clusters."""
    instructions = []
    
    for cluster in proximity_clusters:
        anchor = cluster.get("anchor", "")
        nearby = cluster.get("must_have_nearby", [])
        max_dist = cluster.get("max_distance", 25)
        
        if anchor and nearby:
            nearby_str = ", ".join(nearby[:5])
            instructions.append(
                f"Gdy u≈ºyjesz '{anchor}', w promieniu {max_dist} s≈Ç√≥w "
                f"MUSZƒÑ pojawiƒá siƒô min. 2 z: [{nearby_str}]"
            )
    
    return instructions


def format_concept_map_for_gpt(concept_map: Dict, batch_number: int = 1) -> str:
    """Formatuje concept_map jako instrukcje tekstowe dla GPT."""
    
    lines = []
    
    # Main entity
    main_entity = concept_map.get("main_entity", {})
    if main_entity.get("name"):
        lines.append(f"üìå ENCJA G≈Å√ìWNA: {main_entity['name']} ({main_entity.get('type', 'Thing')})")
    
    # Supporting entities
    supporting = concept_map.get("supporting_entities", {})
    flat_entities = flatten_supporting_entities(supporting)
    if flat_entities:
        lines.append(f"\nüìö ENCJE WSPIERAJƒÑCE (u≈ºyj min. 3-4 w batchu):")
        lines.append(", ".join(flat_entities[:12]))
    
    # Proximity rules
    proximity = concept_map.get("proximity_clusters", [])
    if proximity:
        lines.append(f"\nüîó ZASADY BLISKO≈öCI SEMANTYCZNEJ:")
        for instr in get_proximity_instructions(proximity):
            lines.append(f"  ‚Ä¢ {instr}")
    
    # Lead paragraph (tylko dla batch 1)
    if batch_number == 1:
        triplet = concept_map.get("classification_triplet", {})
        if any(triplet.values()):
            lines.append(f"\nüéØ Z≈ÅOTY AKAPIT (pierwsze 100 s≈Ç√≥w MUSI zawieraƒá):")
            lines.append(f"  [{triplet.get('service_type', '?')}] + "
                        f"[{triplet.get('context', '?')}] + "
                        f"[{triplet.get('main_attribute', '?')}]")
    
    # Semantic confidence terms
    confidence = concept_map.get("semantic_confidence_terms", [])
    if confidence:
        lines.append(f"\nüíé FRAZY EKSPERCKIE (u≈ºyj 1-2 w batchu):")
        lines.append(", ".join(confidence[:5]))
    
    return "\n".join(lines)


# ============================================================================
# TEST
# ============================================================================

if __name__ == "__main__":
    # Test z przyk≈Çadowymi danymi
    test_keyword = "przeprowadzki warszawa"
    test_texts = [
        "Przeprowadzki w Warszawie to us≈Çuga wymagajƒÖca do≈õwiadczenia. "
        "Profesjonalna firma przeprowadzkowa oferuje pakowanie, transport mebli "
        "i roz≈Çadunek. Ubezpieczenie OCP chroni przed szkodami.",
        
        "Transport mebli w Warszawie wymaga windy meblowej do ciƒô≈ºkich przedmiot√≥w. "
        "Fortepian wymaga specjalnych pas√≥w transportowych i do≈õwiadczonej ekipy."
    ]
    
    result = extract_concept_map(test_keyword, test_texts)
    print("\n" + "="*60)
    print("CONCEPT MAP RESULT:")
    print("="*60)
    print(json.dumps(result, indent=2, ensure_ascii=False))
    
    print("\n" + "="*60)
    print("GPT INSTRUCTIONS:")
    print("="*60)
    print(format_concept_map_for_gpt(result["concept_map"], batch_number=1))
