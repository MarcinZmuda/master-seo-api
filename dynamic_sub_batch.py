"""
===============================================================================
ğŸ”€ DYNAMIC SUB-BATCH SPLITTER v1.0
===============================================================================
Automatyczny podziaÅ‚ H2 na sub-batche gdy za duÅ¼o elementÃ³w.

PROBLEM:
- H2 "Procedura sÄ…dowa" ma przypisane 15 fraz kluczowych
- UpchniÄ™cie ich w jednym batchu (nawet LONG) = stuffing
- Max 5 MUST phrases per instrukcja = reszta pominiÄ™ta

ROZWIÄ„ZANIE:
- Przed generowaniem sprawdÅº "gÄ™stoÅ›Ä‡" elementÃ³w
- JeÅ›li > 8 fraz LUB > 3 encje â†’ podziel H2 na sub-batche
- Batch 3 â†’ Batch 3A (first half) + Batch 3B (second half)
- Automatycznie generuj H3 jako pod-wÄ…tki

ZYSK:
- Agent ma 2x wiÄ™cej miejsca na naturalne uÅ¼ycie fraz
- Drastycznie podnosi Human Score
- Pozwala uÅ¼yÄ‡ WSZYSTKIE frazy EXTENDED

===============================================================================
"""

import math
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass, field


@dataclass
class SubBatchConfig:
    """Konfiguracja sub-batchÃ³w."""
    # Progi do podziaÅ‚u
    MAX_PHRASES_PER_BATCH: int = 8
    MAX_ENTITIES_PER_BATCH: int = 3
    MAX_TRIPLETS_PER_BATCH: int = 2
    
    # Minimalna liczba elementÃ³w do podziaÅ‚u
    MIN_ELEMENTS_TO_SPLIT: int = 6
    
    # Max sub-batchÃ³w per H2
    MAX_SUB_BATCHES: int = 3


@dataclass
class SubBatch:
    """Pojedynczy sub-batch."""
    parent_h2: str
    sub_batch_id: str  # "3A", "3B", etc.
    h3_title: str
    assigned_phrases: List[Dict]
    assigned_entities: List[Dict]
    assigned_triplets: List[Dict]
    word_target: Tuple[int, int]  # (min, max)
    
    @property
    def total_elements(self) -> int:
        return len(self.assigned_phrases) + len(self.assigned_entities) + len(self.assigned_triplets)


@dataclass 
class SplitResult:
    """Wynik podziaÅ‚u H2."""
    original_h2: str
    needs_split: bool
    sub_batches: List[SubBatch] = field(default_factory=list)
    reason: str = ""
    stats: Dict = field(default_factory=dict)


CONFIG = SubBatchConfig()


# ============================================================================
# ANALIZA GÄ˜STOÅšCI
# ============================================================================

def analyze_h2_density(
    h2_title: str,
    assigned_phrases: List[Dict],
    assigned_entities: List[Dict],
    assigned_triplets: List[Dict]
) -> Dict:
    """
    Analizuje "gÄ™stoÅ›Ä‡" elementÃ³w przypisanych do H2.
    
    Returns:
        {
            "needs_split": True/False,
            "density_score": float,  # 0-1, >0.7 = needs split
            "total_elements": int,
            "recommended_sub_batches": int,
            "bottleneck": "phrases" | "entities" | "triplets" | None
        }
    """
    total_phrases = len(assigned_phrases)
    total_entities = len(assigned_entities)
    total_triplets = len(assigned_triplets)
    total_elements = total_phrases + total_entities + total_triplets
    
    # Oblicz "przepeÅ‚nienie" dla kaÅ¼dej kategorii
    phrase_overflow = max(0, total_phrases - CONFIG.MAX_PHRASES_PER_BATCH) / CONFIG.MAX_PHRASES_PER_BATCH
    entity_overflow = max(0, total_entities - CONFIG.MAX_ENTITIES_PER_BATCH) / CONFIG.MAX_ENTITIES_PER_BATCH
    triplet_overflow = max(0, total_triplets - CONFIG.MAX_TRIPLETS_PER_BATCH) / CONFIG.MAX_TRIPLETS_PER_BATCH
    
    # Density score: Å›rednia waÅ¼ona przepeÅ‚nieÅ„
    density_score = (
        phrase_overflow * 0.5 +   # Frazy najwaÅ¼niejsze
        entity_overflow * 0.3 +   # Encje drugie
        triplet_overflow * 0.2    # Triplety trzecie
    )
    
    # ZnajdÅº bottleneck
    bottleneck = None
    if phrase_overflow > 0:
        bottleneck = "phrases"
    elif entity_overflow > 0:
        bottleneck = "entities"
    elif triplet_overflow > 0:
        bottleneck = "triplets"
    
    # Ile sub-batchÃ³w potrzeba?
    recommended = 1
    if total_phrases > CONFIG.MAX_PHRASES_PER_BATCH:
        recommended = max(recommended, math.ceil(total_phrases / CONFIG.MAX_PHRASES_PER_BATCH))
    if total_entities > CONFIG.MAX_ENTITIES_PER_BATCH:
        recommended = max(recommended, math.ceil(total_entities / CONFIG.MAX_ENTITIES_PER_BATCH))
    
    recommended = min(recommended, CONFIG.MAX_SUB_BATCHES)
    
    # Decyzja o podziale
    needs_split = (
        density_score > 0.3 or
        total_elements > CONFIG.MIN_ELEMENTS_TO_SPLIT * 1.5 or
        total_phrases > CONFIG.MAX_PHRASES_PER_BATCH
    )
    
    return {
        "needs_split": needs_split,
        "density_score": round(density_score, 2),
        "total_elements": total_elements,
        "element_counts": {
            "phrases": total_phrases,
            "entities": total_entities,
            "triplets": total_triplets
        },
        "recommended_sub_batches": recommended,
        "bottleneck": bottleneck
    }


# ============================================================================
# GENEROWANIE H3 (POD-WÄ„TKÃ“W)
# ============================================================================

def generate_h3_titles(h2_title: str, num_sub_batches: int, domain: str = "prawo") -> List[str]:
    """
    Generuje tytuÅ‚y H3 na podstawie H2.
    
    Strategie:
    1. Rozdziel na aspekty (teoretyczny vs praktyczny)
    2. Rozdziel chronologicznie (przed, w trakcie, po)
    3. Rozdziel na elementy (co, jak, kiedy)
    """
    h2_lower = h2_title.lower()
    
    # Strategia 1: Aspekty (dla definicji, pojÄ™Ä‡)
    if any(w in h2_lower for w in ["czym jest", "definicja", "pojÄ™cie", "co to"]):
        return [
            f"Definicja i podstawy prawne",
            f"Praktyczne zastosowanie"
        ][:num_sub_batches]
    
    # Strategia 2: Chronologiczna (dla procedur)
    if any(w in h2_lower for w in ["procedur", "postÄ™powan", "jak", "krok"]):
        chronological = [
            f"Przygotowanie i pierwsze kroki",
            f"Przebieg postÄ™powania",
            f"ZakoÅ„czenie i skutki"
        ]
        return chronological[:num_sub_batches]
    
    # Strategia 3: Elementy (dla odpowiedzialnoÅ›ci, konsekwencji)
    if any(w in h2_lower for w in ["odpowiedzialn", "kar", "konsekwen", "skutk"]):
        return [
            f"Rodzaje i zakres odpowiedzialnoÅ›ci",
            f"PrzesÅ‚anki i okolicznoÅ›ci"
        ][:num_sub_batches]
    
    # Strategia 4: Podmioty (dla spraw rodzinnych)
    if any(w in h2_lower for w in ["rodzic", "dziec", "opiek"]):
        return [
            f"Perspektywa prawna",
            f"Aspekty praktyczne i psychologiczne"
        ][:num_sub_batches]
    
    # DomyÅ›lna strategia: numeracja
    return [
        f"{h2_title} - czÄ™Å›Ä‡ {i+1}"
        for i in range(num_sub_batches)
    ]


# ============================================================================
# PODZIAÅ ELEMENTÃ“W NA SUB-BATCHE
# ============================================================================

def distribute_elements_to_sub_batches(
    phrases: List[Dict],
    entities: List[Dict],
    triplets: List[Dict],
    num_sub_batches: int
) -> List[Dict]:
    """
    Rozdziela elementy rÃ³wnomiernie na sub-batche.
    
    Strategia:
    1. Sortuj frazy po importance/relevance
    2. Rozdziel round-robin z priorytetem BASIC > EXTENDED
    3. Encje i triplety dopasuj do fraz (semantic matching)
    """
    # Sortuj frazy: BASIC nieuÅ¼yte > BASIC uÅ¼yte > EXTENDED
    def phrase_priority(p):
        ptype = p.get("type", "EXTENDED").upper()
        actual = p.get("actual_uses", 0)
        relevance = p.get("relevance", 0)
        
        if ptype == "BASIC" and actual == 0:
            return (0, -relevance)
        if ptype == "BASIC":
            return (1, -relevance)
        return (2, -relevance)
    
    sorted_phrases = sorted(phrases, key=phrase_priority)
    
    # Rozdziel frazy round-robin
    phrase_buckets = [[] for _ in range(num_sub_batches)]
    for i, phrase in enumerate(sorted_phrases):
        bucket_idx = i % num_sub_batches
        phrase_buckets[bucket_idx].append(phrase)
    
    # Rozdziel encje rÃ³wnomiernie
    entity_buckets = [[] for _ in range(num_sub_batches)]
    for i, entity in enumerate(entities):
        bucket_idx = i % num_sub_batches
        entity_buckets[bucket_idx].append(entity)
    
    # Rozdziel triplety rÃ³wnomiernie
    triplet_buckets = [[] for _ in range(num_sub_batches)]
    for i, triplet in enumerate(triplets):
        bucket_idx = i % num_sub_batches
        triplet_buckets[bucket_idx].append(triplet)
    
    return [
        {
            "phrases": phrase_buckets[i],
            "entities": entity_buckets[i],
            "triplets": triplet_buckets[i]
        }
        for i in range(num_sub_batches)
    ]


# ============================================================================
# GÅÃ“WNA FUNKCJA: SPLIT H2
# ============================================================================

def split_h2_if_needed(
    h2_title: str,
    batch_number: int,
    assigned_phrases: List[Dict],
    assigned_entities: List[Dict],
    assigned_triplets: List[Dict],
    target_words_per_batch: Tuple[int, int] = (400, 600),
    domain: str = "prawo"
) -> SplitResult:
    """
    Analizuje H2 i dzieli na sub-batche jeÅ›li potrzeba.
    
    Args:
        h2_title: TytuÅ‚ H2
        batch_number: Numer oryginalnego batcha
        assigned_phrases: Frazy przypisane do tego H2
        assigned_entities: Encje przypisane do tego H2
        assigned_triplets: Triplety przypisane do tego H2
        target_words_per_batch: Cel dÅ‚ugoÅ›ci batcha
        domain: Domena
    
    Returns:
        SplitResult z listÄ… SubBatch (1 jeÅ›li bez podziaÅ‚u, >1 jeÅ›li podzielony)
    """
    # 1. Analiza gÄ™stoÅ›ci
    density = analyze_h2_density(
        h2_title=h2_title,
        assigned_phrases=assigned_phrases,
        assigned_entities=assigned_entities,
        assigned_triplets=assigned_triplets
    )
    
    # 2. SprawdÅº czy potrzebny podziaÅ‚
    if not density["needs_split"]:
        # Bez podziaÅ‚u - zwrÃ³Ä‡ jeden "sub-batch" = oryginalny batch
        return SplitResult(
            original_h2=h2_title,
            needs_split=False,
            sub_batches=[
                SubBatch(
                    parent_h2=h2_title,
                    sub_batch_id=str(batch_number),
                    h3_title="",  # Brak H3 bo nie ma podziaÅ‚u
                    assigned_phrases=assigned_phrases,
                    assigned_entities=assigned_entities,
                    assigned_triplets=assigned_triplets,
                    word_target=target_words_per_batch
                )
            ],
            reason="Density OK, no split needed",
            stats=density
        )
    
    # 3. OkreÅ›l liczbÄ™ sub-batchÃ³w
    num_sub_batches = density["recommended_sub_batches"]
    
    # 4. Wygeneruj H3
    h3_titles = generate_h3_titles(h2_title, num_sub_batches, domain)
    
    # 5. Rozdziel elementy
    element_distribution = distribute_elements_to_sub_batches(
        phrases=assigned_phrases,
        entities=assigned_entities,
        triplets=assigned_triplets,
        num_sub_batches=num_sub_batches
    )
    
    # 6. Oblicz target words per sub-batch (proporcjonalnie mniejszy)
    sub_batch_words = (
        target_words_per_batch[0] // num_sub_batches + 50,
        target_words_per_batch[1] // num_sub_batches + 100
    )
    # Minimum 200 sÅ‚Ã³w
    sub_batch_words = (max(200, sub_batch_words[0]), max(300, sub_batch_words[1]))
    
    # 7. UtwÃ³rz sub-batche
    sub_batches = []
    sub_batch_letters = "ABCDEFGHIJ"
    
    for i in range(num_sub_batches):
        sub_batch_id = f"{batch_number}{sub_batch_letters[i]}"
        
        sub_batches.append(SubBatch(
            parent_h2=h2_title,
            sub_batch_id=sub_batch_id,
            h3_title=h3_titles[i] if i < len(h3_titles) else f"CzÄ™Å›Ä‡ {i+1}",
            assigned_phrases=element_distribution[i]["phrases"],
            assigned_entities=element_distribution[i]["entities"],
            assigned_triplets=element_distribution[i]["triplets"],
            word_target=sub_batch_words
        ))
    
    return SplitResult(
        original_h2=h2_title,
        needs_split=True,
        sub_batches=sub_batches,
        reason=f"High density ({density['density_score']}), bottleneck: {density['bottleneck']}",
        stats=density
    )


# ============================================================================
# INTEGRACJA Z BATCH PLANNER
# ============================================================================

def process_batch_plan_with_splitting(
    batch_plan: List[Dict],
    phrase_assignments: Dict[str, List[Dict]],
    entity_assignments: Dict[str, List[Dict]],
    triplet_assignments: Dict[str, List[Dict]],
    domain: str = "prawo"
) -> List[Dict]:
    """
    Przetwarza plan batchÃ³w i dzieli H2 gdzie potrzeba.
    
    Args:
        batch_plan: Oryginalny plan batchÃ³w
        phrase_assignments: Przypisanie fraz do H2
        entity_assignments: Przypisanie encji do H2
        triplet_assignments: Przypisanie tripletÃ³w do H2
        domain: Domena
    
    Returns:
        Nowy plan batchÃ³w z sub-batchami
    """
    new_plan = []
    
    for batch in batch_plan:
        batch_number = batch.get("batch_number", len(new_plan) + 1)
        h2_sections = batch.get("h2_sections", [])
        
        # Batch bez H2 (intro) - przepuÅ›Ä‡ bez zmian
        if not h2_sections:
            new_plan.append(batch)
            continue
        
        # Dla kaÅ¼dego H2 w batchu
        for h2_title in h2_sections:
            phrases = phrase_assignments.get(h2_title, [])
            entities = entity_assignments.get(h2_title, [])
            triplets = triplet_assignments.get(h2_title, [])
            
            # SprawdÅº czy potrzebny podziaÅ‚
            split_result = split_h2_if_needed(
                h2_title=h2_title,
                batch_number=batch_number,
                assigned_phrases=phrases,
                assigned_entities=entities,
                assigned_triplets=triplets,
                target_words_per_batch=(
                    batch.get("words_min", 400),
                    batch.get("words_max", 600)
                ),
                domain=domain
            )
            
            # Dodaj sub-batche do planu
            for sub_batch in split_result.sub_batches:
                new_plan.append({
                    "batch_number": sub_batch.sub_batch_id,
                    "batch_type": "CONTENT",
                    "h2_sections": [sub_batch.parent_h2],
                    "h3_title": sub_batch.h3_title if split_result.needs_split else None,
                    "is_sub_batch": split_result.needs_split,
                    "parent_batch": batch_number if split_result.needs_split else None,
                    "assigned_phrases": sub_batch.assigned_phrases,
                    "assigned_entities": sub_batch.assigned_entities,
                    "assigned_triplets": sub_batch.assigned_triplets,
                    "words_min": sub_batch.word_target[0],
                    "words_max": sub_batch.word_target[1],
                    "split_stats": split_result.stats if split_result.needs_split else None
                })
    
    return new_plan


# ============================================================================
# TEST
# ============================================================================

if __name__ == "__main__":
    print("=" * 60)
    print("TEST: DYNAMIC SUB-BATCH SPLITTER")
    print("=" * 60)
    
    # Test 1: H2 z maÅ‚Ä… gÄ™stoÅ›ciÄ… (bez podziaÅ‚u)
    print("\nğŸ“ Test 1: MaÅ‚a gÄ™stoÅ›Ä‡ (5 fraz)")
    result1 = split_h2_if_needed(
        h2_title="Czym jest porwanie rodzicielskie",
        batch_number=2,
        assigned_phrases=[
            {"keyword": "porwanie rodzicielskie", "type": "BASIC"},
            {"keyword": "definicja", "type": "EXTENDED"},
            {"keyword": "rodzic", "type": "EXTENDED"},
            {"keyword": "dziecko", "type": "EXTENDED"},
            {"keyword": "prawo", "type": "EXTENDED"},
        ],
        assigned_entities=[{"name": "sÄ…d rodzinny"}],
        assigned_triplets=[{"subject": "rodzic", "verb": "zabiera", "object": "dziecko"}]
    )
    
    print(f"   Needs split: {result1.needs_split}")
    print(f"   Sub-batches: {len(result1.sub_batches)}")
    print(f"   Reason: {result1.reason}")
    
    # Test 2: H2 z duÅ¼Ä… gÄ™stoÅ›ciÄ… (wymaga podziaÅ‚u)
    print("\nğŸ“ Test 2: DuÅ¼a gÄ™stoÅ›Ä‡ (12 fraz, 4 encje)")
    result2 = split_h2_if_needed(
        h2_title="Procedura sÄ…dowa w sprawach o miejsce pobytu dziecka",
        batch_number=3,
        assigned_phrases=[
            {"keyword": f"fraza_{i}", "type": "BASIC" if i < 5 else "EXTENDED"}
            for i in range(12)
        ],
        assigned_entities=[
            {"name": "sÄ…d rodzinny"},
            {"name": "kurator"},
            {"name": "biegÅ‚y"},
            {"name": "peÅ‚nomocnik"},
        ],
        assigned_triplets=[
            {"subject": "sÄ…d", "verb": "ustala", "object": "miejsce pobytu"},
            {"subject": "kurator", "verb": "bada", "object": "sytuacjÄ™"},
        ]
    )
    
    print(f"   Needs split: {result2.needs_split}")
    print(f"   Sub-batches: {len(result2.sub_batches)}")
    print(f"   Reason: {result2.reason}")
    print(f"   Density score: {result2.stats.get('density_score')}")
    
    if result2.needs_split:
        print(f"\n   Sub-batch details:")
        for sb in result2.sub_batches:
            print(f"     â€¢ {sb.sub_batch_id}: H3='{sb.h3_title}'")
            print(f"       Phrases: {len(sb.assigned_phrases)}, Entities: {len(sb.assigned_entities)}")
