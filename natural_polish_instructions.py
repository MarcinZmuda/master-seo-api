"""
===============================================================================
üáµüá± NATURAL POLISH INSTRUCTIONS v1.0
===============================================================================
RozwiƒÖzuje problem keyword stuffingu przez:

1. INFORMACJƒò O FLEKSJI - agent wie ≈ºe formy odmiany sƒÖ liczone
2. MINIMUM SPACING - fraza nie mo≈ºe byƒá zbyt blisko poprzedniego u≈ºycia
3. SYNONYM ROTATION - wymusza r√≥≈ºnorodno≈õƒá form
4. REPETITION DETECTOR - wykrywa nienaturalne powt√≥rzenia

INTEGRACJA:
- Dodaj do smart_batch_instructions.py
- Dodaj do pre_batch_info response
===============================================================================
"""

import re
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass


# ============================================================================
# KONFIGURACJA
# ============================================================================

# Minimalna odleg≈Ço≈õƒá (w s≈Çowach) miƒôdzy powt√≥rzeniami tej samej frazy
MINIMUM_SPACING = {
    "MAIN": 60,      # Fraza g≈Ç√≥wna - co ~60 s≈Ç√≥w OK
    "BASIC": 80,     # BASIC - co ~80 s≈Ç√≥w
    "EXTENDED": 120  # EXTENDED - co ~120 s≈Ç√≥w
}

# Maksymalny % exact match (reszta musi byƒá odmianami/synonimami)
MAX_EXACT_MATCH_RATIO = 0.50  # Max 50% mo≈ºe byƒá identyczne

# Pr√≥g wykrywania stuffingu (frazy w jednym akapicie)
STUFFING_THRESHOLD = 2  # Max 2x ta sama fraza w jednym akapicie


# ============================================================================
# FLEKSJA INFO - dodaj do instrukcji dla agenta
# ============================================================================

FLEKSJA_INSTRUCTION_PL = """
üîÑ FORMY FLEKSYJNE LICZƒÑ SIƒò AUTOMATYCZNIE!
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
System automatycznie rozpoznaje WSZYSTKIE odmiany jako to samo s≈Çowo:

‚úÖ "zesp√≥≈Ç turnera" = "zespo≈Çu turnera" = "zespo≈Çem turnera" = "zespole turnera"
‚úÖ "sƒÖd rodzinny" = "sƒÖdu rodzinnego" = "sƒÖdem rodzinnym" = "sƒÖdzie rodzinnym"

‚ö° CO TO ZNACZY DLA CIEBIE:
‚Ä¢ Pisz NATURALNIE po polsku
‚Ä¢ U≈ºywaj r√≥≈ºnych przypadk√≥w gramatycznych
‚Ä¢ NIE MUSISZ powtarzaƒá frazy w formie podstawowej
‚Ä¢ System zaliczy "zespo≈Çu turnera" jako u≈ºycie frazy "zesp√≥≈Ç turnera"

‚ùå ≈πLE (keyword stuffing):
"Zesp√≥≈Ç Turnera jest chorobƒÖ. Zesp√≥≈Ç Turnera dotyka kobiet. Zesp√≥≈Ç Turnera wymaga..."

‚úÖ DOBRZE (naturalny polski):
"Zesp√≥≈Ç Turnera jest chorobƒÖ genetycznƒÖ. Osoby dotkniƒôte tym zespo≈Çem wymagajƒÖ 
specjalistycznej opieki. W przypadku zespo≈Çu Turnera kluczowa jest wczesna diagnoza."
"""

FLEKSJA_INSTRUCTION_SHORT = """
üîÑ FLEKSJA: Odmiany frazy liczƒÖ siƒô jako jedno u≈ºycie!
   "zesp√≥≈Ç turnera" = "zespo≈Çu turnera" = "zespo≈Çem turnera"
   Pisz naturalnie, u≈ºywaj r√≥≈ºnych przypadk√≥w.
"""


# ============================================================================
# SPACING VALIDATOR - wykrywa zbyt bliskie powt√≥rzenia
# ============================================================================

@dataclass
class SpacingViolation:
    """Naruszenie minimalnego odstƒôpu miƒôdzy frazami."""
    phrase: str
    position1: int
    position2: int
    distance: int
    min_required: int
    suggestion: str


def find_phrase_positions(text: str, phrase: str) -> List[int]:
    """
    Znajduje pozycje (w s≈Çowach) gdzie wystƒôpuje fraza.
    Uwzglƒôdnia formy fleksyjne poprzez proste dopasowanie.
    """
    if not text or not phrase:
        return []
    
    text_lower = text.lower()
    phrase_lower = phrase.lower()
    
    # Tokenizuj tekst na s≈Çowa z pozycjami
    words = re.findall(r'\b\w+\b', text_lower)
    
    # Szukaj frazy (mo≈ºe byƒá wielowyrazowa)
    phrase_words = phrase_lower.split()
    phrase_len = len(phrase_words)
    
    positions = []
    
    # Proste dopasowanie (dla pe≈Çnej wersji u≈ºyj lemmatyzacji)
    for i in range(len(words) - phrase_len + 1):
        window = words[i:i + phrase_len]
        
        # Sprawd≈∫ czy pasuje (z tolerancjƒÖ na ko≈Ñc√≥wki fleksyjne)
        match = True
        for pw, tw in zip(phrase_words, window):
            # Prosta heurystyka: 4 pierwsze litery muszƒÖ siƒô zgadzaƒá
            if len(pw) >= 4 and len(tw) >= 4:
                if pw[:4] != tw[:4]:
                    match = False
                    break
            elif pw != tw:
                match = False
                break
        
        if match:
            positions.append(i)
    
    return positions


def check_phrase_spacing(
    text: str, 
    phrase: str, 
    phrase_type: str = "BASIC"
) -> Tuple[bool, Optional[SpacingViolation]]:
    """
    Sprawdza czy fraza nie wystƒôpuje zbyt blisko poprzedniego u≈ºycia.
    
    Returns:
        (is_ok, violation_or_none)
    """
    min_spacing = MINIMUM_SPACING.get(phrase_type.upper(), 80)
    
    positions = find_phrase_positions(text, phrase)
    
    if len(positions) < 2:
        return True, None
    
    # Sprawd≈∫ odleg≈Ço≈õci miƒôdzy kolejnymi wystƒÖpieniami
    for i in range(1, len(positions)):
        distance = positions[i] - positions[i-1]
        
        if distance < min_spacing:
            return False, SpacingViolation(
                phrase=phrase,
                position1=positions[i-1],
                position2=positions[i],
                distance=distance,
                min_required=min_spacing,
                suggestion=f"U≈ºyj synonimu lub odmiany zamiast powtarzaƒá '{phrase}' - odstƒôp {distance} s≈Ç√≥w jest za ma≈Çy (min {min_spacing})"
            )
    
    return True, None


def validate_all_spacing(
    text: str, 
    keywords_state: Dict[str, dict]
) -> List[SpacingViolation]:
    """
    Sprawdza spacing dla wszystkich fraz w tek≈õcie.
    
    Returns:
        Lista narusze≈Ñ (pusta = wszystko OK)
    """
    violations = []
    
    for rid, meta in keywords_state.items():
        phrase = meta.get("keyword", "").strip()
        phrase_type = meta.get("type", "BASIC").upper()
        
        if not phrase:
            continue
        
        is_ok, violation = check_phrase_spacing(text, phrase, phrase_type)
        if not is_ok and violation:
            violations.append(violation)
    
    return violations


# ============================================================================
# REPETITION DETECTOR - wykrywa nienaturalne powt√≥rzenia
# ============================================================================

def detect_paragraph_stuffing(text: str, phrase: str, threshold: int = 2) -> List[str]:
    """
    Wykrywa stuffing w pojedynczych akapitach.
    
    Returns:
        Lista ostrze≈ºe≈Ñ (pusta = OK)
    """
    warnings = []
    
    # Podziel na akapity
    paragraphs = re.split(r'\n\s*\n|\n', text)
    
    for i, para in enumerate(paragraphs):
        if not para.strip():
            continue
        
        positions = find_phrase_positions(para, phrase)
        
        if len(positions) > threshold:
            warnings.append(
                f"Akapit {i+1}: Fraza '{phrase}' wystƒôpuje {len(positions)}x "
                f"(max {threshold}x na akapit) - roz≈Ç√≥≈º na wiƒôcej akapit√≥w"
            )
    
    return warnings


def detect_sentence_repetition(text: str, phrase: str) -> List[str]:
    """
    Wykrywa powt√≥rzenia w tym samym zdaniu.
    
    Returns:
        Lista ostrze≈ºe≈Ñ
    """
    warnings = []
    
    # Podziel na zdania
    sentences = re.split(r'[.!?]+', text)
    
    for i, sent in enumerate(sentences):
        if not sent.strip():
            continue
        
        positions = find_phrase_positions(sent, phrase)
        
        if len(positions) > 1:
            warnings.append(
                f"Zdanie {i+1}: Fraza '{phrase}' wystƒôpuje {len(positions)}x "
                f"w jednym zdaniu - to brzmi nienaturalnie"
            )
    
    return warnings


# ============================================================================
# INSTRUKCJE DLA AGENTA - format dla pre_batch_info
# ============================================================================

def generate_natural_writing_instructions(
    keywords_state: Dict[str, dict],
    previous_batch_text: str = ""
) -> Dict:
    """
    Generuje instrukcje naturalnego pisania dla agenta.
    
    Dodaj wynik do pre_batch_info jako "natural_writing_instructions".
    """
    instructions = {
        "fleksja_info": FLEKSJA_INSTRUCTION_SHORT,
        "spacing_rules": [],
        "avoid_repetition": [],
        "general_tips": []
    }
    
    # Spacing rules dla ka≈ºdej frazy
    for rid, meta in keywords_state.items():
        phrase = meta.get("keyword", "").strip()
        phrase_type = meta.get("type", "BASIC").upper()
        
        if not phrase:
            continue
        
        min_spacing = MINIMUM_SPACING.get(phrase_type, 80)
        
        instructions["spacing_rules"].append({
            "phrase": phrase,
            "type": phrase_type,
            "min_spacing": min_spacing,
            "rule": f"'{phrase}' - min {min_spacing} s≈Ç√≥w miƒôdzy u≈ºyciami"
        })
    
    # Je≈õli mamy poprzedni batch, sprawd≈∫ ko≈Ñc√≥wkƒô
    if previous_batch_text:
        # Sprawd≈∫ ostatnie 50 s≈Ç√≥w poprzedniego batcha
        last_words = previous_batch_text.split()[-50:]
        last_text = " ".join(last_words)
        
        for rid, meta in keywords_state.items():
            phrase = meta.get("keyword", "").strip()
            if not phrase:
                continue
            
            positions = find_phrase_positions(last_text, phrase)
            if positions:
                last_pos = positions[-1]
                words_ago = 50 - last_pos
                
                if words_ago < 30:
                    instructions["avoid_repetition"].append({
                        "phrase": phrase,
                        "warning": f"'{phrase}' by≈Ça u≈ºyta {words_ago} s≈Ç√≥w temu (na ko≈Ñcu poprzedniego batcha)",
                        "suggestion": f"Zacznij ten batch BEZ '{phrase}' - u≈ºyj synonimu lub poczekaj ~{MINIMUM_SPACING.get(meta.get('type', 'BASIC').upper(), 80) - words_ago} s≈Ç√≥w"
                    })
    
    # General tips
    instructions["general_tips"] = [
        "U≈ºywaj R√ì≈ªNYCH przypadk√≥w gramatycznych (mianownik, dope≈Çniacz, biernik...)",
        "Synonim lub opis zamiast powt√≥rzenia: 'ta choroba', 'omawiany zesp√≥≈Ç', 'to schorzenie'",
        "Rozk≈Çadaj frazy r√≥wnomiernie w tek≈õcie, nie grupuj na poczƒÖtku/ko≈Ñcu",
        "Jeden akapit = max 2 u≈ºycia tej samej frazy"
    ]
    
    return instructions


def format_natural_instructions_for_prompt(instructions: Dict) -> str:
    """
    Formatuje instrukcje do dodania do promptu dla agenta.
    """
    lines = []
    
    lines.append("\n" + "=" * 60)
    lines.append("üáµüá± NATURALNY POLSKI - JAK PISAƒÜ")
    lines.append("=" * 60)
    
    # Fleksja info
    lines.append(instructions["fleksja_info"])
    
    # Spacing rules (podsumowanie)
    if instructions["spacing_rules"]:
        lines.append("\nüìè ODSTƒòPY MIƒòDZY POWT√ìRZENIAMI:")
        for rule in instructions["spacing_rules"][:5]:  # Max 5
            lines.append(f"   ‚Ä¢ {rule['rule']}")
    
    # Avoid repetition (wa≈ºne!)
    if instructions["avoid_repetition"]:
        lines.append("\n‚ö†Ô∏è UWAGA - UNIKAJ NA POCZƒÑTKU TEGO BATCHA:")
        for item in instructions["avoid_repetition"]:
            lines.append(f"   ‚Ä¢ {item['warning']}")
            lines.append(f"     ‚Üí {item['suggestion']}")
    
    # General tips
    lines.append("\nüí° WSKAZ√ìWKI:")
    for tip in instructions["general_tips"]:
        lines.append(f"   ‚Ä¢ {tip}")
    
    return "\n".join(lines)


# ============================================================================
# WALIDACJA POST-BATCH - sprawd≈∫ przed zatwierdzeniem
# ============================================================================

def validate_natural_writing(
    text: str,
    keywords_state: Dict[str, dict],
    previous_batch_text: str = ""
) -> Dict:
    """
    Waliduje czy tekst jest napisany naturalnie.
    
    Returns:
        {
            "is_natural": bool,
            "score": float (0-100),
            "spacing_violations": [...],
            "stuffing_warnings": [...],
            "sentence_repetitions": [...],
            "suggestions": [...]
        }
    """
    result = {
        "is_natural": True,
        "score": 100.0,
        "spacing_violations": [],
        "stuffing_warnings": [],
        "sentence_repetitions": [],
        "suggestions": []
    }
    
    full_text = (previous_batch_text + "\n\n" + text) if previous_batch_text else text
    
    for rid, meta in keywords_state.items():
        phrase = meta.get("keyword", "").strip()
        phrase_type = meta.get("type", "BASIC").upper()
        
        if not phrase:
            continue
        
        # 1. Spacing check
        is_ok, violation = check_phrase_spacing(full_text, phrase, phrase_type)
        if not is_ok and violation:
            result["spacing_violations"].append({
                "phrase": violation.phrase,
                "distance": violation.distance,
                "min_required": violation.min_required,
                "suggestion": violation.suggestion
            })
            result["score"] -= 10
        
        # 2. Paragraph stuffing (tylko w nowym batchu)
        stuffing = detect_paragraph_stuffing(text, phrase, STUFFING_THRESHOLD)
        result["stuffing_warnings"].extend(stuffing)
        result["score"] -= len(stuffing) * 5
        
        # 3. Sentence repetition (tylko w nowym batchu)
        sent_rep = detect_sentence_repetition(text, phrase)
        result["sentence_repetitions"].extend(sent_rep)
        result["score"] -= len(sent_rep) * 15
    
    # Clamp score
    result["score"] = max(0, min(100, result["score"]))
    
    # Determine if natural
    result["is_natural"] = (
        result["score"] >= 70 and
        len(result["sentence_repetitions"]) == 0
    )
    
    # Generate suggestions
    if result["spacing_violations"]:
        result["suggestions"].append(
            "Roz≈Ç√≥≈º frazy bardziej r√≥wnomiernie - niekt√≥re sƒÖ zbyt blisko siebie"
        )
    
    if result["stuffing_warnings"]:
        result["suggestions"].append(
            "Niekt√≥re akapity majƒÖ za du≈ºo powt√≥rze≈Ñ tej samej frazy - rozdziel na wiƒôcej akapit√≥w"
        )
    
    if result["sentence_repetitions"]:
        result["suggestions"].append(
            "KRYTYCZNE: Powt√≥rzenia w tym samym zdaniu brzmiƒÖ bardzo nienaturalnie - przepisz te zdania"
        )
    
    return result


# ============================================================================
# MAIN - test
# ============================================================================

if __name__ == "__main__":
    # Test
    test_text = """
Zesp√≥≈Ç Turnera jest jednƒÖ z rzadkich jednostek klinicznych. Zesp√≥≈Ç Turnera 
to choroba genetyczna, jednak jednocze≈õnie podkre≈õla siƒô, ≈ºe zesp√≥≈Ç Turnera 
nie jest chorobƒÖ w rozumieniu stanu ca≈Çkowicie wykluczajƒÖcego samodzielne funkcjonowanie.

W praktyce klinicznej zesp√≥≈Ç Turnera jest chorobƒÖ o bardzo zr√≥≈ºnicowanym przebiegu.
Przypadki zespo≈Çu Turnera r√≥≈ºniƒÖ siƒô nasileniem objaw√≥w.

Czƒôsto≈õƒá zespo≈Çu Turnera szacuje siƒô na oko≈Ço 1:2500.
"""
    
    keywords_state = {
        "k1": {"keyword": "zesp√≥≈Ç turnera", "type": "MAIN"},
        "k2": {"keyword": "choroba genetyczna", "type": "BASIC"},
    }
    
    print("=" * 70)
    print("TEST NATURAL POLISH INSTRUCTIONS")
    print("=" * 70)
    
    # Generate instructions
    instructions = generate_natural_writing_instructions(keywords_state)
    print(format_natural_instructions_for_prompt(instructions))
    
    print("\n" + "=" * 70)
    print("WALIDACJA TEKSTU")
    print("=" * 70)
    
    # Validate
    result = validate_natural_writing(test_text, keywords_state)
    
    print(f"\nNaturalno≈õƒá: {'‚úÖ TAK' if result['is_natural'] else '‚ùå NIE'}")
    print(f"Score: {result['score']}/100")
    
    if result["spacing_violations"]:
        print("\n‚ö†Ô∏è SPACING VIOLATIONS:")
        for v in result["spacing_violations"]:
            print(f"  - {v['phrase']}: {v['distance']} s≈Ç√≥w (min {v['min_required']})")
    
    if result["stuffing_warnings"]:
        print("\n‚ö†Ô∏è STUFFING:")
        for w in result["stuffing_warnings"]:
            print(f"  - {w}")
    
    if result["sentence_repetitions"]:
        print("\n‚ùå SENTENCE REPETITIONS:")
        for r in result["sentence_repetitions"]:
            print(f"  - {r}")
    
    if result["suggestions"]:
        print("\nüí° SUGGESTIONS:")
        for s in result["suggestions"]:
            print(f"  - {s}")
