# claude_reviewer.py
# v28.2 - Claude jako Reviewer/Editor batchy
# v33.3 - + mandatory_entities, diff output
#
# System sprawdzania i poprawiania batchy przez Claude API.
# Sprawdza: SEO, dÅ‚ugoÅ›Ä‡, powtÃ³rzenia, gramatykÄ™, AI patterns, halucynacje

import os
import json
import re
import time
import difflib
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict, field

try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False


@dataclass
class ReviewIssue:
    type: str  # seo, length, repetition, grammar, ai_pattern, hallucination, coherence
    severity: str  # critical, warning, suggestion
    description: str
    location: str = ""
    fix_applied: bool = False


@dataclass
class DiffChange:
    """v33.3: Pojedyncza zmiana w tekÅ›cie"""
    type: str  # "removed", "added", "context"
    text: str
    line_num: int = 0


@dataclass
class DiffSummary:
    """v33.3: Podsumowanie zmian"""
    lines_changed: int = 0
    words_removed: int = 0
    words_added: int = 0
    changes: List[DiffChange] = field(default_factory=list)


@dataclass
class ReviewResult:
    status: str  # APPROVED, CORRECTED, REJECTED, QUICK_CHECK_FAILED
    original_text: str
    corrected_text: Optional[str]
    issues: List[ReviewIssue]
    summary: str
    word_count: int = 0
    paragraph_count: int = 0
    diff: Optional[DiffSummary] = None  # v33.3: diff output


# ================================================================
# QUICK CHECKS (Python, bez API)
# ================================================================
# v29.0: NOWE PRIORYTETY
# 1. JAKOÅšÄ† TEKSTU (tautologie, gramatyka) â†’ CRITICAL
# 2. ENCJE + N-GRAMY w odpowiednich miejscach â†’ WARNING  
# 3. SÅOWA KLUCZOWE: min 1Ã—, NIE stuffing â†’ tylko stuffing blokuje
# ================================================================

# Import lemmatyzacji dla quick checks
try:
    from polish_lemmatizer import count_phrase_occurrences
    _LEMMATIZER_OK = True
except ImportError:
    _LEMMATIZER_OK = False
    print("[CLAUDE_REVIEWER] âš ï¸ polish_lemmatizer not available, using exact match")


def quick_check_keywords(text: str, required: List[Dict]) -> Tuple[List[str], List[str], Dict]:
    """
    v29.2: NOWA LOGIKA - TYLKO STUFFING BLOKUJE!
    
    - Fraza 0Ã— â†’ WARNING (Claude uzupeÅ‚ni na koÅ„cu)
    - Fraza <target â†’ OK
    - Fraza >max â†’ CRITICAL (stuffing) - JEDYNY BLOKER!
    
    Zwraca: (critical_errors, warnings, missing_info)
    - critical = TYLKO stuffing
    - warnings = missing (0Ã—) + suggestions
    - missing_info = {"basic": [...], "extended": [...]} - do przekazania Claude'owi
    """
    text_lower = text.lower()
    missing_basic = []        # 0 wystÄ…pieÅ„ BASIC - do uzupeÅ‚nienia
    missing_extended = []     # 0 wystÄ…pieÅ„ EXTENDED - do uzupeÅ‚nienia
    stuffing_errors = []      # za duÅ¼o - CRITICAL (blokuje!)
    warnings = []             # info o brakujÄ…cych
    
    for kw in required:
        keyword = kw.get("keyword", "")
        count_req = kw.get("count", 1)
        count_max = kw.get("max", count_req * 3)  # max = 3Ã— wymagane
        kw_type = kw.get("type", "BASIC").upper()
        if not keyword:
            continue
        
        # Licz z lemmatyzacjÄ…
        if _LEMMATIZER_OK:
            result = count_phrase_occurrences(text, keyword)
            count_found = result.get("count", 0)
        else:
            count_found = text_lower.count(keyword.lower())
        
        # LOGIKA v29.2:
        if count_found == 0:
            # WARNING: fraza brakuje - Claude uzupeÅ‚ni na koÅ„cu
            warnings.append(f'"{keyword}" (0/{count_req}) - brak, do uzupeÅ‚nienia')
            # Dodaj do listy dla Claude
            if kw_type == "EXTENDED":
                missing_extended.append(keyword)
            else:
                missing_basic.append(keyword)
        elif count_found > count_max:
            # CRITICAL: stuffing - JEDYNY BLOKER!
            stuffing_errors.append(f'"{keyword}" ({count_found}Ã—) - STUFFING! Max {count_max}Ã—')
        elif count_found < count_req:
            # OK: mogÅ‚oby byÄ‡ wiÄ™cej - tylko info, nie dodajemy do missing
            warnings.append(f'"{keyword}" ({count_found}/{count_req}) - OK')
    
    # v29.2: TYLKO stuffing blokuje!
    critical = stuffing_errors
    
    # Info o brakujÄ…cych frazach do przekazania Claude'owi
    missing_info = {
        "basic": missing_basic,
        "extended": missing_extended
    }
    
    return critical, warnings, missing_info


def quick_check_text_quality(text: str) -> Tuple[List[str], List[str]]:
    """
    v29.0: NOWY CHECK - JakoÅ›Ä‡ tekstu (PRIORYTET 1!)
    
    Sprawdza:
    - Tautologie (sÅ‚owo powtÃ³rzone w jednym zdaniu)
    - Pleonazmy ("przedszkole...w przedszkolu")
    - Zbyt dÅ‚ugie zdania (>35 sÅ‚Ã³w)
    - Strona bierna naduÅ¼ywana
    """
    import re
    
    critical = []
    warnings = []
    
    # Podziel na zdania
    sentences = re.split(r'[.!?]+', text)
    
    for i, sentence in enumerate(sentences, 1):
        sentence = sentence.strip()
        if not sentence:
            continue
        
        words = sentence.lower().split()
        
        # 1. TAUTOLOGIE - to samo sÅ‚owo 2+ razy w zdaniu (min 4 litery)
        word_counts = {}
        for w in words:
            w_clean = re.sub(r'[^\w]', '', w)
            if len(w_clean) >= 4:
                word_counts[w_clean] = word_counts.get(w_clean, 0) + 1
        
        for word, count in word_counts.items():
            if count >= 2 and word not in ['jest', 'oraz', 'ktÃ³re', 'ktÃ³ry', 'ktÃ³ra', 'takÅ¼e', 'bardzo']:
                # SprawdÅº czy to nie odmiana
                if word in ['przedszkole', 'przedszkolu', 'przedszkolnym', 'przedszkolnych']:
                    critical.append(f'Zdanie {i}: tautologia "przedszkol*" powtÃ³rzone {count}Ã— - POPRAW!')
                elif word in ['sensoryczny', 'sensoryczna', 'sensoryczne', 'sensorycznych', 'sensorycznym']:
                    if count >= 3:
                        warnings.append(f'Zdanie {i}: "sensoryczn*" uÅ¼yte {count}Ã— - rozwaÅ¼ synonim')
        
        # 2. ZBYT DÅUGIE ZDANIE
        if len(words) > 35:
            warnings.append(f'Zdanie {i}: {len(words)} sÅ‚Ã³w - rozwaÅ¼ podziaÅ‚')
    
    # 3. PLEONAZMY GLOBALNE
    text_lower = text.lower()
    
    # "przedszkole...w przedszkolu" w tym samym akapicie
    paragraphs = text.split('\n\n')
    for p_idx, para in enumerate(paragraphs, 1):
        para_lower = para.lower()
        if 'przedszkole' in para_lower and 'w przedszkolu' in para_lower:
            # SprawdÅº czy to nie jest "pomoce sensoryczne w przedszkolu" (fraza kluczowa)
            if 'pomoce sensoryczne w przedszkolu' not in para_lower:
                critical.append(f'Akapit {p_idx}: pleonazm "przedszkole...w przedszkolu" - zamieÅ„ jedno na "placÃ³wka/obiekt"')
    
    return critical, warnings


def quick_check_length(text: str, min_w: int, max_w: int) -> Tuple[Optional[str], int]:
    words = len(text.split())
    if words < min_w * 0.8:
        return f"Za krÃ³tki: {words} sÅ‚Ã³w (min: {min_w})", words
    elif words > max_w * 1.3:
        return f"Za dÅ‚ugi: {words} sÅ‚Ã³w (max: {max_w})", words
    return None, words


def quick_check_forbidden(text: str, forbidden: List[str]) -> List[str]:
    text_lower = text.lower()
    return [f for f in forbidden if f and f.lower() in text_lower]


def quick_check_ai_patterns(text: str) -> List[str]:
    patterns = [
        "w dzisiejszych czasach", "warto wiedzieÄ‡", "nie jest tajemnicÄ…",
        "podsumowujÄ…c", "w niniejszym artykule", "jak wiadomo",
        "przykÅ‚ad:", "na przykÅ‚ad,", "wyobraÅºmy sobie", "zaÅ‚Ã³Å¼my, Å¼e"
    ]
    text_lower = text.lower()
    return [p for p in patterns if p in text_lower]


def run_quick_checks(text: str, context: Dict) -> Dict:
    """
    v29.0: NOWE PRIORYTETY
    
    PRIORYTET 1: JakoÅ›Ä‡ tekstu (tautologie, pleonazmy) â†’ CRITICAL
    PRIORYTET 2: Encje/n-gramy w odpowiednich miejscach â†’ WARNING
    PRIORYTET 3: SÅ‚owa kluczowe (min 1Ã—, nie stuffing) â†’ tylko stuffing/brak blokuje
    """
    critical_errors = []  # BlokujÄ… zapis
    warnings = []         # Tylko info, nie blokujÄ…
    suggestions = []      # Sugestie optymalizacji
    
    # ============================================
    # PRIORYTET 1: JAKOÅšÄ† TEKSTU (CRITICAL!)
    # ============================================
    quality_critical, quality_warnings = quick_check_text_quality(text)
    for err in quality_critical:
        critical_errors.append({"type": "quality", "severity": "critical", "msg": err})
    for warn in quality_warnings:
        warnings.append({"type": "quality", "severity": "warning", "msg": warn})
    
    # AI patterns - teÅ¼ jakoÅ›Ä‡
    ai = quick_check_ai_patterns(text)
    if ai:
        warnings.append({"type": "ai_pattern", "severity": "warning", "msg": f"AI patterns: {', '.join(ai)}"})
    
    # ============================================
    # PRIORYTET 2: DÅUGOÅšÄ† (ale elastyczna)
    # ============================================
    len_err, words = quick_check_length(
        text, 
        context.get("target_words_min", 150),
        context.get("target_words_max", 500)
    )
    if len_err:
        # Za krÃ³tki = critical, za dÅ‚ugi = warning (moÅ¼na skrÃ³ciÄ‡)
        if "za krÃ³tki" in len_err.lower():
            critical_errors.append({"type": "length", "severity": "critical", "msg": len_err})
        else:
            warnings.append({"type": "length", "severity": "warning", "msg": len_err})
    
    # ============================================
    # PRIORYTET 3: KEYWORDS (nowa logika v29.2!)
    # ============================================
    # critical = TYLKO stuffing
    # warnings = info o brakujÄ…cych i niedostatecznych
    # missing_info = lista fraz do uzupeÅ‚nienia przez Claude
    kw_critical, kw_warnings, missing_info = quick_check_keywords(text, context.get("keywords_required", []))
    
    for err in kw_critical:
        critical_errors.append({"type": "seo", "severity": "critical", "msg": err})
    for warn in kw_warnings:
        warnings.append({"type": "seo", "severity": "warning", "msg": warn})
    
    # Forbidden keywords - zawsze critical
    forbidden = quick_check_forbidden(text, context.get("keywords_forbidden", []))
    if forbidden:
        critical_errors.append({"type": "seo", "severity": "critical", "msg": f"Zabronione frazy: {', '.join(forbidden)}"})
    
    # ============================================
    # STATS
    # ============================================
    paras = len([p for p in text.split('\n\n') if p.strip() and len(p) > 30])
    
    return {
        "passed": len(critical_errors) == 0,  # Tylko CRITICAL (stuffing) blokuje!
        "errors": critical_errors,
        "warnings": warnings,
        "suggestions": suggestions,
        "word_count": words,
        "paragraph_count": paras,
        "missing_phrases": missing_info,  # v29.2: do uzupeÅ‚nienia przez Claude
        "priority_summary": {
            "quality_issues": len([e for e in critical_errors if e["type"] == "quality"]),
            "seo_issues": len([e for e in critical_errors if e["type"] == "seo"]),
            "length_issues": len([e for e in critical_errors if e["type"] == "length"])
        }
    }


# ================================================================
# CLAUDE REVIEW
# ================================================================

def build_review_prompt(text: str, ctx: Dict) -> str:
    """v29.2: Prompt z listÄ… BRAKUJÄ„CYCH FRAZ do uzupeÅ‚nienia przez Claude
       v33.3: + mandatory_entities ktÃ³rych Claude NIE MOÅ»E usunÄ…Ä‡
    """
    
    required = "\n".join([f'  â€¢ "{k["keyword"]}" (min 1Ã—, zalecane {k.get("count",1)}Ã—)' 
                          for k in ctx.get("keywords_required", []) if k.get("keyword")])
    forbidden = ", ".join(ctx.get("keywords_forbidden", [])) or "brak"
    h2_list = "\n".join([f"  â€¢ {h}" for h in ctx.get("h2_current", [])]) or "  (brak)"
    
    # GÅ‚Ã³wna fraza
    main_kw = ctx.get("main_keyword", "")
    main_kw_count = ctx.get("main_keyword_count", 2)
    
    # Snippet info
    snippet_info = "TAK (40-60 sÅ‚Ã³w na poczÄ…tku)" if ctx.get("snippet_required") else "NIE"
    
    # v29.2: BRAKUJÄ„CE FRAZY DO UZUPEÅNIENIA
    missing_basic = ctx.get("missing_basic", [])
    missing_extended = ctx.get("missing_extended", [])
    
    # v33.3: MANDATORY ENTITIES - Claude NIE MOÅ»E ich usunÄ…Ä‡/zmieniÄ‡
    mandatory_entities = ctx.get("mandatory_entities", [])
    mandatory_section = ""
    if mandatory_entities:
        entities_list = "\n".join([f'  â›” "{e}"' for e in mandatory_entities])
        mandatory_section = f"""
### â›” OBOWIÄ„ZKOWE ENCJE (NIE USUWAJ, NIE ZMIENIAJ!)
{entities_list}

Te encje/frazy MUSZÄ„ pozostaÄ‡ w tekÅ›cie BEZ ZMIAN. MoÅ¼esz tylko poprawiÄ‡ ich otoczenie gramatycznie.
JeÅ›li usuniesz lub zmienisz ktÃ³rÄ…kolwiek z nich - twoja odpowiedÅº zostanie odrzucona!

"""
    
    missing_section = ""
    if missing_basic or missing_extended:
        missing_section = """
### ðŸ”´ BRAKUJÄ„CE FRAZY - MUSISZ UZUPEÅNIÄ†!

**Te frazy NIE wystÄ™pujÄ… w tekÅ›cie - wpleÄ‡ je naturalnie:**
"""
        if missing_basic:
            missing_section += "\nBASIC (waÅ¼niejsze):\n"
            for phrase in missing_basic:
                missing_section += f'  â€¢ "{phrase}"\n'
        
        if missing_extended:
            missing_section += "\nEXTENDED:\n"
            for phrase in missing_extended:
                missing_section += f'  â€¢ "{phrase}"\n'
        
        missing_section += """
âš ï¸ WPLEÄ† KAÅ»DÄ„ BRAKUJÄ„CÄ„ FRAZÄ˜ min 1Ã— w naturalny sposÃ³b!
   MoÅ¼esz uÅ¼yÄ‡ odmiany (np. "Å›cieÅ¼kÄ… sensorycznÄ…" zamiast "Å›cieÅ¼ka sensoryczna")
"""
    
    return f"""JesteÅ› redaktorem i stylistÄ… jÄ™zyka polskiego. SprawdÅº i POPRAW tekst.

## PRIORYTETY (w tej kolejnoÅ›ci!):
{mandatory_section}
### ðŸ”´ PRIORYTET 1: JAKOÅšÄ† TEKSTU (NAJWAÅ»NIEJSZE!)
Tekst musi byÄ‡ poprawny, naturalny i przyjemny w czytaniu.

SPRAWDÅ¹ I POPRAW:
- **TAUTOLOGIE**: "przedszkole... w przedszkolu" â†’ zamieÅ„ jedno na "placÃ³wka/obiekt/sala"
- **PLEONAZMY**: "nowoczesne przedszkole wyposaÅ¼one jest w pomoce w przedszkolu" â†’ DRAMAT!
- **POWTÃ“RZENIA**: To samo sÅ‚owo 2Ã— w zdaniu (poza spÃ³jnikami) â†’ uÅ¼yj synonimu
- **STRONA BIERNA**: "jest wyposaÅ¼one w" â†’ "posiada", "oferuje", "zawiera"
- **DÅUGIE ZDANIA**: >30 sÅ‚Ã³w â†’ podziel na 2
- **GRAMATYKA**: BÅ‚Ä™dy, kolokacje, naturalnoÅ›Ä‡ jÄ™zyka polskiego
- **AI PATTERNS**: "W dzisiejszych czasach", "Warto wiedzieÄ‡", "Nie jest tajemnicÄ…" â†’ USUÅƒ
- **HALUCYNACJE**: WymyÅ›lone statystyki, badania, fakty bez ÅºrÃ³dÅ‚a â†’ USUÅƒ

### ðŸŸ¡ PRIORYTET 2: ENCJE I N-GRAMY
Upewnij siÄ™, Å¼e kluczowe pojÄ™cia sÄ… zdefiniowane/wyjaÅ›nione przy pierwszym uÅ¼yciu.
{missing_section}
### ðŸŸ¢ PRIORYTET 3: ISTNIEJÄ„CE FRAZY (sprawdÅº iloÅ›ci)
Frazy powinny wystÄ™powaÄ‡ NATURALNIE. Lepiej 1Ã— naturalnie niÅ¼ 3Ã— sztucznie!

GÅÃ“WNA FRAZA: "{main_kw}" (min {main_kw_count}Ã—)

POZOSTAÅE FRAZY (min 1Ã—, zalecane iloÅ›ci to cel, nie wymÃ³g):
{required}

âŒ NIE RÃ“B: wstawiania fraz "na siÅ‚Ä™" ktÃ³re psujÄ… naturalnoÅ›Ä‡
âœ… TAK RÃ“B: wplataj frazy gdzie pasujÄ… do kontekstu

ZABRONIONE: {forbidden}

---

## KONTEKST
- Temat: {ctx.get("topic", "")}
- Batch: #{ctx.get("batch_number", 1)}
- H2: {h2_list}
- SÅ‚owa: {ctx.get("target_words_min", 200)}-{ctx.get("target_words_max", 500)}
- Akapity: {ctx.get("target_paragraphs_min", 2)}-{ctx.get("target_paragraphs_max", 5)}
- Snippet: {snippet_info}

## TEKST DO SPRAWDZENIA:
{text}

---

## ODPOWIEDÅ¹ (tylko JSON):
```json
{{
  "status": "APPROVED | CORRECTED | REJECTED",
  "quality_score": 1-10,
  "issues": [
    {{"priority": 1, "type": "tautologia|pleonazm|gramatyka|halucynacja|ai_pattern", "description": "...", "fix_applied": true}},
    {{"priority": 2, "type": "encja_brak", "description": "...", "fix_applied": false}},
    {{"priority": 3, "type": "fraza_dodana|fraza_brak", "description": "...", "fix_applied": true}}
  ],
  "phrases_added": ["lista fraz ktÃ³re wplotÅ‚eÅ›"],
  "corrected_text": "peÅ‚ny poprawiony tekst (tylko jeÅ›li CORRECTED)",
  "summary": "co poprawiono"
}}
```

ZASADY:
- APPROVED = jakoÅ›Ä‡ OK, wszystkie brakujÄ…ce frazy uzupeÅ‚nione
- CORRECTED = poprawiÅ‚eÅ› bÅ‚Ä™dy jakoÅ›ciowe LUB uzupeÅ‚niÅ‚eÅ› frazy, zwrÃ³Ä‡ peÅ‚ny tekst
- REJECTED = tekst nie do uratowania (za krÃ³tki, same bÅ‚Ä™dy, halucynacje)
- Zachowaj format h2: / h3:
- JEÅšLI SÄ„ BRAKUJÄ„CE FRAZY â†’ MUSISZ zwrÃ³ciÄ‡ CORRECTED z uzupeÅ‚nionym tekstem!
- NIE dopisuj tekstu jeÅ›li za krÃ³tki â†’ zwrÃ³Ä‡ REJECTED
- PRIORYTET 1 (jakoÅ›Ä‡) waÅ¼niejszy niÅ¼ dokÅ‚adne iloÅ›ci fraz!"""


def generate_diff(original: str, corrected: str) -> DiffSummary:
    """
    v33.3: Generuje diff miÄ™dzy oryginaÅ‚em a poprawionym tekstem.
    """
    if not corrected or original == corrected:
        return DiffSummary()
    
    original_lines = original.splitlines()
    corrected_lines = corrected.splitlines()
    
    differ = difflib.unified_diff(
        original_lines,
        corrected_lines,
        lineterm='',
        n=0  # bez kontekstu
    )
    
    changes = []
    words_removed = 0
    words_added = 0
    line_num = 0
    
    for line in differ:
        if line.startswith('@@'):
            # Parse line number from @@ -X,Y +A,B @@
            match = re.search(r'\+(\d+)', line)
            if match:
                line_num = int(match.group(1))
            continue
        elif line.startswith('---') or line.startswith('+++'):
            continue
        elif line.startswith('-'):
            text = line[1:]
            if text.strip():
                changes.append(DiffChange(type="removed", text=text, line_num=line_num))
                words_removed += len(text.split())
        elif line.startswith('+'):
            text = line[1:]
            if text.strip():
                changes.append(DiffChange(type="added", text=text, line_num=line_num))
                words_added += len(text.split())
            line_num += 1
    
    return DiffSummary(
        lines_changed=len([c for c in changes if c.type in ["removed", "added"]]),
        words_removed=words_removed,
        words_added=words_added,
        changes=changes[:20]  # Limit do 20 zmian
    )


def validate_mandatory_entities(original: str, corrected: str, mandatory: List[str]) -> List[str]:
    """
    v33.3: Sprawdza czy mandatory_entities zostaÅ‚y zachowane w tekÅ›cie.
    Zwraca listÄ™ brakujÄ…cych encji.
    """
    if not mandatory or not corrected:
        return []
    
    missing = []
    original_lower = original.lower()
    corrected_lower = corrected.lower()
    
    for entity in mandatory:
        entity_lower = entity.lower()
        # SprawdÅº czy encja byÅ‚a w oryginale i zniknÄ™Å‚a z poprawionego
        if entity_lower in original_lower and entity_lower not in corrected_lower:
            missing.append(entity)
    
    return missing


def review_with_claude(text: str, ctx: Dict) -> ReviewResult:
    if not ANTHROPIC_AVAILABLE or not os.environ.get("ANTHROPIC_API_KEY"):
        return ReviewResult("APPROVED", text, None, [], "Claude niedostÄ™pny", len(text.split()))
    
    try:
        client = anthropic.Anthropic()
        start = time.time()
        
        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=4000,
            messages=[{"role": "user", "content": build_review_prompt(text, ctx)}]
        )
        
        resp_text = response.content[0].text
        json_match = re.search(r'\{[\s\S]*\}', resp_text)
        
        if not json_match:
            return ReviewResult("APPROVED", text, None, [], "Brak JSON w odpowiedzi", len(text.split()))
        
        data = json.loads(json_match.group())
        
        issues = [ReviewIssue(
            type=i.get("type", ""),
            severity=i.get("severity", "warning"),
            description=i.get("description", ""),
            fix_applied=i.get("fix_applied", False)
        ) for i in data.get("issues", [])]
        
        status = data.get("status", "APPROVED")
        corrected = data.get("corrected_text")
        
        if status == "CORRECTED" and (not corrected or len(corrected) < 50):
            status = "APPROVED"
            corrected = None
        
        # v33.3: Walidacja mandatory_entities
        mandatory_entities = ctx.get("mandatory_entities", [])
        if corrected and mandatory_entities:
            missing_entities = validate_mandatory_entities(text, corrected, mandatory_entities)
            if missing_entities:
                # Claude usunÄ…Å‚ obowiÄ…zkowe encje - odrzuÄ‡ korektÄ™!
                issues.append(ReviewIssue(
                    type="mandatory_entity_removed",
                    severity="critical",
                    description=f"Claude usunÄ…Å‚ obowiÄ…zkowe encje: {', '.join(missing_entities)}",
                    fix_applied=False
                ))
                # PrzywrÃ³Ä‡ oryginalny tekst
                print(f"[CLAUDE_REVIEWER] âš ï¸ Mandatory entities removed: {missing_entities} - reverting to original")
                corrected = None
                status = "APPROVED"  # Zachowaj oryginalny tekst
        
        # v33.3: Generuj diff jeÅ›li sÄ… zmiany
        diff_summary = None
        if corrected and corrected != text:
            diff_summary = generate_diff(text, corrected)
            print(f"[CLAUDE_REVIEWER] ðŸ“ Diff: {diff_summary.lines_changed} lines, -{diff_summary.words_removed}/+{diff_summary.words_added} words")
        
        final = corrected if corrected else text
        
        return ReviewResult(
            status=status,
            original_text=text,
            corrected_text=corrected,
            issues=issues,
            summary=data.get("summary", ""),
            word_count=len(final.split()),
            paragraph_count=len([p for p in final.split('\n\n') if p.strip()]),
            diff=diff_summary  # v33.3
        )
        
    except Exception as e:
        print(f"[CLAUDE_REVIEWER] Error: {e}")
        return ReviewResult("APPROVED", text, None, [], f"BÅ‚Ä…d: {e}", len(text.split()))


# ================================================================
# GÅÃ“WNA FUNKCJA
# ================================================================

def review_batch(text: str, context: Dict, skip_claude: bool = False) -> ReviewResult:
    """
    v29.2: PeÅ‚ny review: Quick Checks + Claude.
    
    JeÅ›li sÄ… brakujÄ…ce frazy (0Ã—), przekazuje je do Claude do uzupeÅ‚nienia.
    """
    # Quick checks
    qc = run_quick_checks(text, context)
    
    if not qc["passed"]:
        # v29.2: Jedyny bloker to stuffing
        issues = [ReviewIssue(e["type"], "critical", e["msg"]) for e in qc["errors"]]
        issues += [ReviewIssue(w["type"], "warning", w["msg"]) for w in qc["warnings"]]
        return ReviewResult(
            "QUICK_CHECK_FAILED", text, None, issues,
            "Popraw bÅ‚Ä™dy krytyczne (stuffing)",
            qc["word_count"], qc["paragraph_count"]
        )
    
    if skip_claude:
        issues = [ReviewIssue(w["type"], "warning", w["msg"]) for w in qc["warnings"]]
        return ReviewResult(
            "APPROVED", text, None, issues,
            "Quick check OK",
            qc["word_count"], qc["paragraph_count"]
        )
    
    # v29.2: PrzekaÅ¼ brakujÄ…ce frazy do kontekstu Claude
    missing = qc.get("missing_phrases", {})
    context["missing_basic"] = missing.get("basic", [])
    context["missing_extended"] = missing.get("extended", [])
    
    # Claude review - uzupeÅ‚ni brakujÄ…ce frazy
    result = review_with_claude(text, context)
    
    # Dodaj warnings z quick check
    for w in qc["warnings"]:
        if not any(i.fix_applied and i.type == w["type"] for i in result.issues):
            result.issues.append(ReviewIssue(w["type"], "warning", w["msg"]))
    
    return result


def build_context_from_pre_batch(pre_batch: Dict, project: Dict = None) -> Dict:
    """Helper: buduje context z getPreBatchInfo."""
    keywords_required = []
    
    main_kw = pre_batch.get("main_keyword", {})
    if main_kw.get("keyword"):
        keywords_required.append({
            "keyword": main_kw["keyword"],
            "count": main_kw.get("info", {}).get("use_this_batch", 2)
        })
    
    kw = pre_batch.get("keywords", {})
    for k in kw.get("basic_must_use", [])[:8]:
        if k.get("keyword"):
            keywords_required.append({"keyword": k["keyword"], "count": 1})
    for k in kw.get("extended_this_batch", [])[:4]:
        if k.get("keyword"):
            keywords_required.append({"keyword": k["keyword"], "count": 1})
    
    forbidden = [k.get("keyword") for k in kw.get("locked_exceeded", []) if k.get("keyword")]
    forbidden += kw.get("extended_done", [])
    
    bl = pre_batch.get("batch_length", {})
    
    last = ""
    if project:
        content = project.get("article_content", "")
        if content:
            last = content[-200:]
    
    return {
        "topic": pre_batch.get("topic", ""),
        "h2_current": pre_batch.get("h2_remaining", [])[:2],
        "keywords_required": keywords_required,
        "keywords_forbidden": [f for f in forbidden if f],
        "last_sentences": last,
        "target_words_min": bl.get("suggested_min", 200),
        "target_words_max": bl.get("suggested_max", 500),
        "target_paragraphs_min": bl.get("paragraphs_min", 2),
        "target_paragraphs_max": bl.get("paragraphs_max", 5),
        "main_keyword": main_kw.get("keyword", ""),
        "main_keyword_count": main_kw.get("info", {}).get("use_this_batch", 2),
        "batch_number": pre_batch.get("batch_number", 1),
        "snippet_required": bl.get("snippet_required", True),
        "complexity_score": bl.get("complexity_score", 50)
    }
