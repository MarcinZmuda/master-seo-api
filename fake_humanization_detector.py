"""
===============================================================================
FAKE HUMANIZATION DETECTOR v41.1
===============================================================================
Wykrywa "sztucznƒÖ humanizacjƒô" - gdy agent dodaje kr√≥tkie zdania na ko≈Ñcu
akapit√≥w zamiast naturalnie mieszaƒá d≈Çugo≈õci.

PROBLEMY KT√ìRE WYKRYWA:
1. Wszystkie kr√≥tkie zdania na ko≈Ñcach akapit√≥w
2. PowtarzajƒÖce siƒô fillery ("To wa≈ºne.", "Sprawd≈∫ to.")
3. Zdania w "AI zone" (20-25 s≈Ç√≥w) dominujƒÖ
4. Brak kr√≥tkich zda≈Ñ w ≈õrodku akapit√≥w

v41.1: Nowy modu≈Ç
===============================================================================
"""

import re
from typing import Dict, List, Any, Tuple
from dataclasses import dataclass
from collections import Counter


@dataclass
class FakeHumanizationConfig:
    """Konfiguracja wykrywania fake humanization."""
    
    # Znane fillery
    # v45.0: Rozszerzono o zdania z usuniƒôtej statycznej biblioteki
    # (smart_batch_instructions.py + semantic_phrase_assignment.py)
    # Je≈õli GPT nadal je generuje mimo braku w bibliotece ‚Üí to filler
    KNOWN_FILLERS = [
        # Oryginalne fillery
        "to wa≈ºne",
        "to istotne", 
        "sprawd≈∫ to",
        "warto wiedzieƒá",
        "pamiƒôtaj o tym",
        "zapamiƒôtaj to",
        "to kluczowe",
        "oto szczeg√≥≈Çy",
        "co dalej",
        "ale uwaga",
        "to proste",
        "to jasne",
        # v45.0: Usuniƒôte z biblioteki, ale GPT mo≈ºe je generowaƒá z przyzwyczajenia
        "sƒÖd orzeka",
        "termin biegnie",
        "dowody decydujƒÖ",
        "prawo wymaga",
        "procedura trwa",
        "wyrok zapada",
        "sprawa siƒô toczy",
        "kara grozi",
        "przepis obowiƒÖzuje",
        "lekarz decyduje",
        "badanie wyka≈ºe",
        "leczenie trwa",
        "diagnoza potwierdzona",
        "zysk ro≈õnie",
        "ryzyko istnieje",
        "rynek reaguje",
        "warto rozwa≈ºyƒá",
        "szczeg√≥≈Çy poni≈ºej",
        "praktyka pokazuje",
        "sytuacja jest z≈Ço≈ºona",
        "definicja jest kluczowa",
        "znaczenie jest jasne",
        "relacja ma znaczenie",
        "kontakt jest wa≈ºny",
        "opieka trwa",
        "dobro dziecka",
        "to wa≈ºne pojƒôcie",
        "sankcja jest surowa",
        "odpowiedzialno≈õƒá istnieje",
        "wyrok jest prawomocny",
    ]
    
    # AI zone - zdania kt√≥re AI typowo produkuje
    AI_ZONE_MIN_WORDS = 18
    AI_ZONE_MAX_WORDS = 26
    AI_ZONE_MAX_RATIO = 0.40  # Max 40% zda≈Ñ w AI zone
    
    # Minimalne wymagania
    MIN_SHORT_SENTENCES_IN_MIDDLE = 0.10  # 10% kr√≥tkich w ≈õrodku akapit√≥w
    MIN_SHORT_TOTAL = 0.15  # 15% kr√≥tkich og√≥≈Çem (bloker)
    
    # Progi severity
    CRITICAL_THRESHOLD = 0.70  # >70% filler√≥w na ko≈Ñcach = CRITICAL
    WARNING_THRESHOLD = 0.50   # >50% filler√≥w na ko≈Ñcach = WARNING


CONFIG = FakeHumanizationConfig()


def split_into_sentences(text: str) -> List[str]:
    """Dzieli tekst na zdania."""
    if not text:
        return []
    
    # Ochrona skr√≥t√≥w
    protected = text
    abbreviations = ['art', 'ust', 'pkt', 'np', 'dr', 'prof', 'mgr', 'in≈º', 'tj', 'tzn']
    for abbr in abbreviations:
        protected = re.sub(rf'\b{abbr}\.', f'{abbr}@@DOT@@', protected, flags=re.IGNORECASE)
    
    # Split na zdania
    sentences = re.split(r'(?<=[.!?])\s+', protected)
    
    # Przywr√≥ƒá kropki
    sentences = [s.replace('@@DOT@@', '.').strip() for s in sentences if s.strip()]
    
    return sentences


def split_into_paragraphs(text: str) -> List[str]:
    """Dzieli tekst na akapity."""
    if not text:
        return []
    
    paragraphs = re.split(r'\n\n+', text.strip())
    return [p.strip() for p in paragraphs if p.strip() and len(p.strip()) > 20]


def is_known_filler(sentence: str) -> bool:
    """Sprawdza czy zdanie to znany filler."""
    sentence_lower = sentence.lower().strip().rstrip('.!?')
    return any(filler in sentence_lower for filler in CONFIG.KNOWN_FILLERS)


def is_short_sentence(sentence: str, max_words: int = 8) -> bool:
    """Sprawdza czy zdanie jest kr√≥tkie (3-8 s≈Ç√≥w)."""
    words = len(sentence.split())
    return 2 <= words <= max_words


def is_in_ai_zone(sentence: str) -> bool:
    """Sprawdza czy zdanie jest w typowym zakresie AI (18-26 s≈Ç√≥w)."""
    words = len(sentence.split())
    return CONFIG.AI_ZONE_MIN_WORDS <= words <= CONFIG.AI_ZONE_MAX_WORDS


def analyze_paragraph_structure(paragraph: str) -> Dict[str, Any]:
    """
    Analizuje strukturƒô pojedynczego akapitu.
    
    Zwraca:
    - Pozycje kr√≥tkich zda≈Ñ (poczƒÖtek, ≈õrodek, koniec)
    - Czy ko≈Ñczy siƒô fillerem
    - Rozk≈Çad d≈Çugo≈õci
    """
    sentences = split_into_sentences(paragraph)
    
    if len(sentences) < 2:
        return {
            "sentence_count": len(sentences),
            "short_at_start": False,
            "short_in_middle": False,
            "short_at_end": False,
            "ends_with_filler": False,
            "ai_zone_ratio": 0
        }
    
    # Klasyfikuj pozycje
    short_positions = []
    filler_positions = []
    ai_zone_count = 0
    
    for i, sent in enumerate(sentences):
        if is_short_sentence(sent):
            if i == 0:
                short_positions.append("start")
            elif i == len(sentences) - 1:
                short_positions.append("end")
            else:
                short_positions.append("middle")
                
            if is_known_filler(sent):
                filler_positions.append(i)
        
        if is_in_ai_zone(sent):
            ai_zone_count += 1
    
    return {
        "sentence_count": len(sentences),
        "short_at_start": "start" in short_positions,
        "short_in_middle": "middle" in short_positions,
        "short_at_end": "end" in short_positions,
        "ends_with_filler": len(sentences) - 1 in filler_positions if filler_positions else False,
        "filler_count": len(filler_positions),
        "ai_zone_ratio": ai_zone_count / len(sentences) if sentences else 0,
        "short_positions": short_positions
    }


def detect_fake_humanization(text: str) -> Dict[str, Any]:
    """
    G≈Ç√≥wna funkcja wykrywajƒÖca fake humanization.
    
    Zwraca:
    - is_fake: bool - czy wykryto sztucznƒÖ humanizacjƒô
    - severity: CRITICAL/WARNING/OK
    - score: 0-100 (0 = bardzo fake, 100 = natural)
    - issues: lista problem√≥w
    - recommendations: rekomendacje naprawy
    """
    if not text or len(text) < 100:
        return {
            "is_fake": False,
            "severity": "OK",
            "score": 100,
            "issues": [],
            "recommendations": []
        }
    
    paragraphs = split_into_paragraphs(text)
    all_sentences = split_into_sentences(text)
    
    if len(paragraphs) < 2 or len(all_sentences) < 5:
        return {
            "is_fake": False,
            "severity": "OK", 
            "score": 100,
            "issues": ["Za ma≈Ço tekstu do analizy"],
            "recommendations": []
        }
    
    # Analizuj ka≈ºdy akapit
    paragraph_analyses = [analyze_paragraph_structure(p) for p in paragraphs]
    
    # === METRYKI ===
    
    # 1. Ile akapit√≥w ko≈Ñczy siƒô fillerem?
    ends_with_filler_count = sum(1 for pa in paragraph_analyses if pa["ends_with_filler"])
    filler_at_end_ratio = ends_with_filler_count / len(paragraphs)
    
    # 2. Ile kr√≥tkich zda≈Ñ jest w ≈õrodku vs na ko≈Ñcach?
    total_short_middle = sum(1 for pa in paragraph_analyses if pa["short_in_middle"])
    total_short_end = sum(1 for pa in paragraph_analyses if pa["short_at_end"])
    
    short_position_ratio = 0
    if total_short_middle + total_short_end > 0:
        short_position_ratio = total_short_middle / (total_short_middle + total_short_end)
    
    # 3. Ratio zda≈Ñ w AI zone
    total_ai_zone_ratio = sum(pa["ai_zone_ratio"] for pa in paragraph_analyses) / len(paragraph_analyses)
    
    # 4. Og√≥lny % kr√≥tkich zda≈Ñ
    all_short = sum(1 for s in all_sentences if is_short_sentence(s))
    short_total_ratio = all_short / len(all_sentences) if all_sentences else 0
    
    # 5. PowtarzajƒÖce siƒô fillery
    short_sentences = [s.lower().strip().rstrip('.!?') for s in all_sentences if is_short_sentence(s)]
    filler_counter = Counter(short_sentences)
    repeated_fillers = [f for f, count in filler_counter.items() if count > 1]
    
    # === OCENA ===
    issues = []
    recommendations = []
    
    # Problem 1: Fillery na ko≈Ñcach
    if filler_at_end_ratio > CONFIG.CRITICAL_THRESHOLD:
        issues.append(f"CRITICAL: {filler_at_end_ratio*100:.0f}% akapit√≥w ko≈Ñczy siƒô sztucznym fillerem")
        recommendations.append("Usu≈Ñ fillery z ko≈Ñc√≥w akapit√≥w. Zamiast 'To wa≈ºne.' napisz pe≈Çne zdanie rozwijajƒÖce my≈õl.")
    elif filler_at_end_ratio > CONFIG.WARNING_THRESHOLD:
        issues.append(f"WARNING: {filler_at_end_ratio*100:.0f}% akapit√≥w ko≈Ñczy siƒô fillerem")
        recommendations.append("Zmniejsz liczbƒô kr√≥tkich zda≈Ñ na ko≈Ñcach akapit√≥w.")
    
    # Problem 2: Brak kr√≥tkich w ≈õrodku
    if short_position_ratio < 0.3 and total_short_middle + total_short_end > 0:
        issues.append(f"WARNING: Tylko {short_position_ratio*100:.0f}% kr√≥tkich zda≈Ñ jest w ≈õrodku akapit√≥w")
        recommendations.append("Dodaj kr√≥tkie zdania W ≈öRODKU akapit√≥w, nie tylko na ko≈Ñcach.")
    
    # Problem 3: Za du≈ºo w AI zone
    if total_ai_zone_ratio > CONFIG.AI_ZONE_MAX_RATIO:
        issues.append(f"WARNING: {total_ai_zone_ratio*100:.0f}% zda≈Ñ ma 18-26 s≈Ç√≥w (typowa d≈Çugo≈õƒá AI)")
        recommendations.append("Mieszaj d≈Çugo≈õci zda≈Ñ bardziej naturalnie. Dodaj zdania 10-15 s≈Ç√≥w i 28-35 s≈Ç√≥w.")
    
    # Problem 4: Za ma≈Ço kr√≥tkich og√≥≈Çem
    if short_total_ratio < CONFIG.MIN_SHORT_TOTAL:
        issues.append(f"WARNING: Tylko {short_total_ratio*100:.0f}% kr√≥tkich zda≈Ñ (cel: 15-25%)")
        recommendations.append("Dodaj wiƒôcej kr√≥tkich zda≈Ñ (3-8 s≈Ç√≥w) naturalnie w tek≈õcie.")
    
    # Problem 5: PowtarzajƒÖce siƒô fillery
    if repeated_fillers:
        issues.append(f"WARNING: PowtarzajƒÖce siƒô fillery: {', '.join(repeated_fillers[:3])}")
        recommendations.append("Unikaj powtarzania tych samych kr√≥tkich zda≈Ñ.")
    
    # === SCORING ===
    score = 100
    
    # Kary za problemy
    score -= filler_at_end_ratio * 30  # Max -30 za fillery na ko≈Ñcach
    score -= (1 - short_position_ratio) * 20 if total_short_middle + total_short_end > 0 else 0  # Max -20 za brak w ≈õrodku
    score -= max(0, total_ai_zone_ratio - 0.40) * 50  # Kara za AI zone > 40%
    score -= len(repeated_fillers) * 5  # -5 za ka≈ºdy powt√≥rzony filler
    
    score = max(0, min(100, score))
    
    # === SEVERITY ===
    if score < 50 or any("CRITICAL" in i for i in issues):
        severity = "CRITICAL"
        is_fake = True
    elif score < 70 or len(issues) >= 2:
        severity = "WARNING"
        is_fake = True
    else:
        severity = "OK"
        is_fake = False
    
    return {
        "is_fake": is_fake,
        "severity": severity,
        "score": round(score, 1),
        "issues": issues,
        "recommendations": recommendations,
        "metrics": {
            "filler_at_end_ratio": round(filler_at_end_ratio, 3),
            "short_position_ratio": round(short_position_ratio, 3),
            "ai_zone_ratio": round(total_ai_zone_ratio, 3),
            "short_total_ratio": round(short_total_ratio, 3),
            "repeated_fillers": repeated_fillers[:5],
            "paragraph_count": len(paragraphs),
            "sentence_count": len(all_sentences)
        }
    }


def generate_natural_humanization_tips(analysis: Dict[str, Any]) -> List[str]:
    """
    Generuje konkretne wskaz√≥wki dla naturalnej humanizacji.
    """
    tips = []
    
    if analysis.get("metrics", {}).get("ai_zone_ratio", 0) > 0.35:
        tips.append("üéØ Przeplataj d≈Çugo≈õci: zamiast '15-20-18-22-19' napisz '8-25-12-30-6-18'")
    
    if analysis.get("metrics", {}).get("filler_at_end_ratio", 0) > 0.3:
        tips.append("üö´ Nie ko≈Ñcz akapit√≥w fillerami jak 'To wa≈ºne.' - rozwi≈Ñ my≈õl w pe≈Çne zdanie")
        tips.append("‚úÖ Zamiast: '...wymaga uwagi. To wa≈ºne.' napisz: '...wymaga szczeg√≥lnej uwagi ze strony prawnika.'")
    
    if analysis.get("metrics", {}).get("short_position_ratio", 0) < 0.4:
        tips.append("üí° Kr√≥tkie zdania w ≈öRODKU akapitu: 'SƒÖd orzek≈Ç. To zmieni≈Ço wszystko.' - nie na ko≈Ñcu!")
        tips.append("‚úÖ Przyk≈Çad: 'Procedura jest z≈Ço≈ºona. Wymaga trzech etap√≥w. Pierwszy to...'")
    
    tips.append("üìä Cel rozk≈Çadu: 20% kr√≥tkich (3-8), 55% ≈õrednich (10-18), 25% d≈Çugich (20-30)")
    
    return tips


# === INTEGRATION HELPER ===

def validate_humanization_quality(text: str) -> Dict[str, Any]:
    """
    G≈Ç√≥wna funkcja do integracji z walidatorem.
    
    Returns:
        {
            "passed": bool,
            "severity": "CRITICAL" | "WARNING" | "OK",
            "score": 0-100,
            "issues": [...],
            "action": "CONTINUE" | "FIX_AND_RETRY" | "REWRITE"
        }
    """
    analysis = detect_fake_humanization(text)
    tips = generate_natural_humanization_tips(analysis)
    
    # Determine action
    if analysis["severity"] == "CRITICAL":
        action = "REWRITE"
        passed = False
    elif analysis["severity"] == "WARNING":
        action = "FIX_AND_RETRY"
        passed = False
    else:
        action = "CONTINUE"
        passed = True
    
    return {
        "passed": passed,
        "severity": analysis["severity"],
        "score": analysis["score"],
        "issues": analysis["issues"],
        "recommendations": analysis["recommendations"],
        "tips": tips,
        "action": action,
        "metrics": analysis["metrics"]
    }


if __name__ == "__main__":
    # Test z tekstem ze screenshota
    test_text = """
Porwanie rodzicielskie to sytuacja, w kt√≥rej jeden z rodzic√≥w samowolnie zabiera lub zatrzymuje dziecko, mimo ≈ºe drugi rodzic r√≥wnie≈º posiada prawa do sprawowania opieki. Najczƒô≈õciej dotyczy to przypadk√≥w, gdy oboje rodzice majƒÖ pe≈Çniƒô praw rodzicielskich, a mimo to jeden z nich jednostronnie decyduje o zmianie miejsca pobytu dziecka. To wa≈ºne.

W praktyce nie chodzi o klasyczne porwanie przez osobƒô trzeciƒÖ. SprawcƒÖ jest rodzic, kt√≥ry dzia≈Ça bez porozumienia i bez zgody drugiego rodzica, naruszajƒÖc ustalony porzƒÖdek prawny. Organy rozstrzygajƒÖce takie sprawy nie koncentrujƒÖ siƒô na konflikcie miƒôdzy doros≈Çymi, lecz na tym, czy zachowanie jednego z nich pozostaje zgodne z dobrem dziecka i zapewnia mu stabilne warunki rozwoju.

Kluczowe znaczenie ma odr√≥≈ºnienie porwania rodzicielskiego od uprowadzenia dziecka w rozumieniu prawa karnego. W pierwszym przypadku sprawcƒÖ jest rodzic posiadajƒÖcy formalne uprawnienia, kt√≥ry dzia≈Ça jednostronnie, lecz niekoniecznie ≈Çamie przepisy karne. Taka sytuacja jest najczƒô≈õciej oceniana na gruncie prawa rodzinnego.

Inaczej wyglƒÖda to przy uprowadzeniu, o kt√≥rym mowa w art. 211 kodeksu karnego. Do odpowiedzialno≈õci karnej mo≈ºe doj≈õƒá wtedy, gdy osoba nieuprawniona albo rodzic pozbawiony lub ograniczony we w≈Çadzy zatrzymuje dziecko wbrew orzeczeniu organu sƒÖdowego. W orzecznictwie podkre≈õla siƒô, ≈ºe decydujƒÖce znaczenie ma naruszenie obowiƒÖzujƒÖcego rozstrzygniƒôcia oraz faktyczne pozbawienie drugiego rodzica mo≈ºliwo≈õci wykonywania jego praw. Sprawd≈∫ to.

Odpowied≈∫ na to pytanie nie jest jednoznaczna. Sam fakt, ≈ºe rodzic zabiera dziecko bez zgody drugiego rodzica, nie zawsze oznacza pope≈Çnienie przestƒôpstwa. W polskim systemie prawnym kluczowe jest to, czy dosz≈Ço do naruszenia konkretnego orzeczenia lub czy w≈Çadza rodzicielska zosta≈Ça wcze≈õniej ograniczona.

Je≈ºeli jednak porwanie prowadzi do trwa≈Çego zerwania relacji, ukrywania miejsca pobytu albo odbywa siƒô wbrew wiƒÖ≈ºƒÖcemu rozstrzygniƒôciu, mo≈ºe zostaƒá uznane za dzia≈Çanie bezprawne. W takich sprawach wymiar sprawiedliwo≈õci analizuje okoliczno≈õci indywidualnie, biorƒÖc pod uwagƒô wp≈Çyw zdarzenia na dziecko oraz to, czy drugi rodzic zosta≈Ç realnie pozbawiony kontaktu. To wa≈ºne.
"""
    
    result = validate_humanization_quality(test_text)
    
    print("=== FAKE HUMANIZATION DETECTOR ===\n")
    print(f"Passed: {result['passed']}")
    print(f"Severity: {result['severity']}")
    print(f"Score: {result['score']}")
    print(f"Action: {result['action']}")
    print(f"\nIssues:")
    for issue in result['issues']:
        print(f"  - {issue}")
    print(f"\nMetrics: {result['metrics']}")
    print(f"\nTips:")
    for tip in result['tips']:
        print(f"  {tip}")
