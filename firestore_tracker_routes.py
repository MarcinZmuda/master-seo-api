import os
import json
from flask import Blueprint, jsonify
from firebase_admin import firestore
import spacy
import google.generativeai as genai

tracker_routes = Blueprint("tracker_routes", __name__)

# ≈Åadowanie spaCy (raz przy starcie aplikacji)
nlp = spacy.load("pl_core_news_sm")

# Konfiguracja Gemini (Pobierana ze zmiennych ≈õrodowiskowych Render)
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# ===========================================================
# ‚öñÔ∏è GEMINI JUDGE (Sƒôdzia z TwojƒÖ listƒÖ Banned + My≈õlnik)
# ===========================================================
def evaluate_with_gemini(text, meta_trace):
    """
    Wysy≈Ça tekst do Gemini w celu oceny jako≈õci (Glass Box).
    Zwraca werdykt JSON: pass/fail, score, feedback.
    """
    if not GEMINI_API_KEY:
        # Fallback: Je≈õli brak klucza, przepuszczamy tekst (Fail Open)
        return {"pass": True, "quality_score": 100, "feedback_for_writer": "Brak klucza Gemini - skip check"}

    model = genai.GenerativeModel('gemini-1.5-flash')
    
    # Pobieramy metadane od GPT (intencja i rytm)
    intent = meta_trace.get("execution_intent", "Brak")
    rhythm = meta_trace.get("rhythm_pattern_used", "Brak")
    
   # üî• ZAKTUALIZOWANA, ROZSZERZONA LISTA DLA GEMINI JUDGE
    banned_phrases_list = """
    1. WYPE≈ÅNIACZE STARTOWE: "W dzisiejszych czasach", "W dobie...", "Od zarania dziej√≥w", "W niniejszym artykule", "Coraz wiƒôcej os√≥b".
    2. LENIWE ≈ÅƒÑCZNIKI: "Warto zauwa≈ºyƒá", "Nale≈ºy wspomnieƒá", "Warto dodaƒá", "Co wiƒôcej", "Ponadto", "Kolejnym aspektem".
    3. ZAKO≈ÉCZENIA: "PodsumowujƒÖc", "ReasumujƒÖc", "W ostatecznym rozrachunku", "BiorƒÖc wszystko pod uwagƒô".
    4. IDIOMY AI: "Gra warta ≈õwieczki", "Strza≈Ç w dziesiƒÖtkƒô", "Szyte na miarƒô", "Klucz do sukcesu".
    5. ASEKURANCTWO: "Wszystko zale≈ºy od indywidualnych preferencji", "Ka≈ºde rozwiƒÖzanie ma wady i zalety".
    6. WZMOCNIENIA: "Nie ma wƒÖtpliwo≈õci", "Bez wƒÖtpienia", "Z ca≈ÇƒÖ pewno≈õciƒÖ", "Niezwykle wa≈ºne".
    7. ZNAKI: "‚Äî" (D≈Çugi my≈õlnik/Pauza - AI nadu≈ºywa go do wtrƒÖce≈Ñ).
    """

    prompt = f"""
    Jeste≈õ bezwzglƒôdnym SƒôdziƒÖ Jako≈õci SEO (Quality Gatekeeper).
    Oceniasz fragment tekstu pod kƒÖtem naturalno≈õci, stylu HEAR i braku "AI-izm√≥w".
    
    PARAMETRY AUTORA:
    - Intencja: {intent}
    - Deklarowany Rytm: {rhythm}
    
    LISTA ZAKAZANYCH FRAZ:
    {banned_phrases_list}
    
    KRYTERIA PUNKTACJI (0-100):
    - < 50 (ODRZUT): WystƒôpujƒÖ zakazane frazy (w tym d≈Çugie my≈õlniki "‚Äî"), styl bota, listy punktowane.
    - 50-69 (S≈ÅABY): Nudny, powtarzalny schemat zda≈Ñ.
    - 70-89 (DOBRY): Naturalny jƒôzyk, brak zakazanych fraz, dobra asymetria.
    - 90+ (WYBITNY): Ludzki styl, flow, nieszablonowe s≈Çownictwo.

    Zwr√≥ƒá JSON:
    {{
        "pass": true/false, (false je≈õli sƒÖ zakazane s≈Çowa LUB score < 70)
        "quality_score": (0-100),
        "feedback_for_writer": "Instrukcja co poprawiƒá (np. 'Usu≈Ñ d≈Çugie my≈õlniki', 'Zmie≈Ñ rytm')"
    }}
    
    TEKST DO OCENY:
    "{text}"
    """
    try:
        response = model.generate_content(prompt)
        # Czyszczenie odpowiedzi z markdowna (```json ... ```)
        clean = response.text.replace("```json", "").replace("```", "").strip()
        return json.loads(clean)
    except Exception as e:
        print(f"Gemini Error: {e}")
        # W razie awarii Gemini dajemy bezpieczny wynik, ale z ostrze≈ºeniem
        return {"pass": True, "quality_score": 50, "feedback_for_writer": "Gemini Error"}


# ===========================================================
# üîß Helpery do liczenia (Row-Level Lemma Logic)
# ===========================================================
def count_phrase_in_text_lemmas(text_lemma_list, phrase_lemma_str):
    """
    Sprawdza wystƒÖpienie sekwencji lemat√≥w (phrase_lemma_str) w li≈õcie (text_lemma_list).
    Dzia≈Ça jak "okno przesuwne".
    """
    target_tokens = phrase_lemma_str.split()
    if not target_tokens:
        return 0
    
    target_len = len(target_tokens)
    text_len = len(text_lemma_list)
    count = 0

    for i in range(text_len - target_len + 1):
        if text_lemma_list[i : i + target_len] == target_tokens:
            count += 1
    return count


def compute_status(actual, target_min, target_max):
    if actual < target_min:
        return "UNDER"
    if actual > target_max:
        return "OVER"
    return "OK"


def global_keyword_stats(keywords_state):
    under = sum(1 for v in keywords_state.values() if v["status"] == "UNDER")
    over = sum(1 for v in keywords_state.values() if v["status"] == "OVER")
    locked = 1 if over >= 4 else 0
    ok = sum(1 for v in keywords_state.values() if v["status"] == "OK")
    return under, over, locked, ok


# ===========================================================
# üß† G≈Å√ìWNA FUNKCJA (QUALITY GATE + ZLICZANIE)
# ===========================================================
def process_batch_in_firestore(project_id: str, batch_text: str, meta_trace: dict = None):
    db = firestore.client()
    doc_ref = db.collection("seo_projects").document(project_id)
    doc = doc_ref.get()

    if not doc.exists:
        return {"error": "Project not found", "status": 404}

    # -------------------------------------------------------
    # 1. QUALITY GATE (GEMINI)
    # -------------------------------------------------------
    gemini_verdict = {"pass": True, "quality_score": 100}
    
    if meta_trace:
        gemini_verdict = evaluate_with_gemini(batch_text, meta_trace)
    
    # üî• PR√ìG JAKO≈öCI = 70 punkt√≥w
    QUALITY_THRESHOLD = 70

    # Je≈õli werdykt to FAIL albo punkty < 70 -> ODRZUCAMY
    if not gemini_verdict.get("pass", True) or gemini_verdict.get("quality_score", 100) < QUALITY_THRESHOLD:
        return {
            "status": "REJECTED_QUALITY",
            "error": "Quality Gate Failed",
            "gemini_feedback": gemini_verdict, # To wraca do GPT
            "quality_alert": True,
            "info": f"Odrzucono: Wynik {gemini_verdict.get('quality_score')} < {QUALITY_THRESHOLD} lub wykryto zakazane frazy."
        }

    # -------------------------------------------------------
    # 2. ZLICZANIE FRAZ (Tylko je≈õli Quality Gate = Pass)
    # -------------------------------------------------------
    data = doc.to_dict()
    keywords_state = data.get("keywords_state", {})

    # Lematyzacja tekstu batcha
    doc_nlp = nlp(batch_text)
    text_lemma_list = [t.lemma_.lower() for t in doc_nlp if t.is_alpha]

    # Iteracja po frazach z briefu (Row-Level)
    for original_keyword, meta in keywords_state.items():
        search_lemma = meta.get("search_lemma", "")
        
        # Fallback dla starszych projekt√≥w
        if not search_lemma:
            doc_tmp = nlp(original_keyword)
            search_lemma = " ".join([t.lemma_.lower() for t in doc_tmp if t.is_alpha])

        # Liczenie wystƒÖpie≈Ñ
        occurrences = count_phrase_in_text_lemmas(text_lemma_list, search_lemma)
        
        # Aktualizacja stanu
        meta["actual_uses"] += occurrences
        meta["status"] = compute_status(meta["actual_uses"], meta["target_min"], meta["target_max"])

    # Statystyki globalne
    under, over, locked, ok = global_keyword_stats(keywords_state)
    forced_regen = over >= 10
    emergency_exit = locked >= 1

    # -------------------------------------------------------
    # 3. ZAPIS DO BAZY
    # -------------------------------------------------------
    batch_entry = {
        "text": batch_text,
        "gemini_audit": gemini_verdict,
        "summary": {"under": under, "over": over, "locked": locked, "ok": ok}
    }

    if "batches" not in data:
        data["batches"] = []
    
    data["batches"].append(batch_entry)
    data["total_batches"] = len(data["batches"])
    data["keywords_state"] = keywords_state

    doc_ref.set(data)

    # -------------------------------------------------------
    # 4. ODPOWIED≈π DLA GPT
    # -------------------------------------------------------
    meta_prompt_summary = f"UNDER={under}, OVER={over}, LOCKED={locked} | Quality={gemini_verdict.get('quality_score')}%"

    return {
        "status": "BATCH_ACCEPTED",
        "counting_mode": "row_lemma",
        "gemini_feedback": gemini_verdict,
        "quality_alert": False,
        "regeneration_triggered": forced_regen,
        "emergency_exit_triggered": emergency_exit,
        "keywords_report": [
            {
                "keyword": kw,
                "actual_uses": meta["actual_uses"],
                "target_range": f"{meta['target_min']}‚Äì{meta['target_max']}",
                "status": meta["status"],
                "priority_instruction": ("INCREASE" if meta["status"] == "UNDER" else "DECREASE" if meta["status"] == "OVER" else "IGNORE")
            }
            for kw, meta in keywords_state.items()
        ],
        "meta_prompt_summary": meta_prompt_summary
    }


# ===========================================================
# üìå ENDPOINTY GET (Do podglƒÖdu w dashboardzie)
# ===========================================================
@tracker_routes.get("/api/project/<project_id>")
def get_project(project_id):
    db = firestore.client()
    doc = db.collection("seo_projects").document(project_id).get()
    
    if not doc.exists:
        return jsonify({"error": "Project not found"}), 404

    return jsonify(doc.to_dict()), 200


@tracker_routes.get("/api/project/<project_id>/keywords")
def get_keywords_state(project_id):
    db = firestore.client()
    doc = db.collection("seo_projects").document(project_id).get()
    
    if not doc.exists:
        return jsonify({"error": "Project not found"}), 404

    data = doc.to_dict()
    return jsonify(data.get("keywords_state", {})), 200
