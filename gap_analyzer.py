"""
===============================================================================
üìè DEPTH SCORER v1.0 ‚Äî Section Quality Measurement
===============================================================================
Mierzy czy sekcja H2 wnosi G≈ÅƒòBIƒò merytorycznƒÖ, czy jest powierzchowna.

Sygna≈Çy g≈Çƒôbi (wiƒôcej = lepiej):
- Konkretne liczby, daty, kwoty
- Nazwane instytucje (nie "w≈Ça≈õciwy sƒÖd" tylko "SƒÖd Okrƒôgowy w Warszawie")
- Cytowania prawne, naukowe
- Wyja≈õnienia przyczynowe (dlaczego, poniewa≈º)
- Por√≥wnania z alternatywami
- WyjƒÖtki od regu≈Çy
- Praktyczne porady

Integracja:
1. Standalone: score_section_depth() per sekcja H2
2. MoE Expert #11: DepthExpert w moe_batch_validator.py
3. Pre-batch hint: get_depth_hints() ‚Üí instrukcja dla agenta

Autor: BRAJEN Team
Data: 2025
===============================================================================
"""

import re
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field, asdict


# ================================================================
# üìä KONFIGURACJA
# ================================================================

@dataclass
class DepthSignal:
    """Definicja jednego sygna≈Çu g≈Çƒôbi."""
    name: str
    description: str
    weight: float
    patterns: List[str]     # regex patterns do wykrycia


# Sygna≈Çy g≈Çƒôbi ‚Äî posortowane po wadze (najwa≈ºniejsze pierwsze)
DEPTH_SIGNALS: List[DepthSignal] = [
    # ‚ïê‚ïê‚ïê TWARDE DANE ‚Äî najwy≈ºsza waga ‚ïê‚ïê‚ïê
    DepthSignal(
        name="legal_reference",
        description="Cytowanie artyku≈Çu ustawy, wyroku, rozporzƒÖdzenia",
        weight=2.5,
        patterns=[
            r'art\.\s*\d+\s*(?:¬ß\s*\d+)?\s*(?:k\.c\.|k\.p\.c\.|k\.r\.o\.|k\.k\.|k\.p\.|k\.s\.h\.|k\.w\.|u\.s\.p\.)',
            r'(?:Dz\.?\s*U\.?\s*(?:z\s*)?\d{4})',
            r'(?:wyrok|uchwa≈Ça|postanowienie)\s+(?:SN|SA|SO|SR|NSA|WSA|TK)',
            r'(?:rozporzƒÖdzeni[eua])\s+(?:Ministra|Prezesa|Rady)',
        ]
    ),
    DepthSignal(
        name="scientific_reference",
        description="Cytowanie badania, publikacji, danych statystycznych",
        weight=2.5,
        patterns=[
            r'(?:PMID|DOI|NCT)\s*:?\s*[\d/]+',
            r'(?:badanie|metaanaliza|przeglƒÖd systematyczny|metaanalizƒô)\s+(?:[A-Z][a-zƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈º]+)',
            r'(?:wg|wed≈Çug)\s+(?:bada≈Ñ|danych|raportu|publikacji|statystyk)',
            r'(?:opublikowan[aoey]\s+w|w\s+czasopi≈õmie|w\s+journalu)',
        ]
    ),
    DepthSignal(
        name="specific_number",
        description="Konkretna liczba/kwota/procent (nie 'oko≈Ço')",
        weight=2.0,
        patterns=[
            r'\b\d+[\s,.]\d*\s*(?:z≈Ç|z≈Çotych|PLN|EUR|USD|%|procent)',
            r'\b\d+\s*(?:tygodni|miesiƒôcy|dni|lat|godzin|minut)',
            r'(?:od|do|miƒôdzy)\s+\d+\s+(?:a|do|i)\s+\d+',
            r'\b\d{2,}\s*(?:m¬≤|m2|km|ha|cm|mm|mg|ml|kg)',
        ]
    ),
    DepthSignal(
        name="named_institution",
        description="Nazwana instytucja (nie 'w≈Ça≈õciwy sƒÖd' ‚Äî konkretna nazwa)",
        weight=1.8,
        patterns=[
            r'(?:SƒÖd\s+(?:Okrƒôgowy|Rejonowy|Najwy≈ºszy|Apelacyjny)\s+(?:w\s+)?[A-ZƒÑƒÜƒò≈Å≈É√ì≈ö≈π≈ª][a-zƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈º]+)',
            r'(?:(?:Ministerstwo|UrzƒÖd|Zak≈Çad|Agencja|Instytut|Centrum|Szpital|Klinika)\s+[A-ZƒÑƒÜƒò≈Å≈É√ì≈ö≈π≈ª][a-zƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈º\s]{3,})',
            r'(?:ZUS|NFZ|GUS|PZH|AOTMiT|PARP|UOKiK|KRS|CEIDG|GIF|PIP|UODO)',
        ]
    ),
    DepthSignal(
        name="date_reference",
        description="Konkretna data/rok/okres",
        weight=1.5,
        patterns=[
            r'\b(?:20[12]\d|19\d{2})\s*(?:r\.|roku)',
            r'\b\d{1,2}\s+(?:stycznia|lutego|marca|kwietnia|maja|czerwca|lipca|sierpnia|wrze≈õnia|pa≈∫dziernika|listopada|grudnia)',
            r'(?:od\s+(?:20[12]\d|19\d{2})\s+(?:r\.|roku))',
            r'(?:nowelizacj[aiƒô]\s+z\s+\d{1,2})',
        ]
    ),

    # ‚ïê‚ïê‚ïê G≈ÅƒòBIA WYJA≈öNIENIOWA ‚ïê‚ïê‚ïê
    DepthSignal(
        name="causal_explanation",
        description="Wyja≈õnienie przyczynowe (dlaczego, poniewa≈º, w wyniku)",
        weight=1.5,
        patterns=[
            r'(?:poniewa≈º|dlatego\s+≈ºe|gdy≈º|bowiem|albowiem)',
            r'(?:w wyniku|na skutek|wskutek|w rezultacie|co prowadzi do)',
            r'(?:przyczynƒÖ|powodem|skutkiem)\s+(?:jest|mo≈ºe byƒá|bywa)',
            r'(?:wynika\s+to\s+z|t≈Çumaczy\s+to)',
        ]
    ),
    DepthSignal(
        name="exception_case",
        description="WyjƒÖtek od regu≈Çy (chyba ≈ºe, z wyjƒÖtkiem, jednak)",
        weight=1.5,
        patterns=[
            r'(?:z wyjƒÖtkiem|wyjƒÖtkowo|chyba\s+≈ºe|o ile nie)',
            r'(?:jednak≈ºe|niemniej jednak|mimo to|aczkolwiek|pomimo)',
            r'(?:uwaga:|zastrze≈ºenie:|wyjƒÖtek:)',
            r'(?:nie dotyczy to|nie stosuje siƒô do|wy≈ÇƒÖczeni[ea])',
        ]
    ),
    DepthSignal(
        name="comparison",
        description="Por√≥wnanie z alternatywƒÖ (w odr√≥≈ºnieniu od, zamiast)",
        weight=1.2,
        patterns=[
            r'(?:w odr√≥≈ºnieniu od|w przeciwie≈Ñstwie do|w por√≥wnaniu z)',
            r'(?:z jednej strony|z drugiej strony)',
            r'(?:zamiast|lepsze ni≈º|gorsze ni≈º|szybsze ni≈º|skuteczniejsz)',
            r'(?:w odr√≥≈ºnieniu|w por√≥wnaniu)',
        ]
    ),

    # ‚ïê‚ïê‚ïê SYGNA≈ÅY DO≈öWIADCZENIA ‚ïê‚ïê‚ïê
    DepthSignal(
        name="practical_advice",
        description="Praktyczna porada (w praktyce, z do≈õwiadczenia)",
        weight=1.8,
        patterns=[
            r'(?:w praktyce|z do≈õwiadczenia|z naszego do≈õwiadczenia)',
            r'(?:typowo|najczƒô≈õciej|statystycznie)',
            r'(?:klienci|pacjenci)\s+(?:czƒôsto|najczƒô≈õciej|zwykle)\s+(?:pytajƒÖ|zg≈ÇaszajƒÖ|nie wiedzƒÖ)',
            r'(?:czƒôsty b≈ÇƒÖd|czƒôstym b≈Çƒôdem|czƒôsto pope≈Çnianym)',
        ]
    ),
    DepthSignal(
        name="process_steps",
        description="Kroki procedury (krok 1, etap, najpierw/potem)",
        weight=1.0,
        patterns=[
            r'(?:krok\s+\d|etap\s+\d|faza\s+\d)',
            r'(?:najpierw|nastƒôpnie|potem|w kolejnym kroku|na ko≈Ñcu)',
            r'(?:procedura\s+(?:obejmuje|sk≈Çada siƒô|wyglƒÖda))',
        ]
    ),
]


# ================================================================
# üìä SCORING
# ================================================================

def score_section_depth(
    section_text: str,
    h2_title: str,
    is_ymyl: bool = False
) -> Dict:
    """
    Ocenia g≈Çƒôbiƒô merytorycznƒÖ sekcji H2.

    Args:
        section_text: Tekst sekcji (pod jednym H2)
        h2_title: Tytu≈Ç H2
        is_ymyl: Czy artyku≈Ç YMYL (wy≈ºsze progi)

    Returns:
        {
            "depth_score": 0-100,
            "signals_found": {...},
            "signals_missing": [...],
            "is_shallow": bool,
            "word_count": int,
            "recommendation": str
        }
    """
    if not section_text or not section_text.strip():
        return {
            "depth_score": 0,
            "signals_found": {},
            "signals_missing": [{"signal": s.name, "description": s.description} for s in DEPTH_SIGNALS[:5]],
            "is_shallow": True,
            "word_count": 0,
            "recommendation": f"Sekcja '{h2_title}' jest pusta."
        }

    found_signals = {}
    total_weight = 0.0
    max_weight = sum(s.weight for s in DEPTH_SIGNALS)

    for signal in DEPTH_SIGNALS:
        for pattern in signal.patterns:
            try:
                if re.search(pattern, section_text, re.IGNORECASE):
                    found_signals[signal.name] = {
                        "description": signal.description,
                        "weight": signal.weight
                    }
                    total_weight += signal.weight
                    break  # Jeden match per signal wystarczy
            except re.error:
                continue

    # Bonus za d≈Çugo≈õƒá (sekcja >200 s≈Ç√≥w = dodatkowe punkty, max 15%)
    word_count = len(section_text.split())
    length_bonus = min(0.15, word_count / 2000)

    # Oblicz score
    raw_score = (total_weight / max_weight) + length_bonus
    depth_score = min(100, int(raw_score * 100))

    # Progi ‚Äî YMYL wymaga wy≈ºszych standard√≥w
    threshold = 40 if is_ymyl else 30

    # BrakujƒÖce sygna≈Çy (posortowane po wadze, najwa≈ºniejsze pierwsze)
    missing = [
        {"signal": s.name, "description": s.description, "weight": s.weight}
        for s in DEPTH_SIGNALS
        if s.name not in found_signals
    ]
    missing.sort(key=lambda m: -m["weight"])

    # Rekomendacja
    recommendation = ""
    if depth_score < threshold:
        top_missing = missing[:3]
        recommendation = (
            f"Sekcja '{h2_title}' jest p≈Çytka (score: {depth_score}/{threshold}). "
            f"Dodaj: {', '.join(m['description'] for m in top_missing)}"
        )

    return {
        "depth_score": depth_score,
        "signals_found": found_signals,
        "signals_missing": missing[:5],
        "is_shallow": depth_score < threshold,
        "word_count": word_count,
        "threshold": threshold,
        "recommendation": recommendation
    }


# ================================================================
# üìã BATCH-LEVEL DEPTH ANALYSIS
# ================================================================

def analyze_batch_depth(
    batch_text: str,
    h2_list: List[str],
    is_ymyl: bool = False
) -> Dict:
    """
    Analizuje g≈Çƒôbiƒô wszystkich sekcji w batchu.

    Args:
        batch_text: Pe≈Çny tekst batcha
        h2_list: Lista H2 w tym batchu
        is_ymyl: Czy YMYL

    Returns:
        {
            "overall_score": 0-100,
            "sections": [{"h2": ..., "score": ..., "is_shallow": ...}],
            "shallow_sections": [...],
            "fix_instructions": [...]
        }
    """
    if not batch_text or not h2_list:
        return {
            "overall_score": 0,
            "sections": [],
            "shallow_sections": [],
            "fix_instructions": []
        }

    # Podziel tekst na sekcje po H2
    sections = _split_by_h2(batch_text, h2_list)

    section_results = []
    shallow = []
    fixes = []

    for h2, text in sections.items():
        result = score_section_depth(text, h2, is_ymyl)
        section_results.append({
            "h2": h2,
            "depth_score": result["depth_score"],
            "is_shallow": result["is_shallow"],
            "word_count": result["word_count"],
            "signals_found": list(result["signals_found"].keys()),
            "top_missing": [m["description"] for m in result["signals_missing"][:2]]
        })

        if result["is_shallow"]:
            shallow.append(h2)
            if result["recommendation"]:
                fixes.append(result["recommendation"])

    # Overall score = ≈õrednia wa≈ºona (d≈Çu≈ºsze sekcje wa≈ºƒÖ wiƒôcej)
    if section_results:
        total_words = sum(s["word_count"] for s in section_results)
        if total_words > 0:
            overall = sum(
                s["depth_score"] * s["word_count"] / total_words
                for s in section_results
            )
        else:
            overall = sum(s["depth_score"] for s in section_results) / len(section_results)
    else:
        overall = 0

    return {
        "overall_score": int(overall),
        "sections": section_results,
        "shallow_sections": shallow,
        "shallow_count": len(shallow),
        "fix_instructions": fixes[:5]
    }


def _split_by_h2(text: str, h2_list: List[str]) -> Dict[str, str]:
    """Dzieli tekst na sekcje po H2."""
    sections = {}
    text_lower = text.lower()

    # Znajd≈∫ pozycje H2 w tek≈õcie
    h2_positions = []
    for h2 in h2_list:
        h2_lower = h2.lower().strip()
        # Szukaj H2 z r√≥≈ºnymi formatami (markdown, plain)
        for prefix in ['## ', '### ', '']:
            pos = text_lower.find(prefix + h2_lower)
            if pos != -1:
                h2_positions.append((pos, h2))
                break

    # Posortuj po pozycji
    h2_positions.sort(key=lambda x: x[0])

    # WyciƒÖgnij tekst miƒôdzy H2
    for i, (pos, h2) in enumerate(h2_positions):
        start = pos + len(h2) + 5  # +5 na prefix i newline
        end = h2_positions[i + 1][0] if i + 1 < len(h2_positions) else len(text)
        section_text = text[start:end].strip()
        sections[h2] = section_text

    # Je≈õli nie znaleziono ≈ºadnego H2, traktuj ca≈Çy tekst jako jednƒÖ sekcjƒô
    if not sections and h2_list:
        sections[h2_list[0]] = text

    return sections


# ================================================================
# üìù PRE-BATCH HINTS
# ================================================================

def get_depth_hints(
    h2_title: str,
    domain: str = "prawo",
    is_ymyl: bool = False
) -> str:
    """
    Generuje hint dla agenta GPT ‚Äî jakie sygna≈Çy g≈Çƒôbi dodaƒá.

    Args:
        h2_title: Tytu≈Ç aktualnego H2
        domain: Domena artyku≈Çu
        is_ymyl: Czy YMYL

    Returns:
        Instrukcja tekstowa dla agenta
    """
    hints = []

    if domain == "prawo" or is_ymyl:
        hints.extend([
            "Cytuj konkretny artyku≈Ç ustawy (art. X k.c./k.r.o./k.p.c.)",
            "Podaj nazwƒô sƒÖdu (SƒÖd Okrƒôgowy w..., nie 'w≈Ça≈õciwy sƒÖd')",
            "Dodaj konkretny termin lub kwotƒô (np. '14 dni', '300 z≈Ç')",
        ])
    elif domain == "medycyna":
        hints.extend([
            "Podaj konkretnƒÖ dawkƒô, czas trwania lub skuteczno≈õƒá (%)",
            "Nazwij badanie lub wytyczne (np. 'wg wytycznych PTG z 2023')",
            "Dodaj wyjƒÖtek lub przeciwwskazanie",
        ])
    else:
        hints.extend([
            "Podaj konkretnƒÖ liczbƒô lub statystykƒô",
            "Wymie≈Ñ nazwanƒÖ instytucjƒô lub ≈∫r√≥d≈Ço",
            "Dodaj por√≥wnanie z alternatywƒÖ",
        ])

    # Uniwersalne
    hints.extend([
        "Wyja≈õnij DLACZEGO (przyczyna), nie tylko CO (fakt)",
        "Dodaj wyjƒÖtek od opisanej regu≈Çy",
    ])

    return (
        f"üìè G≈ÅƒòBIA SEKCJI \"{h2_title}\": "
        + " | ".join(hints[:4])
    )


# ================================================================
# üîå MOE EXPERT INTERFACE
# ================================================================
# Gotowy interface do u≈ºycia jako Expert #11 w moe_batch_validator.py
#
# W moe_batch_validator.py dodaj:
#
# try:
#     from depth_scorer import analyze_batch_depth, get_depth_hints
#     DEPTH_SCORER_AVAILABLE = True
# except ImportError:
#     DEPTH_SCORER_AVAILABLE = False
#
# Nastƒôpnie w validate_batch_moe(), po PERPLEXITY EXPERT:
#
#     if DEPTH_SCORER_AVAILABLE:
#         try:
#             h2_list = [current_h2] if current_h2 else []
#             is_ymyl = project_data.get("is_ymyl", False)
#             depth_result = analyze_batch_depth(
#                 corrected_text or batch_text, h2_list, is_ymyl
#             )
#             experts_summary["depth"] = {
#                 "enabled": True,
#                 "overall_score": depth_result["overall_score"],
#                 "shallow_count": depth_result["shallow_count"],
#             }
#             for fix in depth_result["fix_instructions"][:3]:
#                 fix_instructions.append(f"[DEPTH] {fix}")
#         except Exception as e:
#             experts_summary["depth"] = {"enabled": False, "error": str(e)[:100]}
# ================================================================


# ================================================================
# EXPORTS
# ================================================================

__all__ = [
    'score_section_depth',
    'analyze_batch_depth',
    'get_depth_hints',
    'DEPTH_SIGNALS',
]
