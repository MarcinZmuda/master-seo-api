"""
===============================================================================
üìä MATTR CALCULATOR v41.0 - Moving Average Type-Token Ratio
===============================================================================

PROBLEM Z PROSTYM TTR:
TTR (unique_words / total_words) spada z d≈Çugo≈õciƒÖ tekstu.
Tekst 500 s≈Ç√≥w mo≈ºe mieƒá TTR 0.60, ale tekst 5000 s≈Ç√≥w tylko TTR 0.30.
To b≈ÇƒÖd wielko≈õci pr√≥bki - nie mo≈ºna por√≥wnywaƒá tekst√≥w r√≥≈ºnej d≈Çugo≈õci.

ROZWIƒÑZANIE - MATTR:
Moving Average Type-Token Ratio oblicza TTR w "oknach" (np. 500 s≈Ç√≥w)
i u≈õrednia wyniki. Dziƒôki temu:
- Wynik jest por√≥wnywalny miƒôdzy tekstami r√≥≈ºnej d≈Çugo≈õci
- Lokalnie mierzy r√≥≈ºnorodno≈õƒá s≈Çownictwa
- Bardziej wiarygodny dla detekcji AI

PROGI (oparte na empirycznych obserwacjach):
- MATTR < 0.35 = CRITICAL (niskie zr√≥≈ºnicowanie, sygna≈Ç AI)
- MATTR 0.35-0.42 = WARNING (strefa podejrzana)
- MATTR > 0.42 = OK (dobra r√≥≈ºnorodno≈õƒá)

===============================================================================
"""

import re
import statistics
from typing import Dict, List, Any, Set
from dataclasses import dataclass
from enum import Enum


class Severity(Enum):
    OK = "OK"
    WARNING = "WARNING"
    CRITICAL = "CRITICAL"


# ============================================================================
# POLSKIE STOP WORDS (do wykluczenia z analizy)
# ============================================================================

POLISH_STOP_WORDS: Set[str] = {
    # Sp√≥jniki
    "i", "oraz", "a", "ale", "lub", "albo", "jednak", "wiƒôc", "bo", "≈ºe",
    "czy", "je≈õli", "gdy", "kiedy", "choƒá", "chocia≈º", "poniewa≈º", "gdy≈º",
    
    # Przyimki
    "w", "we", "na", "z", "ze", "do", "od", "przy", "po", "za", "przed",
    "nad", "pod", "miƒôdzy", "przez", "dla", "bez", "o", "u", "ku",
    
    # Zaimki
    "ja", "ty", "on", "ona", "ono", "my", "wy", "oni", "one",
    "mnie", "mi", "ciƒô", "ci", "go", "mu", "jej", "nas", "was", "im", "ich",
    "ten", "ta", "to", "ci", "te", "tamten", "tamta", "tamto",
    "kt√≥ry", "kt√≥ra", "kt√≥re", "kt√≥rzy", "kt√≥rych", "kt√≥rej", "kt√≥remu",
    "co", "kto", "jaki", "jaka", "jakie", "jakiego", "jakiej",
    "sam", "sama", "samo", "sami", "same",
    "siƒô", "siebie", "sobie", "sobƒÖ",
    
    # Czasowniki posi≈Çkowe
    "byƒá", "jest", "sƒÖ", "by≈Ç", "by≈Ça", "by≈Ço", "byli", "by≈Çy",
    "bƒôdzie", "bƒôdƒÖ", "bƒôdƒô", "bƒôdziesz", "bƒôdziemy", "bƒôdziecie",
    "mieƒá", "ma", "majƒÖ", "mia≈Ç", "mia≈Ça", "mia≈Ço", "mieli", "mia≈Çy",
    "zostaƒá", "zostanie", "zostanƒÖ", "zosta≈Ç", "zosta≈Ça", "zosta≈Ço",
    
    # Partyku≈Çy i przys≈Ç√≥wki
    "nie", "tak", "te≈º", "tak≈ºe", "r√≥wnie≈º", "tylko", "ju≈º", "jeszcze",
    "bardzo", "bardziej", "najbardziej", "do≈õƒá", "dosyƒá", "zbyt",
    "tu", "tutaj", "tam", "teraz", "wtedy", "zawsze", "nigdy",
    "mo≈ºe", "mo≈ºna", "trzeba", "nale≈ºy", "warto",
    
    # Liczebniki
    "jeden", "jedna", "jedno", "dwa", "dwie", "trzy", "cztery", "piƒôƒá",
    "pierwszy", "druga", "trzeci",
    
    # Inne czƒôste
    "jako", "jak", "gdzie", "czym", "tym", "tego", "tej", "tych",
    "ile", "tyle", "kilka", "wiele", "wielu", "wszystko", "wszystkie",
    "ka≈ºdy", "ka≈ºda", "ka≈ºde", "≈ºaden", "≈ºadna", "≈ºadne",
    "inny", "inna", "inne", "innych",
}


# ============================================================================
# KONFIGURACJA
# ============================================================================

@dataclass
class MATTRConfig:
    """Konfiguracja kalkulatora MATTR."""
    
    # Rozmiar okna (w s≈Çowach)
    WINDOW_SIZE: int = 500
    
    # Minimalna liczba s≈Ç√≥w do analizy MATTR
    MIN_WORDS_FOR_MATTR: int = 500
    
    # Progi MATTR
    MATTR_CRITICAL_LOW: float = 0.35
    MATTR_WARNING_LOW: float = 0.42
    MATTR_OK_MIN: float = 0.42
    MATTR_OK_MAX: float = 0.65
    MATTR_WARNING_HIGH: float = 0.70  # Zbyt wysokie mo≈ºe oznaczaƒá nadmiar ≈ºargonu
    
    # Czy wykluczaƒá stop words
    EXCLUDE_STOP_WORDS: bool = True


CONFIG = MATTRConfig()


# ============================================================================
# TOKENIZACJA
# ============================================================================

def tokenize_text(text: str, exclude_stop_words: bool = True) -> List[str]:
    """
    Tokenizuje tekst do listy s≈Ç√≥w (lowercase).
    
    Args:
        text: Tekst do tokenizacji
        exclude_stop_words: Czy wykluczaƒá stop words
        
    Returns:
        Lista s≈Ç√≥w (lowercase)
    """
    # WyciƒÖgnij s≈Çowa (alfanumeryczne + polskie znaki)
    words = re.findall(r'\b[a-zƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈º]+\b', text.lower())
    
    # Filtruj kr√≥tkie (1-2 znaki) i stop words
    if exclude_stop_words:
        words = [w for w in words if len(w) > 2 and w not in POLISH_STOP_WORDS]
    else:
        words = [w for w in words if len(w) > 2]
    
    return words


# ============================================================================
# G≈Å√ìWNA FUNKCJA MATTR
# ============================================================================

def calculate_mattr(
    text: str,
    window_size: int = None,
    config: MATTRConfig = None
) -> Dict[str, Any]:
    """
    Oblicza Moving Average Type-Token Ratio.
    
    MATTR oblicza TTR w przesuwajƒÖcych siƒô oknach i u≈õrednia wyniki.
    Bardziej wiarygodna miara ni≈º prosty TTR dla d≈Çu≈ºszych tekst√≥w.
    
    Args:
        text: Tekst do analizy
        window_size: Rozmiar okna (domy≈õlnie 500)
        config: Konfiguracja
        
    Returns:
        Dict z wynikami:
        - value: warto≈õƒá MATTR (0-1)
        - std: odchylenie standardowe TTR miƒôdzy oknami
        - status: OK/WARNING/CRITICAL
        - message: komunikat diagnostyczny
        - method: "mattr" lub "standard_ttr" (dla kr√≥tkich tekst√≥w)
        - window_size: u≈ºyty rozmiar okna
        - windows_count: liczba okien
        - word_count: ca≈Çkowita liczba s≈Ç√≥w
        - score: znormalizowany score (0-100)
    """
    if config is None:
        config = CONFIG
    
    if window_size is None:
        window_size = config.WINDOW_SIZE
    
    # Tokenizuj
    words = tokenize_text(text, exclude_stop_words=config.EXCLUDE_STOP_WORDS)
    word_count = len(words)
    
    # Za ma≈Ço s≈Ç√≥w - u≈ºyj standardowego TTR
    if word_count < config.MIN_WORDS_FOR_MATTR:
        return _calculate_simple_ttr(words, word_count, config)
    
    # Oblicz TTR dla ka≈ºdego okna
    ttr_values = []
    
    for i in range(word_count - window_size + 1):
        window = words[i:i + window_size]
        unique = len(set(window))
        ttr = unique / window_size
        ttr_values.append(ttr)
    
    # Oblicz MATTR (≈õrednia TTR z wszystkich okien)
    mattr = statistics.mean(ttr_values)
    mattr_std = statistics.stdev(ttr_values) if len(ttr_values) > 1 else 0
    
    # Okre≈õl status i score
    status, score, message = _evaluate_mattr(mattr, config)
    
    return {
        "value": round(mattr, 3),
        "std": round(mattr_std, 4),
        "status": status.value,
        "message": message,
        "method": "mattr",
        "window_size": window_size,
        "windows_count": len(ttr_values),
        "word_count": word_count,
        "score": score,
        "min_ttr_window": round(min(ttr_values), 3) if ttr_values else 0,
        "max_ttr_window": round(max(ttr_values), 3) if ttr_values else 0,
    }


def _calculate_simple_ttr(
    words: List[str],
    word_count: int,
    config: MATTRConfig
) -> Dict[str, Any]:
    """
    Fallback do prostego TTR dla kr√≥tkich tekst√≥w.
    """
    if word_count == 0:
        return {
            "value": 0.0,
            "status": "INSUFFICIENT_DATA",
            "message": "Brak s≈Ç√≥w do analizy",
            "method": "none",
            "word_count": 0,
            "score": 50
        }
    
    unique = len(set(words))
    ttr = unique / word_count
    
    # U≈ºyj tych samych prog√≥w co MATTR (w przybli≈ºeniu)
    status, score, message = _evaluate_mattr(ttr, config)
    
    return {
        "value": round(ttr, 3),
        "std": 0.0,
        "status": status.value,
        "message": f"(Simple TTR - tekst < {config.MIN_WORDS_FOR_MATTR} s≈Ç√≥w) {message}",
        "method": "standard_ttr",
        "window_size": word_count,
        "windows_count": 1,
        "word_count": word_count,
        "unique_words": unique,
        "score": score
    }


def _evaluate_mattr(mattr: float, config: MATTRConfig) -> tuple:
    """
    Ocenia warto≈õƒá MATTR i zwraca (status, score, message).
    """
    if mattr < config.MATTR_CRITICAL_LOW:
        status = Severity.CRITICAL
        score = max(10, int(mattr / config.MATTR_CRITICAL_LOW * 40))
        message = f"‚ö†Ô∏è MATTR {mattr:.3f} < {config.MATTR_CRITICAL_LOW} = niskie zr√≥≈ºnicowanie s≈Çownictwa"
        
    elif mattr < config.MATTR_WARNING_LOW:
        status = Severity.WARNING
        score = 40 + int((mattr - config.MATTR_CRITICAL_LOW) / 
                        (config.MATTR_WARNING_LOW - config.MATTR_CRITICAL_LOW) * 30)
        message = f"‚ö† MATTR {mattr:.3f} < {config.MATTR_WARNING_LOW} = strefa podejrzana"
        
    elif mattr <= config.MATTR_OK_MAX:
        status = Severity.OK
        # Score 70-100 w zale≈ºno≈õci od tego jak blisko optimum (0.50)
        optimal = 0.50
        deviation = abs(mattr - optimal)
        score = 85 + int((1 - deviation / 0.15) * 15)
        score = min(100, max(70, score))
        message = f"‚úÖ MATTR {mattr:.3f} = dobre zr√≥≈ºnicowanie s≈Çownictwa"
        
    elif mattr <= config.MATTR_WARNING_HIGH:
        status = Severity.WARNING
        score = 65
        message = f"‚ö† MATTR {mattr:.3f} > {config.MATTR_OK_MAX} = bardzo wysokie (sprawd≈∫ nadmiar ≈ºargonu)"
        
    else:
        status = Severity.WARNING
        score = 55
        message = f"‚ö† MATTR {mattr:.3f} > {config.MATTR_WARNING_HIGH} = nienaturalnie wysokie"
    
    return status, score, message


# ============================================================================
# POR√ìWNANIE TTR vs MATTR
# ============================================================================

def compare_ttr_mattr(text: str) -> Dict[str, Any]:
    """
    Por√≥wnuje prosty TTR z MATTR dla tego samego tekstu.
    Pokazuje dlaczego MATTR jest lepszƒÖ miarƒÖ.
    """
    words = tokenize_text(text, exclude_stop_words=True)
    word_count = len(words)
    
    # Simple TTR
    unique = len(set(words))
    simple_ttr = unique / word_count if word_count > 0 else 0
    
    # MATTR
    mattr_result = calculate_mattr(text)
    
    return {
        "word_count": word_count,
        "simple_ttr": round(simple_ttr, 3),
        "mattr": mattr_result["value"],
        "difference": round(abs(simple_ttr - mattr_result["value"]), 3),
        "mattr_method": mattr_result["method"],
        "recommendation": "MATTR" if word_count >= CONFIG.MIN_WORDS_FOR_MATTR else "TTR (tekst kr√≥tki)"
    }


# ============================================================================
# INTEGRACJA Z AI_DETECTION_METRICS
# ============================================================================

def get_vocabulary_richness_v41(text: str) -> Dict[str, Any]:
    """
    Zastƒôpuje calculate_vocabulary_richness() z ai_detection_metrics.py.
    
    U≈ºywa MATTR dla tekst√≥w >= 500 s≈Ç√≥w, TTR dla kr√≥tszych.
    """
    mattr_result = calculate_mattr(text)
    
    return {
        "value": mattr_result["value"],
        "score": mattr_result["score"],
        "status": mattr_result["status"],
        "message": mattr_result["message"],
        "method": mattr_result["method"],
        "word_count": mattr_result["word_count"],
        # Kompatybilno≈õƒá wsteczna
        "ttr": mattr_result["value"],  # alias
        "normalized_score": mattr_result["score"] / 100  # 0-1 dla wag
    }


# ============================================================================
# INSTRUKCJA INTEGRACJI
# ============================================================================

"""
INTEGRACJA Z BRAJEN:

1. W ai_detection_metrics.py:

   # Zamie≈Ñ import/funkcjƒô calculate_vocabulary_richness na:
   from mattr_calculator_v41 import get_vocabulary_richness_v41 as calculate_vocabulary_richness

   # Lub je≈õli chcesz zachowaƒá starƒÖ funkcjƒô jako fallback:
   from mattr_calculator_v41 import get_vocabulary_richness_v41
   
   def calculate_vocabulary_richness(text: str) -> Dict[str, Any]:
       # U≈ºyj MATTR v41
       return get_vocabulary_richness_v41(text)

2. Progi pozostajƒÖ podobne, ale MATTR daje bardziej stabilne wyniki.

3. Waga w WEIGHTS mo≈ºe pozostaƒá 0.18 lub zmniejszyƒá do 0.14 
   (je≈õli dodajesz paragraph_cv z wagƒÖ 0.15).
"""


# ============================================================================
# TEST
# ============================================================================

if __name__ == "__main__":
    # Test z kr√≥tkim tekstem
    short_text = """
    Ubezw≈Çasnowolnienie to powa≈ºna decyzja prawna. SƒÖd musi zbadaƒá 
    wszystkie okoliczno≈õci sprawy. Procedura trwa kilka miesiƒôcy.
    """
    
    # Test z d≈Çugim tekstem (powtarzalny - symulacja AI)
    ai_like_text = """
    Ubezw≈Çasnowolnienie jest instytucjƒÖ prawnƒÖ uregulowanƒÖ w Kodeksie cywilnym.
    Procedura ubezw≈Çasnowolnienia wymaga z≈Ço≈ºenia wniosku do sƒÖdu okrƒôgowego.
    SƒÖd okrƒôgowy przeprowadza postƒôpowanie z udzia≈Çem bieg≈Çych sƒÖdowych.
    Biegli sƒÖdowi wydajƒÖ opiniƒô psychiatrycznƒÖ i psychologicznƒÖ w sprawie.
    Opinia bieg≈Çych jest podstawƒÖ do wydania orzeczenia przez sƒÖd.
    Orzeczenie sƒÖdu okre≈õla zakres ubezw≈Çasnowolnienia osoby fizycznej.
    Osoba fizyczna mo≈ºe byƒá ubezw≈Çasnowolniona ca≈Çkowicie lub czƒô≈õciowo.
    Ubezw≈Çasnowolnienie ca≈Çkowite pozbawia zdolno≈õci do czynno≈õci prawnych.
    Zdolno≈õƒá do czynno≈õci prawnych jest niezbƒôdna do zawierania um√≥w.
    Umowy zawarte przez osobƒô ubezw≈ÇasnowolnionƒÖ sƒÖ niewa≈ºne z mocy prawa.
    """ * 3  # Powt√≥rzenie ≈ºeby mieƒá > 500 s≈Ç√≥w
    
    # Test z naturalnym tekstem
    human_like_text = """
    Ubezw≈Çasnowolnienie to jedna z najtrudniejszych decyzji, jakie mo≈ºe podjƒÖƒá sƒÖd.
    Dlaczego? Bo dotyka sfery najbardziej intymnej - autonomii cz≈Çowieka.
    
    Wyobra≈∫ sobie sytuacjƒô: Twoja babcia ma 85 lat. Przez ca≈Çe ≈ºycie by≈Ça niezale≈ºna,
    prowadzi≈Ça w≈Çasny biznes, wychowa≈Ça troje dzieci. Teraz demencja postƒôpuje.
    Zaczyna zapominaƒá twarze, gubi≈Ça siƒô w drodze do sklepu, a ostatnio da≈Ça
    "mi≈Çemu panu z telefonu" numer karty kredytowej.
    
    Co robiƒá? Rodzina stoi przed dylematem. Z jednej strony trzeba chroniƒá babciƒô
    przed oszustami i jej w≈Çasnymi, niestety, b≈Çƒôdnymi decyzjami. Z drugiej -
    nikt nie chce jej odbieraƒá godno≈õci, traktowaƒá jak dziecko.
    
    Prawo daje narzƒôdzie: ubezw≈Çasnowolnienie. Ale to narzƒôdzie obosieczne.
    SƒÖd nie podejmie takiej decyzji pochopnie. Wymaga dowod√≥w, opinii bieg≈Çych,
    przes≈Çucha≈Ñ. Procedura mo≈ºe trwaƒá rok albo d≈Çu≈ºej. I dobrze - bo chodzi o co≈õ
    wiƒôcej ni≈º formalno≈õci. Chodzi o cz≈Çowieka.
    
    Czy warto? To zale≈ºy od konkretnej sytuacji. Czasem tak. Czasem lepsze sƒÖ
    inne rozwiƒÖzania: pe≈Çnomocnictwo, pomoc spo≈Çeczna, opieka rodziny bez
    formalnego pozbawienia praw. Ka≈ºdy przypadek jest inny.
    """ * 2  # Powt√≥rzenie ≈ºeby mieƒá > 500 s≈Ç√≥w
    
    print("=" * 60)
    print("TEST 1: Kr√≥tki tekst (TTR fallback)")
    print("=" * 60)
    result1 = calculate_mattr(short_text)
    print(f"Method: {result1['method']}")
    print(f"Value: {result1['value']}")
    print(f"Status: {result1['status']}")
    print(f"Score: {result1['score']}")
    print(f"Word count: {result1['word_count']}")
    
    print("\n" + "=" * 60)
    print("TEST 2: D≈Çugi tekst AI-like (powtarzalne s≈Çownictwo)")
    print("=" * 60)
    result2 = calculate_mattr(ai_like_text)
    print(f"Method: {result2['method']}")
    print(f"MATTR: {result2['value']}")
    print(f"Std: {result2['std']}")
    print(f"Status: {result2['status']}")
    print(f"Score: {result2['score']}")
    print(f"Word count: {result2['word_count']}")
    print(f"Windows: {result2['windows_count']}")
    print(f"Message: {result2['message']}")
    
    print("\n" + "=" * 60)
    print("TEST 3: D≈Çugi tekst human-like (zr√≥≈ºnicowane s≈Çownictwo)")
    print("=" * 60)
    result3 = calculate_mattr(human_like_text)
    print(f"Method: {result3['method']}")
    print(f"MATTR: {result3['value']}")
    print(f"Std: {result3['std']}")
    print(f"Status: {result3['status']}")
    print(f"Score: {result3['score']}")
    print(f"Word count: {result3['word_count']}")
    print(f"Windows: {result3['windows_count']}")
    print(f"Message: {result3['message']}")
    
    print("\n" + "=" * 60)
    print("POR√ìWNANIE TTR vs MATTR")
    print("=" * 60)
    comp = compare_ttr_mattr(human_like_text)
    print(f"Simple TTR: {comp['simple_ttr']}")
    print(f"MATTR: {comp['mattr']}")
    print(f"Difference: {comp['difference']}")
    print(f"Recommendation: {comp['recommendation']}")
