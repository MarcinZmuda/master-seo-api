# claude_judgment_verifier.py
# BRAJEN Legal Module v3.2 - Weryfikacja orzecze≈Ñ przez Claude
# Claude wybiera najlepsze orzeczenia zamiast prostego scoringu

"""
===============================================================================
ü§ñ CLAUDE JUDGMENT VERIFIER v3.2
===============================================================================

Zamiast g≈Çupiego scoringu regex, Claude:
1. Analizuje czy orzeczenie PASUJE do tematu artyku≈Çu
2. Ocenia kierunek (za/przeciw)
3. Wybiera 2 najlepsze z 10-15 kandydat√≥w

Koszt: ~300 input + ~200 output = ~500 token√≥w = ~$0.0003 per artyku≈Ç (Haiku)

===============================================================================
"""

import os
import json
from typing import Dict, List, Any, Optional
from anthropic import Anthropic

# ============================================================================
# KONFIGURACJA
# ============================================================================

CLAUDE_MODEL = "claude-3-haiku-20240307"  # Najta≈Ñszy, wystarczy do klasyfikacji
MAX_JUDGMENTS_TO_VERIFY = 10
MAX_JUDGMENTS_TO_SELECT = 2

# ============================================================================
# KLIENT ANTHROPIC
# ============================================================================

_client = None

def get_anthropic_client() -> Optional[Anthropic]:
    """Zwraca singleton klienta Anthropic."""
    global _client
    if _client is None:
        api_key = os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            print("[CLAUDE_VERIFIER] ‚ö†Ô∏è Brak ANTHROPIC_API_KEY")
            return None
        _client = Anthropic(api_key=api_key)
    return _client


# ============================================================================
# WERYFIKACJA ORZECZE≈É
# ============================================================================

def verify_judgments_with_claude(
    article_topic: str,
    judgments: List[Dict],
    max_to_select: int = MAX_JUDGMENTS_TO_SELECT
) -> Dict[str, Any]:
    """
    Claude wybiera najlepsze orzeczenia dla tematu artyku≈Çu.
    
    Args:
        article_topic: Temat artyku≈Çu (np. "alimenty na dziecko")
        judgments: Lista orzecze≈Ñ z SAOS (max 10-15)
        max_to_select: Ile wybraƒá (default 2)
        
    Returns:
        Dict z wybranymi orzeczeniami i uzasadnieniem
    """
    client = get_anthropic_client()
    
    if not client:
        return {
            "status": "ERROR",
            "error": "Anthropic client not available",
            "selected": [],
            "fallback": True
        }
    
    if not judgments:
        return {
            "status": "NO_JUDGMENTS",
            "selected": [],
            "fallback": False
        }
    
    # Ogranicz liczbƒô do weryfikacji
    judgments_to_verify = judgments[:MAX_JUDGMENTS_TO_VERIFY]
    
    # Przygotuj prompt
    prompt = _build_verification_prompt(article_topic, judgments_to_verify, max_to_select)
    
    try:
        response = client.messages.create(
            model=CLAUDE_MODEL,
            max_tokens=500,
            messages=[
                {"role": "user", "content": prompt}
            ]
        )
        
        # Parsuj odpowied≈∫
        result = _parse_claude_response(response.content[0].text, judgments_to_verify)
        
        return {
            "status": "OK",
            "selected": result["selected"],
            "reasoning": result.get("reasoning", ""),
            "model": CLAUDE_MODEL,
            "fallback": False
        }
        
    except Exception as e:
        print(f"[CLAUDE_VERIFIER] ‚ùå Error: {e}")
        return {
            "status": "ERROR",
            "error": str(e),
            "selected": [],
            "fallback": True
        }


def _build_verification_prompt(
    topic: str,
    judgments: List[Dict],
    max_to_select: int
) -> str:
    """Buduje prompt dla Claude'a - v3.2 z weryfikacjƒÖ PRZEDMIOTU sprawy."""
    
    judgments_text = ""
    for i, j in enumerate(judgments, 1):
        signature = j.get('signature', '')
        excerpt = j.get('excerpt', '')[:400]
        judgments_text += f"""
[{i}] {j.get('citation', f'Orzeczenie {i}')}
Sygnatura: {signature}
Fragment: "{excerpt}..."
"""
    
    # Wykryj czy temat dotyczy przestƒôpstwa
    criminal_keywords = ["przestƒôpstwo", "art. 209", "niealimentacja", "niep≈Çacenie aliment√≥w", 
                         "kara", "wyrok karny", "skazany", "oskar≈ºony"]
    is_criminal = any(kw in topic.lower() for kw in criminal_keywords)
    
    division_hint = ""
    if not is_criminal:
        division_hint = """
PRIORYTET WYDZIA≈Å√ìW (KRYTYCZNE!):
- Sprawy rodzinne/cywilne ‚Üí preferuj sygnatury: C, Ca, ACa, RC, CZP, CSK
- ‚õî ODRZUƒÜ sygnatury: K, Ka (Karne), U, Ua (Ubezpieczenia spo≈Çeczne)
- Sygnatura "K" = sprawa KARNA ‚Üí NIE PASUJE do tematu cywilnego!
- Sygnatura "U" = sprawa UBEZPIECZE≈É SPO≈ÅECZNYCH ‚Üí NIE PASUJE!
"""
    else:
        division_hint = """
PRIORYTET WYDZIA≈Å√ìW:
- Temat dotyczy przestƒôpstwa ‚Üí preferuj sygnatury: K, Ka, AKa, KK, KZP
- Sygnatura "I KZP" = uchwa≈Ça SN (Izba Karna) ‚Üí bardzo warto≈õciowe!
"""
    
    prompt = f"""Jeste≈õ ekspertem prawnym. Analizujesz orzeczenia sƒÖdowe dla artyku≈Çu SEO.

TEMAT ARTYKU≈ÅU: "{topic}"

KANDYDACI (orzeczenia z SAOS):
{judgments_text}

ZADANIE:
Wybierz {max_to_select} orzeczenia kt√≥re NAJLEPIEJ pasujƒÖ do tematu artyku≈Çu.

‚õî KRYTYCZNE KRYTERIUM - PRZEDMIOT SPRAWY vs KONTEKST UBOCZNY:

Orzeczenie PASUJE tylko je≈õli temat artyku≈Çu jest PRZEDMIOTEM sprawy (g≈Ç√≥wnym zagadnieniem).
Orzeczenie NIE PASUJE je≈õli temat jest tylko KONTEKSTEM UBOCZNYM (wspomniany przy okazji).

Przyk≈Çady dla tematu "ubezw≈Çasnowolnienie":
‚úÖ PASUJE: Sprawa O ubezw≈Çasnowolnienie (sygnatura C, Ca) - to jest przedmiot sprawy
‚ùå NIE PASUJE: Sprawa karna (sygnatura K) gdzie oskar≈ºony "jest ubezw≈Çasnowolniony" - to tylko kontekst
‚ùå NIE PASUJE: Sprawa o rentƒô (sygnatura U) gdzie wnioskodawca "zosta≈Ç ubezw≈Çasnowolniony" - to tylko kontekst

Przyk≈Çady dla tematu "alimenty":
‚úÖ PASUJE: Sprawa O alimenty (art. 133 KRO) - przedmiot sprawy
‚ùå NIE PASUJE: Sprawa karna o niealimentacjƒô (art. 209 KK) - to inna kategoria!
‚ùå NIE PASUJE: Sprawa spadkowa gdzie wspomina "obowiƒÖzek alimentacyjny" - kontekst uboczny

KRYTERIA WYBORU:

1. SYGNATURA (NAJWA≈ªNIEJSZE!):
   - Sprawd≈∫ czy wydzia≈Ç pasuje do tematu
   - "K" = karny, "U" = ubezpieczenia, "C/Ca/ACa" = cywilny
{division_hint}

2. WERYFIKACJA PRZEPISU:
   Znasz tre≈õƒá polskich kodeks√≥w (KK, KC, KRO, KPC, KPK, KP).
   Sprawd≈∫ czy przepis cytowany w orzeczeniu PASUJE do tematu artyku≈Çu.
   
   - Temat "ubezw≈Çasnowolnienie" ‚Üí art. 13, 16 KC (‚úÖ) | art. 178a KK (‚ùå to jazda po alkoholu!)
   - Temat "alimenty" ‚Üí art. 133 KRO (‚úÖ) | art. 209 KK (‚ùå to sprawa karna!)

3. KONTEKST MERYTORYCZNY:
   Fragment orzeczenia musi zawieraƒá warto≈õciowƒÖ tezƒô prawnƒÖ zwiƒÖzanƒÖ z tematem.
   NIE wybieraj orzecze≈Ñ gdzie temat jest tylko wspomniany "przy okazji".

ODPOWIEDZ W FORMACIE JSON:
{{
    "selected": [
        {{
            "index": 1,
            "direction": "za|przeciw|neutralny",
            "article_cited": "art. X ustawy Y",
            "is_main_subject": true,
            "division_ok": true,
            "reason": "kr√≥tkie uzasadnienie (max 20 s≈Ç√≥w)"
        }}
    ],
    "rejected_reason": "dlaczego pozosta≈Çe nie pasujƒÖ (max 30 s≈Ç√≥w)"
}}

WA≈ªNE:
- "is_main_subject": true TYLKO je≈õli temat jest PRZEDMIOTEM sprawy, nie kontekstem!
- "division_ok": true TYLKO je≈õli wydzia≈Ç (z sygnatury) pasuje do tematu!
- Je≈õli ≈ªADNE orzeczenie nie pasuje ‚Üí zwr√≥ƒá pustƒÖ listƒô selected i wyja≈õnij dlaczego

Odpowiedz TYLKO JSON, bez dodatkowego tekstu."""

    return prompt


def _parse_claude_response(
    response_text: str,
    original_judgments: List[Dict]
) -> Dict[str, Any]:
    """Parsuje odpowied≈∫ Claude'a i mapuje na oryginalne orzeczenia. v3.2"""
    
    # Wyczy≈õƒá response z markdown
    text = response_text.strip()
    if text.startswith("```"):
        text = text.split("```")[1]
        if text.startswith("json"):
            text = text[4:]
    text = text.strip()
    
    try:
        data = json.loads(text)
    except json.JSONDecodeError:
        # Fallback: we≈∫ pierwsze 2
        print("[CLAUDE_VERIFIER] ‚ö†Ô∏è JSON parse error, using fallback")
        return {
            "selected": original_judgments[:2],
            "reasoning": "Nie uda≈Ço siƒô sparsowaƒá odpowiedzi Claude'a"
        }
    
    selected = []
    for item in data.get("selected", []):
        idx = item.get("index", 0) - 1  # Claude zwraca 1-indexed
        if 0 <= idx < len(original_judgments):
            # üÜï v3.2: Sprawd≈∫ czy to PRZEDMIOT sprawy i czy wydzia≈Ç pasuje
            is_main_subject = item.get("is_main_subject", True)
            division_ok = item.get("division_ok", True)
            article_matches = item.get("article_matches_topic", True)
            
            # Odrzuƒá je≈õli kt√≥rekolwiek kryterium nie jest spe≈Çnione
            if is_main_subject == False:
                print(f"[CLAUDE_VERIFIER] ‚ö†Ô∏è Skipping [{idx+1}] - temat to tylko kontekst uboczny")
                continue
            if division_ok == False:
                print(f"[CLAUDE_VERIFIER] ‚ö†Ô∏è Skipping [{idx+1}] - wydzia≈Ç nie pasuje do tematu")
                continue
            if article_matches == False:
                print(f"[CLAUDE_VERIFIER] ‚ö†Ô∏è Skipping [{idx+1}] - przepis nie pasuje do tematu")
                continue
                
            judgment = original_judgments[idx].copy()
            judgment["direction"] = item.get("direction", "neutralny")
            judgment["claude_reason"] = item.get("reason", "")
            judgment["article_cited"] = item.get("article_cited", "")
            judgment["verified_by_claude"] = True
            judgment["is_main_subject"] = is_main_subject
            judgment["division_ok"] = division_ok
            selected.append(judgment)
    
    return {
        "selected": selected,
        "reasoning": data.get("rejected_reason", "")
    }


# ============================================================================
# FALLBACK: Prosty scoring (gdy Claude niedostƒôpny)
# ============================================================================

def simple_scoring_fallback(
    judgments: List[Dict],
    max_to_select: int = 2
) -> List[Dict]:
    """
    Prosty scoring jako fallback gdy Claude niedostƒôpny.
    U≈ºywa tylko podstawowych heurystyk.
    """
    import re
    
    scored = []
    for j in judgments:
        text = (j.get("full_text", "") or j.get("excerpt", "")).lower()
        score = 0
        
        # +40: zawiera przepis
        if re.search(r'art\.\s*\d+', text):
            score += 40
        
        # +30: ma tezƒô
        if any(p in text for p in ["zdaniem sƒÖdu", "nale≈ºy uznaƒá", "sƒÖd zwa≈ºy≈Ç"]):
            score += 30
        
        # +20: nie jest proceduralne
        if not any(p in text[:500] for p in ["umarza", "odrzuca", "zwraca sprawƒô"]):
            score += 20
        
        j_copy = j.copy()
        j_copy["score"] = score
        j_copy["direction"] = "neutralny"
        j_copy["verified_by_claude"] = False
        scored.append(j_copy)
    
    # Sortuj i we≈∫ najlepsze
    scored.sort(key=lambda x: x["score"], reverse=True)
    return scored[:max_to_select]


# ============================================================================
# G≈Å√ìWNA FUNKCJA
# ============================================================================

def select_best_judgments(
    article_topic: str,
    judgments: List[Dict],
    max_to_select: int = 2,
    use_claude: bool = True
) -> Dict[str, Any]:
    """
    G≈Ç√≥wna funkcja - wybiera najlepsze orzeczenia.
    
    Pr√≥buje Claude, fallback na prosty scoring.
    
    Args:
        article_topic: Temat artyku≈Çu
        judgments: Lista orzecze≈Ñ z SAOS
        max_to_select: Ile wybraƒá
        use_claude: Czy u≈ºywaƒá Claude (default True)
        
    Returns:
        Dict z wybranymi orzeczeniami
    """
    if not judgments:
        return {
            "status": "NO_JUDGMENTS",
            "selected": [],
            "method": "none"
        }
    
    # Pr√≥buj Claude
    if use_claude:
        result = verify_judgments_with_claude(article_topic, judgments, max_to_select)
        
        if result["status"] == "OK" and result["selected"]:
            return {
                "status": "OK",
                "selected": result["selected"],
                "method": "claude",
                "reasoning": result.get("reasoning", "")
            }
    
    # Fallback na prosty scoring
    print("[JUDGMENT_VERIFIER] ‚ö†Ô∏è Using fallback scoring")
    selected = simple_scoring_fallback(judgments, max_to_select)
    
    return {
        "status": "OK",
        "selected": selected,
        "method": "fallback_scoring",
        "reasoning": "Claude niedostƒôpny, u≈ºyto prostego scoringu"
    }


# ============================================================================
# TEST
# ============================================================================

if __name__ == "__main__":
    print("ü§ñ Claude Judgment Verifier Test\n")
    
    # Symulacja orzecze≈Ñ
    test_judgments = [
        {
            "citation": "wyrok SN z dnia 15.03.2023 (III CZP 12/23)",
            "excerpt": "ObowiƒÖzek alimentacyjny zgodnie z art. 133 KRO polega na dostarczaniu ≈õrodk√≥w utrzymania odpowiadajƒÖcych usprawiedliwionym potrzebom uprawnionego."
        },
        {
            "citation": "wyrok SA Warszawa z dnia 10.01.2022 (I ACa 456/22)",
            "excerpt": "Sprzeda≈º alkoholu nieletnim stanowi naruszenie art. 43 ustawy o wychowaniu w trze≈∫wo≈õci."
        },
        {
            "citation": "wyrok SO Krak√≥w z dnia 05.06.2022 (III Ca 789/22)",
            "excerpt": "Przy ustalaniu wysoko≈õci aliment√≥w sƒÖd bierze pod uwagƒô mo≈ºliwo≈õci zarobkowe zobowiƒÖzanego zgodnie z art. 135 KRO."
        }
    ]
    
    result = select_best_judgments(
        article_topic="alimenty na dziecko",
        judgments=test_judgments,
        use_claude=True
    )
    
    print(f"Status: {result['status']}")
    print(f"Method: {result['method']}")
    print(f"Selected: {len(result['selected'])}")
    
    for j in result["selected"]:
        print(f"\n  üìÑ {j['citation']}")
        print(f"     Direction: {j.get('direction', '?')}")
        print(f"     Reason: {j.get('claude_reason', 'N/A')}")
