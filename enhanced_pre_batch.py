"""
===============================================================================
ðŸŽ¯ ENHANCED PRE-BATCH INSTRUCTIONS v39.0
===============================================================================
ModuÅ‚ generujÄ…cy KONKRETNE instrukcje dla GPT zamiast surowych danych.

ROZWIÄ„ZUJE PROBLEMY:
1. Encje/Triplety - zamiast listy â†’ konkretne "jak zdefiniowaÄ‡"
2. Keywords - tracking w tle, nie blokowanie per-batch
3. Humanizacja - konkretne instrukcje stylu
4. Kontynuacja - peÅ‚ny kontekst poprzedniego batcha

Autor: BRAJEN SEO Master API v39.0
===============================================================================
"""

import re
import math
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field


# ============================================================================
# KONFIGURACJA
# ============================================================================

@dataclass
class EnhancedPreBatchConfig:
    """Konfiguracja dla enhanced pre_batch_info."""
    
    # Ile encji max pokazaÄ‡ w instrukcjach
    MAX_ENTITIES_TO_DEFINE: int = 5
    MAX_RELATIONS_TO_ESTABLISH: int = 4
    MAX_NGRAMS_PER_BATCH: int = 6
    
    # Semantic context
    MIN_CONTEXT_TERMS: int = 3
    MAX_CONTEXT_TERMS: int = 6
    
    # Style
    TARGET_SENTENCE_CV: float = 0.40  # WspÃ³Å‚czynnik zmiennoÅ›ci zdaÅ„
    MIN_SHORT_SENTENCES_PCT: int = 20
    MAX_AI_PATTERN_SENTENCES: int = 30  # % zdaÅ„ w przedziale 15-22 sÅ‚Ã³w
    
    # Kontynuacja
    LAST_PARAGRAPH_WORDS: int = 150  # Ile sÅ‚Ã³w z ostatniego akapitu


CONFIG = EnhancedPreBatchConfig()


# ============================================================================
# 1. ENTITIES TO DEFINE - konkretne instrukcje jak zdefiniowaÄ‡
# ============================================================================

# Wzorce definicji dla rÃ³Å¼nych typÃ³w encji
DEFINITION_TEMPLATES = {
    "legal_concept": [
        "WyjaÅ›nij Å¼e {entity} to instytucja prawna polegajÄ…ca na...",
        "Zdefiniuj {entity} jako procedurÄ™/mechanizm sÅ‚uÅ¼Ä…cy do...",
        "Napisz Å¼e {entity} w rozumieniu prawa oznacza..."
    ],
    "person_role": [
        "Przedstaw {entity} jako osobÄ™/organ odpowiedzialnÄ… za...",
        "WyjaÅ›nij rolÄ™ {entity} w kontekÅ›cie..."
    ],
    "process": [
        "Opisz {entity} jako proces skÅ‚adajÄ…cy siÄ™ z etapÃ³w...",
        "WyjaÅ›nij Å¼e {entity} przebiega w nastÄ™pujÄ…cy sposÃ³b..."
    ],
    "document": [
        "WyjaÅ›nij Å¼e {entity} to dokument zawierajÄ…cy...",
        "Zdefiniuj {entity} jako pismo/wniosek sÅ‚uÅ¼Ä…cy do..."
    ],
    "institution": [
        "Przedstaw {entity} jako organ/instytucjÄ™ wÅ‚aÅ›ciwÄ… do...",
        "WyjaÅ›nij kompetencje {entity} w zakresie..."
    ],
    "default": [
        "Zdefiniuj {entity} wyjaÅ›niajÄ…c czym jest i do czego sÅ‚uÅ¼y",
        "WprowadÅº pojÄ™cie {entity} w kontekÅ›cie tematu"
    ]
}

# SÅ‚owa kluczowe do klasyfikacji typu encji
ENTITY_TYPE_KEYWORDS = {
    "legal_concept": ["ubezwÅ‚asnowolnienie", "prawo", "przepis", "ustawa", "kodeks", 
                      "zdolnoÅ›Ä‡", "legitymacja", "postÄ™powanie"],
    "person_role": ["sÄ™dzia", "kurator", "opiekun", "biegÅ‚y", "prokurator", 
                    "adwokat", "radca", "przedstawiciel"],
    "process": ["procedura", "postÄ™powanie", "proces", "tryb", "etap"],
    "document": ["wniosek", "pismo", "pozew", "apelacja", "orzeczenie", "wyrok"],
    "institution": ["sÄ…d", "organ", "urzÄ…d", "ministerstwo", "instytut"]
}


def classify_entity_type(entity: str) -> str:
    """Klasyfikuje typ encji na podstawie sÅ‚Ã³w kluczowych."""
    entity_lower = entity.lower()
    
    for entity_type, keywords in ENTITY_TYPE_KEYWORDS.items():
        for keyword in keywords:
            if keyword in entity_lower:
                return entity_type
    
    return "default"


def generate_definition_instruction(entity: str, context: str = "", h2: str = "") -> Dict[str, Any]:
    """
    Generuje konkretnÄ… instrukcjÄ™ jak zdefiniowaÄ‡ encjÄ™.
    
    Args:
        entity: Nazwa encji
        context: Kontekst z S1 (jeÅ›li dostÄ™pny)
        h2: NagÅ‚Ã³wek H2 tej sekcji
        
    Returns:
        Dict z instrukcjÄ… definicji
    """
    entity_type = classify_entity_type(entity)
    templates = DEFINITION_TEMPLATES.get(entity_type, DEFINITION_TEMPLATES["default"])
    
    # Wybierz template
    template = templates[0]
    how = template.format(entity=entity)
    
    # Dodaj kontekst jeÅ›li dostÄ™pny
    if context:
        how += f" W kontekÅ›cie: {context}"
    
    return {
        "entity": entity,
        "action": "DEFINE",
        "type": entity_type,
        "how": how,
        "example_pattern": f'"{entity} to/jest/oznacza..."',
        "h2_context": h2
    }


def get_entities_to_define(
    s1_data: Dict,
    current_batch_num: int,
    entity_state: Dict,
    current_h2: str,
    total_batches: int
) -> List[Dict]:
    """
    Zwraca listÄ™ encji do zdefiniowania w tym batchu z konkretnymi instrukcjami.
    
    Args:
        s1_data: Dane z analizy S1
        current_batch_num: Numer aktualnego batcha
        entity_state: Stan encji (ktÃ³re juÅ¼ zdefiniowane)
        current_h2: NagÅ‚Ã³wek H2 tego batcha
        total_batches: ÅÄ…czna liczba batchÃ³w
        
    Returns:
        Lista encji z instrukcjami definicji
    """
    entity_seo = s1_data.get("entity_seo", {})
    entities = entity_seo.get("entities", [])
    topical_coverage = entity_seo.get("topical_coverage", [])
    
    # Filtruj encje ktÃ³re jeszcze nie zostaÅ‚y zdefiniowane
    already_defined = set(entity_state.get("defined", []))
    
    result = []
    
    # 1. Najpierw encje MUST z topical_coverage
    for topic in topical_coverage:
        if topic.get("priority") == "MUST":
            entity = topic.get("topic", "")
            if entity and entity.lower() not in {e.lower() for e in already_defined}:
                instruction = generate_definition_instruction(
                    entity=entity,
                    context=topic.get("context", ""),
                    h2=current_h2
                )
                instruction["priority"] = "MUST"
                result.append(instruction)
    
    # 2. Encje HIGH importance
    for ent in entities:
        if ent.get("importance", 0) >= 0.7:
            entity = ent.get("text", ent.get("entity", ""))
            if entity and entity.lower() not in {e.lower() for e in already_defined}:
                # SprawdÅº czy nie ma juÅ¼ w wynikach
                if entity.lower() not in {r["entity"].lower() for r in result}:
                    instruction = generate_definition_instruction(
                        entity=entity,
                        context=ent.get("context", ""),
                        h2=current_h2
                    )
                    instruction["priority"] = "SHOULD"
                    result.append(instruction)
    
    # 3. RozÅ‚Ã³Å¼ rÃ³wnomiernie na batche
    entities_per_batch = max(2, len(result) // total_batches)
    start_idx = (current_batch_num - 1) * entities_per_batch
    end_idx = min(start_idx + entities_per_batch + 1, len(result))
    
    # Batch 1 = INTRO, weÅº wiÄ™cej encji fundamentalnych
    if current_batch_num == 1:
        # Sortuj by MUST byÅ‚y pierwsze
        result.sort(key=lambda x: 0 if x.get("priority") == "MUST" else 1)
        return result[:CONFIG.MAX_ENTITIES_TO_DEFINE]
    
    return result[start_idx:end_idx][:CONFIG.MAX_ENTITIES_TO_DEFINE]


# ============================================================================
# 2. RELATIONS TO ESTABLISH - relacje z wzorcami zdaÅ„
# ============================================================================

RELATION_TEMPLATES = {
    "orzeka": [
        "{subject} orzeka o {object}",
        "{subject} wydaje orzeczenie w sprawie {object}",
        "to {subject} rozstrzyga o {object}"
    ],
    "prowadzi_do": [
        "{subject} moÅ¼e prowadziÄ‡ do {object}",
        "{subject} skutkuje {object}",
        "konsekwencjÄ… {subject} jest {object}"
    ],
    "wymaga": [
        "{subject} wymaga {object}",
        "do {subject} niezbÄ™dne jest {object}",
        "{subject} nie moÅ¼e nastÄ…piÄ‡ bez {object}"
    ],
    "reprezentuje": [
        "{subject} reprezentuje interesy {object}",
        "{subject} dziaÅ‚a w imieniu {object}"
    ],
    "chroni": [
        "{subject} sÅ‚uÅ¼y ochronie {object}",
        "celem {subject} jest zabezpieczenie {object}"
    ],
    "default": [
        "{subject} jest powiÄ…zane z {object}",
        "{subject} ma zwiÄ…zek z {object}"
    ]
}


def generate_relation_instruction(
    from_entity: str,
    relation: str,
    to_entity: str
) -> Dict[str, Any]:
    """
    Generuje instrukcjÄ™ ustanowienia relacji miÄ™dzy encjami.
    """
    # ZnajdÅº odpowiedni template
    relation_lower = relation.lower().replace(" ", "_")
    templates = RELATION_TEMPLATES.get(relation_lower, RELATION_TEMPLATES["default"])
    
    example_sentences = [
        t.format(subject=from_entity, object=to_entity)
        for t in templates[:2]
    ]
    
    return {
        "from": from_entity,
        "relation": relation,
        "to": to_entity,
        "example_sentences": example_sentences,
        "instruction": f"UstanÃ³w relacjÄ™: {from_entity} â†’ {relation} â†’ {to_entity}",
        "how": f"Napisz zdanie Å‚Ä…czÄ…ce '{from_entity}' z '{to_entity}' przez '{relation}'"
    }


def get_relations_to_establish(
    s1_data: Dict,
    current_batch_num: int,
    entity_state: Dict,
    total_batches: int
) -> List[Dict]:
    """
    Zwraca relacje do ustanowienia w tym batchu.
    """
    entity_seo = s1_data.get("entity_seo", {})
    relationships = entity_seo.get("entity_relationships", [])
    
    # Filtruj juÅ¼ ustanowione
    established = set(entity_state.get("relations_established", []))
    
    result = []
    for rel in relationships:
        from_ent = rel.get("from", rel.get("subject", ""))
        to_ent = rel.get("to", rel.get("object", ""))
        relation = rel.get("relation", rel.get("predicate", ""))
        
        if not from_ent or not to_ent or not relation:
            continue
        
        # UtwÃ³rz klucz relacji
        rel_key = f"{from_ent}|{relation}|{to_ent}".lower()
        if rel_key not in established:
            instruction = generate_relation_instruction(from_ent, relation, to_ent)
            instruction["priority"] = rel.get("priority", "SHOULD")
            result.append(instruction)
    
    # RozÅ‚Ã³Å¼ na batche
    rels_per_batch = max(1, len(result) // total_batches)
    start_idx = (current_batch_num - 1) * rels_per_batch
    end_idx = min(start_idx + rels_per_batch + 1, len(result))
    
    return result[start_idx:end_idx][:CONFIG.MAX_RELATIONS_TO_ESTABLISH]


# ============================================================================
# 3. SEMANTIC CONTEXT - terminy ktÃ³re MUSZÄ„ byÄ‡ uÅ¼yte
# ============================================================================

def get_semantic_context(
    s1_data: Dict,
    current_batch_num: int,
    current_h2: str,
    keywords_state: Dict
) -> Dict[str, Any]:
    """
    Generuje semantic context z terminami do uÅ¼ycia.
    
    Zawiera:
    - context_terms: terminy ktÃ³re MUSZÄ„ pojawiÄ‡ siÄ™ w tekÅ›cie
    - supporting_phrases: frazy wzbogacajÄ…ce
    - semantic_field: pole semantyczne tematu
    """
    # N-gramy
    ngrams = s1_data.get("ngrams", [])
    top_ngrams = [n.get("ngram", "") for n in ngrams if n.get("weight", 0) > 0.4]
    
    # LSI keywords
    semantic_keyphrases = s1_data.get("semantic_keyphrases", [])
    lsi_keywords = [kp.get("phrase", "") for kp in semantic_keyphrases if kp.get("score", 0) > 0.6]
    
    # Related searches
    serp = s1_data.get("serp_analysis", {})
    related = serp.get("related_searches", [])[:5]
    
    # Wybierz terminy dla tego batcha
    all_terms = top_ngrams + lsi_keywords
    terms_per_batch = max(CONFIG.MIN_CONTEXT_TERMS, len(all_terms) // 8)
    
    start_idx = (current_batch_num - 1) * terms_per_batch
    end_idx = min(start_idx + terms_per_batch + 2, len(all_terms))
    
    batch_terms = all_terms[start_idx:end_idx][:CONFIG.MAX_CONTEXT_TERMS]
    
    # Filtruj - usuÅ„ terminy ktÃ³re sÄ… w keywords_state (bÄ™dÄ… osobno trackowane)
    keyword_set = {meta.get("keyword", "").lower() for meta in keywords_state.values()}
    batch_terms = [t for t in batch_terms if t.lower() not in keyword_set]
    
    return {
        "context_terms": batch_terms,
        "instruction": f"UÅ¼yj NATURALNIE w tekÅ›cie (nie stuffing!): {', '.join(batch_terms[:4])}",
        "supporting_phrases": lsi_keywords[:3],
        "related_topics": related[:3],
        "semantic_density_target": "min 2 terminy na 100 sÅ‚Ã³w"
    }


# ============================================================================
# 4. STYLE INSTRUCTIONS - humanizacja tekstu
# ============================================================================

# Frazy typowe dla AI do unikania
AI_PATTERNS_TO_AVOID = [
    "warto podkreÅ›liÄ‡",
    "naleÅ¼y pamiÄ™taÄ‡",
    "w kontekÅ›cie",
    "istotne jest",
    "kluczowym aspektem",
    "nie moÅ¼na pominÄ…Ä‡",
    "szczegÃ³lnie waÅ¼ne",
    "fundamentalne znaczenie",
    "z perspektywy",
    "w odniesieniu do",
    "majÄ…c na uwadze",
    "biorÄ…c pod uwagÄ™",
    "co wiÄ™cej",
    "ponadto",
    "dodatkowo",  # Tylko na poczÄ…tku zdania
    "warto zaznaczyÄ‡",
    "naleÅ¼y podkreÅ›liÄ‡",
    "trzeba wspomnieÄ‡"
]

# Naturalne alternatywy
NATURAL_ALTERNATIVES = {
    "warto podkreÅ›liÄ‡": ["", "ZwrÃ³Ä‡ uwagÄ™:", "WaÅ¼ne:"],
    "naleÅ¼y pamiÄ™taÄ‡": ["PamiÄ™taj,", "Nie zapomnij,", ""],
    "w kontekÅ›cie": ["przy", "jeÅ›li chodzi o", "w sprawie"],
    "co wiÄ™cej": ["Poza tym", "RÃ³wnieÅ¼", "A co waÅ¼ne"],
    "ponadto": ["OprÃ³cz tego", "TeÅ¼", "RÃ³wnieÅ¼"],
}


def get_style_instructions(
    style_fingerprint: Dict,
    current_batch_num: int,
    is_ymyl: bool = False
) -> Dict[str, Any]:
    """
    Generuje konkretne instrukcje stylistyczne dla GPT.
    """
    # Bazowe instrukcje
    instructions = {
        "vary_sentence_length": {
            "instruction": "Mieszaj dÅ‚ugoÅ›ci zdaÅ„: 5-40 sÅ‚Ã³w",
            "target_distribution": {
                "short_2_10_words": "20-25%",
                "medium_12_18_words": "50-60%",
                "long_20_35_words": "15-25%"
            },
            "avoid": "Nie pisz wszystkich zdaÅ„ 15-22 sÅ‚Ã³w (wzorzec AI)"
        },
        
        "avoid_ai_patterns": {
            "instruction": "UNIKAJ tych fraz (typowe dla AI):",
            "patterns": AI_PATTERNS_TO_AVOID[:10],
            "alternatives": NATURAL_ALTERNATIVES
        },
        
        "use_active_voice": {
            "instruction": "Preferuj stronÄ™ czynnÄ…",
            "examples": {
                "bad": "Wniosek jest skÅ‚adany do sÄ…du",
                "good": "Wniosek skÅ‚ada siÄ™ do sÄ…du"
            }
        },
        
        "pronouns_consistency": {
            "instruction": "Wybierz JEDEN styl i trzymaj siÄ™ go",
            "options": ["bezosobowo (moÅ¼na, naleÅ¼y)", "per 'ty' (moÅ¼esz, powinieneÅ›)"],
            "warning": "NIE mieszaj stylÃ³w w jednym tekÅ›cie!"
        },
        
        "natural_flow": {
            "instruction": "Pisz jak ekspert tÅ‚umaczÄ…cy znajomemu, nie jak encyklopedia",
            "tips": [
                "UÅ¼ywaj pytaÅ„ retorycznych",
                "Dodaj przykÅ‚ady z Å¼ycia",
                "Nie kaÅ¼de zdanie musi byÄ‡ 'mÄ…drÄ…' definicjÄ…"
            ]
        }
    }
    
    # JeÅ›li mamy fingerprint z poprzednich batchÃ³w
    if style_fingerprint and style_fingerprint.get("analyzed_batches", 0) > 0:
        instructions["match_established_style"] = {
            "instruction": "ZACHOWAJ styl z poprzednich batchÃ³w:",
            "formality": style_fingerprint.get("formality_level", "semi_formal"),
            "pronouns": style_fingerprint.get("personal_pronouns", "bezosobowo"),
            "avg_sentence_length": style_fingerprint.get("sentence_length_avg", 16),
            "example_sentences": style_fingerprint.get("example_sentences", [])[:2]
        }
    
    # YMYL - dodatkowe wymagania
    if is_ymyl:
        instructions["ymyl_precision"] = {
            "instruction": "TreÅ›Ä‡ YMYL - wymagana precyzja!",
            "requirements": [
                "Cytuj przepisy: 'art. X Â§ Y k.c.'",
                "Nie uÅ¼ywaj 'zaleca siÄ™', 'warto' - pisz konkretnie",
                "Dodaj disclaimer na koÅ„cu artykuÅ‚u"
            ]
        }
    
    return instructions


# ============================================================================
# 5. CONTINUATION CONTEXT - poÅ‚Ä…czenie miÄ™dzy batchami
# ============================================================================

def get_continuation_context(
    batches: List[Dict],
    keywords_state: Dict,
    style_fingerprint: Dict,
    entity_state: Dict
) -> Dict[str, Any]:
    """
    Generuje peÅ‚ny kontekst kontynuacji dla GPT.
    """
    if not batches:
        return {
            "is_first_batch": True,
            "instruction": "To jest PIERWSZY batch - wprowadÅº temat"
        }
    
    last_batch = batches[-1]
    last_text = last_batch.get("text", "")
    
    # WyciÄ…gnij ostatni peÅ‚ny akapit (nie tylko 2 zdania)
    paragraphs = re.split(r'\n\n+', last_text)
    paragraphs = [p.strip() for p in paragraphs if p.strip() and not p.startswith("h2:")]
    
    last_paragraph = ""
    if paragraphs:
        last_paragraph = paragraphs[-1]
        # Ogranicz dÅ‚ugoÅ›Ä‡
        words = last_paragraph.split()
        if len(words) > CONFIG.LAST_PARAGRAPH_WORDS:
            last_paragraph = " ".join(words[-CONFIG.LAST_PARAGRAPH_WORDS:])
    
    # Zbierz zdefiniowane encje
    defined_entities = {}
    for ent, batch_num in entity_state.get("introduced_entities", {}).items():
        definition = entity_state.get("defined_terms", {}).get(ent, "wprowadzone")
        defined_entities[ent] = {
            "status": "zdefiniowane" if definition != "wprowadzone" else "wspomniane",
            "in_batch": batch_num
        }
    
    # Ostatnie H2
    last_h2 = ""
    h2_match = re.search(r'^h2:\s*(.+)$', last_text, re.MULTILINE | re.IGNORECASE)
    if h2_match:
        last_h2 = h2_match.group(1).strip()
    
    return {
        "is_first_batch": False,
        "last_paragraph": last_paragraph,
        "last_h2": last_h2,
        "batches_completed": len(batches),
        
        "established_entities": defined_entities,
        "instruction_entities": "NIE powtarzaj definicji tych pojÄ™Ä‡ - sÄ… juÅ¼ wyjaÅ›nione",
        
        "style_fingerprint": {
            "tone": style_fingerprint.get("formality_level", "semi_formal"),
            "pronouns": style_fingerprint.get("personal_pronouns", "bezosobowo"),
            "avg_sentence_length": round(style_fingerprint.get("sentence_length_avg", 16))
        },
        "instruction_style": "ZACHOWAJ ten sam styl pisania!",
        
        "continuation_instruction": "KONTYNUUJ narracjÄ™ pÅ‚ynnie. Pierwsze zdanie powinno nawiÄ…zywaÄ‡ do poprzedniej sekcji.",
        
        "example_transitions": [
            "Kolejnym aspektem jest...",
            "OmawiajÄ…c [temat H2], naleÅ¼y...",
            "W kontekÅ›cie [poprzedniego tematu], warto teraz...",
            "PrzechodzÄ…c do [nowy temat]..."
        ]
    }


# ============================================================================
# 6. KEYWORD TRACKING MODE - tracking zamiast blokowania
# ============================================================================

def get_keyword_tracking_info(
    keywords_state: Dict,
    current_batch_num: int,
    total_batches: int,
    remaining_batches: int
) -> Dict[str, Any]:
    """
    Generuje informacje o keywords w trybie TRACKING (nie blokujÄ…cym).
    
    Per-batch: tylko INFO/WARNING, nigdy STOP
    Final review: weryfikacja globalna
    """
    tracking = {
        "mode": "TRACKING",
        "explanation": "Frazy sÄ… ÅšLEDZONE w tle. Per-batch nie blokuje. Weryfikacja globalna w final_review.",
        
        "use_naturally": [],      # UÅ¼yj naturalnie
        "available": [],          # DostÄ™pne, ale nie wymagane
        "near_limit": [],         # Blisko limitu - uwaÅ¼aj
        "structural": [],         # STRUCTURAL - bez limitu per-batch
    }
    
    for rid, meta in keywords_state.items():
        keyword = meta.get("keyword", "")
        if not keyword:
            continue
        
        kw_type = meta.get("type", "BASIC").upper()
        actual = meta.get("actual_uses", 0)
        target_min = meta.get("target_min", 1)
        target_max = meta.get("target_max", 999)
        is_main = meta.get("is_main_keyword", False)
        is_structural = meta.get("is_structural", False) or is_main
        
        # Oblicz ile jeszcze potrzeba
        remaining_needed = max(0, target_min - actual)
        remaining_allowed = max(0, target_max - actual)
        
        # Suggested per batch
        if remaining_batches > 0:
            suggested = math.ceil(remaining_needed / remaining_batches) if remaining_needed > 0 else 0
            max_here = math.ceil(remaining_allowed / remaining_batches)
        else:
            suggested = remaining_needed
            max_here = remaining_allowed
        
        kw_info = {
            "keyword": keyword,
            "type": kw_type,
            "actual_total": actual,
            "target": f"{target_min}-{target_max}",
            "remaining_needed": remaining_needed,
            "remaining_allowed": remaining_allowed,
            "suggested_this_batch": min(suggested, 3),
            "max_this_batch": min(max_here, 5)
        }
        
        # Kategoryzuj
        if is_structural:
            kw_info["note"] = "ðŸ”µ STRUCTURAL - uÅ¼yj naturalnie, limit globalny"
            tracking["structural"].append(kw_info)
        elif remaining_allowed <= 2:
            kw_info["note"] = "âš ï¸ Blisko limitu - max 1Ã— tu"
            tracking["near_limit"].append(kw_info)
        elif remaining_needed > 0:
            kw_info["note"] = f"UÅ¼yj ~{suggested}Ã— w tym batchu"
            tracking["use_naturally"].append(kw_info)
        else:
            kw_info["note"] = "âœ“ W normie, opcjonalnie 1Ã—"
            tracking["available"].append(kw_info)
    
    # Podsumowanie dla GPT
    tracking["summary"] = {
        "total_keywords": len(keywords_state),
        "need_usage": len(tracking["use_naturally"]),
        "near_limit": len(tracking["near_limit"]),
        "structural": len(tracking["structural"]),
        "instruction": "UÅ¼yj fraz NATURALNIE. System Å›ledzi iloÅ›ci automatycznie. Nie rÃ³b stuffingu!"
    }
    
    return tracking


# ============================================================================
# 7. DYNAMIC BATCH COUNT - na podstawie S1
# ============================================================================

def calculate_optimal_batch_count(
    s1_data: Dict,
    keywords_count: int,
    h2_count: int,
    target_length: int,
    is_ymyl: bool = False
) -> Dict[str, Any]:
    """
    Oblicza optymalnÄ… liczbÄ™ batchÃ³w na podstawie analizy S1.
    
    Faktory:
    - Liczba encji do zdefiniowania
    - Liczba relacji do ustanowienia
    - Liczba keywords
    - DÅ‚ugoÅ›Ä‡ docelowa
    - YMYL wymaga wiÄ™cej szczegÃ³Å‚Ã³w
    """
    entity_seo = s1_data.get("entity_seo", {})
    entities = entity_seo.get("entities", [])
    relationships = entity_seo.get("entity_relationships", [])
    topical_coverage = entity_seo.get("topical_coverage", [])
    
    # Policz encje HIGH importance
    high_entities = len([e for e in entities if e.get("importance", 0) >= 0.7])
    must_topics = len([t for t in topical_coverage if t.get("priority") == "MUST"])
    
    # Bazowa liczba batchÃ³w
    base_batches = h2_count + 1  # H2 + intro
    
    # Dodatkowe batche na podstawie zÅ‚oÅ¼onoÅ›ci
    complexity_batches = 0
    
    # DuÅ¼o encji = wiÄ™cej batchÃ³w
    if high_entities > 8:
        complexity_batches += 2
    elif high_entities > 5:
        complexity_batches += 1
    
    # DuÅ¼o relacji = wiÄ™cej batchÃ³w
    if len(relationships) > 6:
        complexity_batches += 1
    
    # DuÅ¼o keywords = wiÄ™cej batchÃ³w
    if keywords_count > 25:
        complexity_batches += 2
    elif keywords_count > 15:
        complexity_batches += 1
    
    # YMYL = wiÄ™cej szczegÃ³Å‚Ã³w
    if is_ymyl:
        complexity_batches += 1
    
    # DÅ‚ugi artykuÅ‚ = wiÄ™cej batchÃ³w
    if target_length > 3500:
        complexity_batches += 2
    elif target_length > 2500:
        complexity_batches += 1
    
    optimal = base_batches + complexity_batches
    
    # Limity
    min_batches = max(4, h2_count)
    max_batches = 15
    
    optimal = max(min_batches, min(optimal, max_batches))
    
    return {
        "recommended_batches": optimal,
        "min_batches": min_batches,
        "max_batches": max_batches,
        "factors": {
            "h2_count": h2_count,
            "high_entities": high_entities,
            "must_topics": must_topics,
            "relationships": len(relationships),
            "keywords": keywords_count,
            "target_length": target_length,
            "is_ymyl": is_ymyl
        },
        "explanation": f"Zalecane {optimal} batchÃ³w: {h2_count} H2 + intro + {complexity_batches} dla zÅ‚oÅ¼onoÅ›ci"
    }


# ============================================================================
# 8. MAIN FUNCTION - generuje kompletne enhanced pre_batch_info
# ============================================================================

def generate_enhanced_pre_batch_info(
    s1_data: Dict,
    keywords_state: Dict,
    batches: List[Dict],
    h2_structure: List[str],
    current_batch_num: int,
    total_batches: int,
    main_keyword: str,
    entity_state: Dict = None,
    style_fingerprint: Dict = None,
    is_ymyl: bool = False,
    is_legal: bool = False
) -> Dict[str, Any]:
    """
    Generuje KOMPLETNE enhanced pre_batch_info z konkretnymi instrukcjami.
    
    Returns:
        Dict gotowy do wysÅ‚ania do GPT
    """
    if entity_state is None:
        entity_state = {}
    if style_fingerprint is None:
        style_fingerprint = {}
    
    remaining_batches = max(1, total_batches - len(batches))
    
    # OkreÅ›l H2 dla tego batcha
    used_h2 = []
    for batch in batches:
        h2_match = re.search(r'^h2:\s*(.+)$', batch.get("text", ""), re.MULTILINE | re.IGNORECASE)
        if h2_match:
            used_h2.append(h2_match.group(1).strip())
    
    remaining_h2 = [h2 for h2 in h2_structure if h2 not in used_h2]
    current_h2 = remaining_h2[0] if remaining_h2 else main_keyword
    
    # Batch type
    if current_batch_num == 1:
        batch_type = "INTRO"
    elif current_batch_num >= total_batches:
        batch_type = "FINAL"
    else:
        batch_type = "CONTENT"
    
    # ================================================================
    # GENERUJ WSZYSTKIE SEKCJE
    # ================================================================
    
    enhanced = {
        "batch_number": current_batch_num,
        "total_batches": total_batches,
        "batch_type": batch_type,
        "current_h2": current_h2,
        "remaining_h2": remaining_h2[1:4],  # NastÄ™pne 3 H2
        
        # 1. ENCJE DO ZDEFINIOWANIA
        "entities_to_define": get_entities_to_define(
            s1_data=s1_data,
            current_batch_num=current_batch_num,
            entity_state=entity_state,
            current_h2=current_h2,
            total_batches=total_batches
        ),
        
        # 2. RELACJE DO USTANOWIENIA
        "relations_to_establish": get_relations_to_establish(
            s1_data=s1_data,
            current_batch_num=current_batch_num,
            entity_state=entity_state,
            total_batches=total_batches
        ),
        
        # 3. KONTEKST SEMANTYCZNY
        "semantic_context": get_semantic_context(
            s1_data=s1_data,
            current_batch_num=current_batch_num,
            current_h2=current_h2,
            keywords_state=keywords_state
        ),
        
        # 4. INSTRUKCJE STYLU
        "style_instructions": get_style_instructions(
            style_fingerprint=style_fingerprint,
            current_batch_num=current_batch_num,
            is_ymyl=is_ymyl
        ),
        
        # 5. KONTEKST KONTYNUACJI
        "continuation": get_continuation_context(
            batches=batches,
            keywords_state=keywords_state,
            style_fingerprint=style_fingerprint,
            entity_state=entity_state
        ),
        
        # 6. KEYWORD TRACKING
        "keyword_tracking": get_keyword_tracking_info(
            keywords_state=keywords_state,
            current_batch_num=current_batch_num,
            total_batches=total_batches,
            remaining_batches=remaining_batches
        )
    }
    
    # ================================================================
    # GPT PROMPT SECTION - gotowy do wklejenia
    # ================================================================
    
    enhanced["gpt_instructions"] = _generate_gpt_prompt_section(enhanced, is_legal)
    
    return enhanced


def _generate_gpt_prompt_section(enhanced: Dict, is_legal: bool = False) -> str:
    """
    Generuje gotowÄ… sekcjÄ™ promptu dla GPT.
    """
    lines = []
    lines.append("=" * 60)
    lines.append(f"ðŸ“‹ BATCH #{enhanced['batch_number']} - {enhanced['batch_type']}")
    lines.append("=" * 60)
    lines.append("")
    
    # H2
    lines.append(f"ðŸ“Œ H2: \"{enhanced['current_h2']}\"")
    lines.append("")
    
    # Encje do zdefiniowania
    entities = enhanced.get("entities_to_define", [])
    if entities:
        lines.append("ðŸ§  ENCJE DO ZDEFINIOWANIA:")
        for ent in entities[:4]:
            priority_icon = "ðŸ”´" if ent.get("priority") == "MUST" else "ðŸŸ¡"
            lines.append(f"   {priority_icon} {ent['entity']}")
            lines.append(f"      â†’ {ent['how']}")
        lines.append("")
    
    # Relacje
    relations = enhanced.get("relations_to_establish", [])
    if relations:
        lines.append("ðŸ”— RELACJE DO USTANOWIENIA:")
        for rel in relations[:3]:
            lines.append(f"   â€¢ {rel['from']} â†’ {rel['relation']} â†’ {rel['to']}")
            if rel.get("example_sentences"):
                lines.append(f"     PrzykÅ‚ad: \"{rel['example_sentences'][0]}\"")
        lines.append("")
    
    # Kontekst semantyczny
    semantic = enhanced.get("semantic_context", {})
    context_terms = semantic.get("context_terms", [])
    if context_terms:
        lines.append("ðŸ“š TERMINY KONTEKSTOWE (uÅ¼yj naturalnie):")
        lines.append(f"   {', '.join(context_terms[:5])}")
        lines.append("")
    
    # Styl
    style = enhanced.get("style_instructions", {})
    if style.get("avoid_ai_patterns"):
        patterns = style["avoid_ai_patterns"].get("patterns", [])[:5]
        lines.append("ðŸš« UNIKAJ (typowe dla AI):")
        lines.append(f"   {', '.join(patterns)}")
        lines.append("")
    
    # Kontynuacja
    continuation = enhanced.get("continuation", {})
    if not continuation.get("is_first_batch"):
        lines.append("ðŸ”„ KONTYNUACJA:")
        if continuation.get("last_paragraph"):
            last_p = continuation["last_paragraph"][:200]
            lines.append(f"   Ostatni akapit: \"{last_p}...\"")
        
        established = continuation.get("established_entities", {})
        if established:
            defined = [k for k, v in established.items() if v.get("status") == "zdefiniowane"][:5]
            if defined:
                lines.append(f"   âœ“ JuÅ¼ zdefiniowane: {', '.join(defined)}")
        lines.append("")
    
    # Keywords summary
    tracking = enhanced.get("keyword_tracking", {})
    summary = tracking.get("summary", {})
    if summary:
        lines.append(f"ðŸ“Š KEYWORDS: {summary.get('need_usage', 0)} do uÅ¼ycia | {summary.get('near_limit', 0)} blisko limitu")
        lines.append("   ðŸ’¡ UÅ¼yj NATURALNIE - system Å›ledzi automatycznie")
        lines.append("")
    
    lines.append("=" * 60)
    
    return "\n".join(lines)


# ============================================================================
# EXPORTS
# ============================================================================

__all__ = [
    'generate_enhanced_pre_batch_info',
    'get_entities_to_define',
    'get_relations_to_establish',
    'get_semantic_context',
    'get_style_instructions',
    'get_continuation_context',
    'get_keyword_tracking_info',
    'calculate_optimal_batch_count',
    'CONFIG',
    'AI_PATTERNS_TO_AVOID',
    'NATURAL_ALTERNATIVES'
]
