"""
===============================================================================
ðŸ§  SHARED NLP v23.0 - WspÃ³Å‚dzielony model spaCy
===============================================================================
RozwiÄ…zuje problem wielokrotnego Å‚adowania modelu spaCy.

Zamiast:
    unified_validator.py    â†’ nlp = spacy.load()  # 150MB
    project_routes_v23.py   â†’ nlp = spacy.load()  # 150MB
    entity_ngram_analyzer.py â†’ nlp = spacy.load() # 150MB
    polish_language_quality.py â†’ nlp = spacy.load() # 150MB
    RAZEM: ~600MB RAM

Teraz:
    shared_nlp.py â†’ nlp = spacy.load()  # 150MB (raz!)
    Wszystkie moduÅ‚y: from shared_nlp import nlp

OSZCZÄ˜DNOÅšÄ†: ~450MB RAM
===============================================================================
"""

import spacy
import os

# ================================================================
# ðŸ”§ KONFIGURACJA
# ================================================================
# DomyÅ›lny model - moÅ¼na zmieniÄ‡ przez env
SPACY_MODEL = os.getenv("SPACY_MODEL", "pl_core_news_md")

# Alternatywy:
# - pl_core_news_sm  (15MB)  - szybki, mniej dokÅ‚adny
# - pl_core_news_md  (50MB)  - balans (DOMYÅšLNY)
# - pl_core_news_lg  (150MB) - najdokÅ‚adniejszy, wiÄ™cej RAM

# ================================================================
# ðŸ§  SINGLETON - JEDEN MODEL DLA CAÅEJ APLIKACJI
# ================================================================
_nlp_instance = None

def get_nlp():
    """
    Zwraca wspÃ³Å‚dzielonÄ… instancjÄ™ modelu spaCy.
    Åaduje model tylko przy pierwszym wywoÅ‚aniu (lazy loading).
    """
    global _nlp_instance
    
    if _nlp_instance is None:
        try:
            _nlp_instance = spacy.load(SPACY_MODEL)
            print(f"[SHARED_NLP] âœ… ZaÅ‚adowano model: {SPACY_MODEL}")
        except OSError:
            print(f"[SHARED_NLP] âš ï¸ Model {SPACY_MODEL} nie znaleziony, pobieram...")
            from spacy.cli import download
            download(SPACY_MODEL)
            _nlp_instance = spacy.load(SPACY_MODEL)
            print(f"[SHARED_NLP] âœ… Pobrano i zaÅ‚adowano: {SPACY_MODEL}")
    
    return _nlp_instance


# ================================================================
# ðŸ”— EKSPORT - dla kompatybilnoÅ›ci wstecznej
# ================================================================
# ModuÅ‚y mogÄ… uÅ¼ywaÄ‡:
#   from shared_nlp import nlp
# lub:
#   from shared_nlp import get_nlp
#   nlp = get_nlp()

# Lazy loading przy imporcie
nlp = None

def __getattr__(name):
    """Lazy loading przy pierwszym uÅ¼yciu `nlp`."""
    if name == "nlp":
        global nlp
        if nlp is None:
            nlp = get_nlp()
        return nlp
    raise AttributeError(f"module {__name__!r} has no attribute {name!r}")


# ================================================================
# ðŸ”§ HELPER FUNCTIONS
# ================================================================
def reload_model(model_name: str = None):
    """
    PrzeÅ‚adowuje model spaCy.
    UÅ¼yteczne przy zmianie modelu w runtime.
    """
    global _nlp_instance, nlp, SPACY_MODEL
    
    if model_name:
        SPACY_MODEL = model_name
    
    _nlp_instance = None
    nlp = None
    return get_nlp()


def get_model_info() -> dict:
    """Zwraca informacje o zaÅ‚adowanym modelu."""
    model = get_nlp()
    return {
        "model_name": SPACY_MODEL,
        "pipeline": model.pipe_names,
        "vocab_size": len(model.vocab),
        "vectors": model.vocab.vectors.shape if model.vocab.vectors else None
    }


# ================================================================
# ðŸ“Š PRE-LOAD przy starcie (opcjonalne)
# ================================================================
if os.getenv("PRELOAD_SPACY", "false").lower() == "true":
    print("[SHARED_NLP] Pre-loading spaCy model...")
    get_nlp()
