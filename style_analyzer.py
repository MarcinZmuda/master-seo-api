"""
üé® STYLE ANALYZER v1.0
Persona Fingerprint - analiza i utrzymanie sp√≥jno≈õci stylu

RozwiƒÖzuje problem niesp√≥jnego tonu miƒôdzy batchami:
- Analizuje formalno≈õƒá, d≈Çugo≈õƒá zda≈Ñ, u≈ºycie strony biernej
- Generuje "fingerprint" stylu do wstrzykniƒôcia w kolejne batche
- Wykrywa odchylenia od ustalnego tonu

Autor: SEO Master API v36.2
"""

import re
import statistics
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass, field, asdict
from enum import Enum


class FormalityLevel(Enum):
    """Poziom formalno≈õci tekstu"""
    CASUAL = "casual"           # Ty, proste s≈Çowa, potoczny
    SEMI_FORMAL = "semi_formal" # Mieszany, ale profesjonalny
    FORMAL = "formal"           # Pa≈Ñstwo, Pan/Pani, terminologia
    ACADEMIC = "academic"       # Bardzo formalny, naukowy


class PersonalPronouns(Enum):
    """Spos√≥b zwracania siƒô do czytelnika"""
    TY = "ty"               # "Mo≈ºesz z≈Ço≈ºyƒá wniosek..."
    WY = "wy"               # "Mo≈ºecie z≈Ço≈ºyƒá..."  
    PANSTWO = "panstwo"     # "Pa≈Ñstwo mogƒÖ z≈Ço≈ºyƒá..."
    BEZOSOBOWO = "bezosobowo"  # "Wniosek mo≈ºna z≈Ço≈ºyƒá..."


@dataclass
class StyleFingerprint:
    """
    Fingerprint stylistyczny tekstu.
    
    U≈ºywany do utrzymania sp√≥jno≈õci miƒôdzy batchami.
    """
    # Formalno≈õƒá (0.0 = casual, 1.0 = academic)
    formality_score: float = 0.5
    formality_level: FormalityLevel = FormalityLevel.SEMI_FORMAL
    
    # Struktura zda≈Ñ
    sentence_length_avg: float = 18.0      # ≈õrednia d≈Çugo≈õƒá zdania (s≈Çowa)
    sentence_length_std: float = 5.0       # odchylenie standardowe
    sentence_variety: float = 0.3          # wsp√≥≈Çczynnik zmienno≈õci (CV)
    
    # G≈Ços
    passive_voice_ratio: float = 0.15      # % zda≈Ñ w stronie biernej
    personal_pronouns: PersonalPronouns = PersonalPronouns.BEZOSOBOWO
    
    # Styl
    transition_words_ratio: float = 0.25   # % zda≈Ñ ze s≈Çowami przej≈õciowymi
    question_ratio: float = 0.05           # % pyta≈Ñ retorycznych
    example_ratio: float = 0.1             # % zda≈Ñ z przyk≈Çadami
    
    # S≈Çownictwo
    avg_word_length: float = 6.5           # ≈õrednia d≈Çugo≈õƒá s≈Çowa
    complex_words_ratio: float = 0.15      # % s≈Ç√≥w > 3 sylaby
    
    # Wzorcowe elementy (do na≈õladowania)
    example_sentences: List[str] = field(default_factory=list)  # 2-3 wzorcowe zdania
    preferred_transitions: List[str] = field(default_factory=list)  # preferowane s≈Çowa ≈ÇƒÖczƒÖce
    forbidden_patterns: List[str] = field(default_factory=list)  # czego unikaƒá
    
    # Meta
    analyzed_batches: int = 0
    total_sentences_analyzed: int = 0
    
    def to_dict(self) -> dict:
        return {
            "formality_score": self.formality_score,
            "formality_level": self.formality_level.value,
            "sentence_length_avg": self.sentence_length_avg,
            "sentence_length_std": self.sentence_length_std,
            "sentence_variety": self.sentence_variety,
            "passive_voice_ratio": self.passive_voice_ratio,
            "personal_pronouns": self.personal_pronouns.value,
            "transition_words_ratio": self.transition_words_ratio,
            "question_ratio": self.question_ratio,
            "example_ratio": self.example_ratio,
            "avg_word_length": self.avg_word_length,
            "complex_words_ratio": self.complex_words_ratio,
            "example_sentences": self.example_sentences,
            "preferred_transitions": self.preferred_transitions,
            "forbidden_patterns": self.forbidden_patterns,
            "analyzed_batches": self.analyzed_batches,
            "total_sentences_analyzed": self.total_sentences_analyzed
        }
    
    @classmethod
    def from_dict(cls, data: dict) -> "StyleFingerprint":
        fp = cls()
        fp.formality_score = data.get("formality_score", 0.5)
        fp.formality_level = FormalityLevel(data.get("formality_level", "semi_formal"))
        fp.sentence_length_avg = data.get("sentence_length_avg", 18.0)
        fp.sentence_length_std = data.get("sentence_length_std", 5.0)
        fp.sentence_variety = data.get("sentence_variety", 0.3)
        fp.passive_voice_ratio = data.get("passive_voice_ratio", 0.15)
        fp.personal_pronouns = PersonalPronouns(data.get("personal_pronouns", "bezosobowo"))
        fp.transition_words_ratio = data.get("transition_words_ratio", 0.25)
        fp.question_ratio = data.get("question_ratio", 0.05)
        fp.example_ratio = data.get("example_ratio", 0.1)
        fp.avg_word_length = data.get("avg_word_length", 6.5)
        fp.complex_words_ratio = data.get("complex_words_ratio", 0.15)
        fp.example_sentences = data.get("example_sentences", [])
        fp.preferred_transitions = data.get("preferred_transitions", [])
        fp.forbidden_patterns = data.get("forbidden_patterns", [])
        fp.analyzed_batches = data.get("analyzed_batches", 0)
        fp.total_sentences_analyzed = data.get("total_sentences_analyzed", 0)
        return fp
    
    def generate_style_instructions(self) -> str:
        """Generuj instrukcje stylistyczne dla GPT"""
        lines = []
        lines.append("=" * 60)
        lines.append("üé® STYL PISANIA - ZACHOWAJ SP√ìJNO≈öƒÜ!")
        lines.append("=" * 60)
        lines.append("")
        
        # Formalno≈õƒá
        formality_desc = {
            FormalityLevel.CASUAL: "Nieformalny, przyjazny, prosty jƒôzyk",
            FormalityLevel.SEMI_FORMAL: "Profesjonalny ale przystƒôpny",
            FormalityLevel.FORMAL: "Formalny, u≈ºywaj 'Pa≈Ñstwo', 'Pan/Pani'",
            FormalityLevel.ACADEMIC: "Bardzo formalny, terminologia naukowa"
        }
        lines.append(f"üìä FORMALNO≈öƒÜ: {formality_desc[self.formality_level]}")
        lines.append("")
        
        # Zwracanie siƒô
        pronouns_desc = {
            PersonalPronouns.TY: "Zwracaj siƒô per 'Ty' (mo≈ºesz, powiniene≈õ)",
            PersonalPronouns.WY: "Zwracaj siƒô per 'Wy' (mo≈ºecie, powinni≈õcie)",
            PersonalPronouns.PANSTWO: "U≈ºywaj 'Pa≈Ñstwo' (mogƒÖ Pa≈Ñstwo, Pa≈Ñstwa sprawa)",
            PersonalPronouns.BEZOSOBOWO: "Pisz bezosobowo (mo≈ºna, nale≈ºy, warto)"
        }
        lines.append(f"üë§ FORMA ZWRACANIA: {pronouns_desc[self.personal_pronouns]}")
        lines.append("")
        
        # Zdania
        lines.append(f"üìè D≈ÅUGO≈öƒÜ ZDA≈É:")
        lines.append(f"   ‚Ä¢ ≈örednio: {self.sentence_length_avg:.0f} s≈Ç√≥w (zakres: {self.sentence_length_avg-5:.0f}-{self.sentence_length_avg+5:.0f})")
        lines.append(f"   ‚Ä¢ Zmienno≈õƒá: {'Wysoka - mieszaj kr√≥tkie i d≈Çugie' if self.sentence_variety > 0.35 else 'Umiarkowana - zachowaj r√≥wnomierne'}")
        lines.append("")
        
        # G≈Ços
        if self.passive_voice_ratio > 0.25:
            lines.append(f"üîä G≈ÅOS: Czƒô≈õciej strona bierna (jest wykonywane, zostaje z≈Ço≈ºony)")
        elif self.passive_voice_ratio < 0.1:
            lines.append(f"üîä G≈ÅOS: Preferuj stronƒô czynnƒÖ (wykonuje siƒô, sk≈Çada siƒô)")
        else:
            lines.append(f"üîä G≈ÅOS: Mieszaj stronƒô czynnƒÖ i biernƒÖ naturalnie")
        lines.append("")
        
        # Przyk≈Çadowe zdania
        if self.example_sentences:
            lines.append(f"‚ú® WZORCOWE ZDANIA Z POPRZEDNICH BATCHY:")
            for ex in self.example_sentences[:2]:
                lines.append(f"   \"{ex[:100]}...\"" if len(ex) > 100 else f"   \"{ex}\"")
            lines.append("")
        
        # Preferowane przej≈õcia
        if self.preferred_transitions:
            lines.append(f"üîó PREFEROWANE S≈ÅOWA ≈ÅƒÑCZƒÑCE:")
            lines.append(f"   {', '.join(self.preferred_transitions[:6])}")
            lines.append("")
        
        # Zakazane wzorce
        if self.forbidden_patterns:
            lines.append(f"‚õî UNIKAJ TYCH SFORMU≈ÅOWA≈É:")
            for pattern in self.forbidden_patterns[:4]:
                lines.append(f"   ‚Ä¢ {pattern}")
            lines.append("")
        
        return "\n".join(lines)


class StyleAnalyzer:
    """
    Analizator stylu tekstu.
    
    U≈ºywany po ka≈ºdym batchu do aktualizacji fingerprinta.
    """
    
    # S≈Çowa formalne
    FORMAL_WORDS = {
        "nale≈ºy", "powinno", "wymaga", "stanowi", "zgodnie",
        "pa≈Ñstwo", "pani", "pana", "przedmiotowy", "niniejszy",
        "powy≈ºszy", "stosownie", "w≈Ça≈õciwy", "odpowiedni"
    }
    
    # S≈Çowa nieformalne
    INFORMAL_WORDS = {
        "fajnie", "super", "mega", "bardzo", "naprawdƒô",
        "normalnie", "po prostu", "w sumie", "generalnie",
        "szczerze", "w≈Ça≈õciwie", "chyba"
    }
    
    # S≈Çowa przej≈õciowe
    TRANSITION_WORDS = [
        "jednak", "natomiast", "ponadto", "dodatkowo", "r√≥wnie≈º",
        "w zwiƒÖzku z tym", "dlatego", "zatem", "tym samym",
        "przede wszystkim", "po pierwsze", "po drugie",
        "z kolei", "nastƒôpnie", "wreszcie", "podsumowujƒÖc",
        "innymi s≈Çowy", "to znaczy", "mianowicie"
    ]
    
    # Wzorce strony biernej (polskiej)
    PASSIVE_PATTERNS = [
        r'\bjest\s+\w+[aoy]n[aey]?\b',  # jest wykonany/a/e
        r'\bzosta≈Ç[aoy]?\s+\w+[aoy]n[aey]?\b',  # zosta≈Ç z≈Ço≈ºony
        r'\bzostaje\s+\w+[aoy]n[aey]?\b',  # zostaje wykonany
        r'\bby≈Ço\s+\w+[aoy]n[aey]?\b',  # by≈Ço zrobione
    ]
    
    # Wzorce przyk≈Çad√≥w
    EXAMPLE_PATTERNS = [
        r'\bna przyk≈Çad\b',
        r'\bnp\.\s',
        r'\bprzyk≈Çadowo\b',
        r'\bwyobra≈∫my sobie\b',
        r'\bza≈Ç√≥≈ºmy,? ≈ºe\b',
        r'\bw praktyce\b'
    ]
    
    def __init__(self, existing_fingerprint: Optional[StyleFingerprint] = None):
        self.fingerprint = existing_fingerprint or StyleFingerprint()
    
    def analyze_batch(self, batch_text: str) -> StyleFingerprint:
        """
        Analizuj batch i zaktualizuj fingerprint.
        
        Args:
            batch_text: Tekst batcha do analizy
            
        Returns:
            Zaktualizowany StyleFingerprint
        """
        # Wyczy≈õƒá tekst
        clean_text = self._clean_text(batch_text)
        
        # Podziel na zdania
        sentences = self._split_sentences(clean_text)
        
        if len(sentences) < 3:
            return self.fingerprint
        
        # Analizuj metryki
        new_metrics = self._compute_metrics(clean_text, sentences)
        
        # Po≈ÇƒÖcz z istniejƒÖcym fingerprintem (weighted average)
        self._merge_metrics(new_metrics)
        
        # Znajd≈∫ przyk≈Çadowe zdania
        self._find_example_sentences(sentences)
        
        # Znajd≈∫ preferowane przej≈õcia
        self._find_preferred_transitions(clean_text)
        
        # Aktualizuj meta
        self.fingerprint.analyzed_batches += 1
        self.fingerprint.total_sentences_analyzed += len(sentences)
        
        return self.fingerprint
    
    def _clean_text(self, text: str) -> str:
        """Usu≈Ñ tagi HTML i nag≈Ç√≥wki"""
        clean = re.sub(r'<[^>]+>', ' ', text)
        clean = re.sub(r'^h[23]:\s*.+$', '', clean, flags=re.MULTILINE)
        clean = re.sub(r'\s+', ' ', clean).strip()
        return clean
    
    def _split_sentences(self, text: str) -> List[str]:
        """Podziel tekst na zdania"""
        # Uwzglƒôdnij skr√≥ty
        text = re.sub(r'\b(np|m\.in|tj|tzw|itd|itp|ok|ul|art|ust|pkt)\.\s', r'\1<DOT> ', text)
        
        sentences = re.split(r'[.!?]+', text)
        sentences = [s.replace('<DOT>', '.').strip() for s in sentences if s.strip() and len(s.strip()) > 10]
        
        return sentences
    
    def _compute_metrics(self, text: str, sentences: List[str]) -> dict:
        """Oblicz metryki stylistyczne"""
        metrics = {}
        
        # D≈Çugo≈õƒá zda≈Ñ
        sentence_lengths = [len(s.split()) for s in sentences]
        metrics["sentence_length_avg"] = statistics.mean(sentence_lengths)
        metrics["sentence_length_std"] = statistics.stdev(sentence_lengths) if len(sentence_lengths) > 1 else 5.0
        metrics["sentence_variety"] = metrics["sentence_length_std"] / metrics["sentence_length_avg"] if metrics["sentence_length_avg"] > 0 else 0.3
        
        # Formalno≈õƒá
        text_lower = text.lower()
        formal_count = sum(1 for w in self.FORMAL_WORDS if w in text_lower)
        informal_count = sum(1 for w in self.INFORMAL_WORDS if w in text_lower)
        
        total_words = len(text.split())
        formality_raw = (formal_count - informal_count) / max(total_words / 100, 1)
        metrics["formality_score"] = max(0, min(1, 0.5 + formality_raw * 0.1))
        
        # Strona bierna
        passive_count = sum(1 for pattern in self.PASSIVE_PATTERNS 
                          for _ in re.findall(pattern, text_lower))
        metrics["passive_voice_ratio"] = passive_count / max(len(sentences), 1)
        
        # S≈Çowa przej≈õciowe
        transition_count = sum(1 for t in self.TRANSITION_WORDS if t in text_lower)
        metrics["transition_words_ratio"] = transition_count / max(len(sentences), 1)
        
        # Pytania
        question_count = text.count('?')
        metrics["question_ratio"] = question_count / max(len(sentences), 1)
        
        # Przyk≈Çady
        example_count = sum(1 for pattern in self.EXAMPLE_PATTERNS 
                          for _ in re.findall(pattern, text_lower))
        metrics["example_ratio"] = example_count / max(len(sentences), 1)
        
        # D≈Çugo≈õƒá s≈Ç√≥w
        words = re.findall(r'\b\w+\b', text)
        if words:
            metrics["avg_word_length"] = statistics.mean(len(w) for w in words)
            # S≈Çowa > 3 sylaby (przybli≈ºenie: > 8 liter)
            complex_count = sum(1 for w in words if len(w) > 8)
            metrics["complex_words_ratio"] = complex_count / len(words)
        else:
            metrics["avg_word_length"] = 6.5
            metrics["complex_words_ratio"] = 0.15
        
        # Zaimki osobowe
        metrics["personal_pronouns"] = self._detect_pronouns(text_lower)
        
        # Poziom formalno≈õci
        if metrics["formality_score"] > 0.7:
            metrics["formality_level"] = FormalityLevel.FORMAL
        elif metrics["formality_score"] > 0.55:
            metrics["formality_level"] = FormalityLevel.SEMI_FORMAL
        elif metrics["formality_score"] < 0.35:
            metrics["formality_level"] = FormalityLevel.CASUAL
        else:
            metrics["formality_level"] = FormalityLevel.SEMI_FORMAL
        
        return metrics
    
    def _detect_pronouns(self, text: str) -> PersonalPronouns:
        """Wykryj spos√≥b zwracania siƒô"""
        ty_count = len(re.findall(r'\b(mo≈ºesz|musisz|powiniene≈õ|tw√≥j|twoja|twoje|ciebie|ci)\b', text))
        wy_count = len(re.findall(r'\b(mo≈ºecie|musicie|powinni≈õcie|wasz|wasza|wasze|was|wam)\b', text))
        panstwo_count = len(re.findall(r'\b(pa≈Ñstwo|pa≈Ñstwa|pa≈Ñstwu|pana|pani|pa≈Ñsk)\b', text))
        bezos_count = len(re.findall(r'\b(mo≈ºna|nale≈ºy|warto|trzeba|powinno siƒô)\b', text))
        
        counts = {
            PersonalPronouns.TY: ty_count,
            PersonalPronouns.WY: wy_count,
            PersonalPronouns.PANSTWO: panstwo_count,
            PersonalPronouns.BEZOSOBOWO: bezos_count
        }
        
        return max(counts, key=counts.get)
    
    def _merge_metrics(self, new_metrics: dict):
        """Po≈ÇƒÖcz nowe metryki z istniejƒÖcym fingerprintem"""
        # Waga dla nowych danych (im wiƒôcej batchy, tym mniejsza waga nowych)
        weight = 1 / (self.fingerprint.analyzed_batches + 1)
        old_weight = 1 - weight
        
        # Metryki liczbowe - weighted average
        numeric_fields = [
            "formality_score", "sentence_length_avg", "sentence_length_std",
            "sentence_variety", "passive_voice_ratio", "transition_words_ratio",
            "question_ratio", "example_ratio", "avg_word_length", "complex_words_ratio"
        ]
        
        for field in numeric_fields:
            old_val = getattr(self.fingerprint, field)
            new_val = new_metrics.get(field, old_val)
            setattr(self.fingerprint, field, old_weight * old_val + weight * new_val)
        
        # Enum fields - u≈ºyj nowych je≈õli to pierwszy batch, inaczej zachowaj
        if self.fingerprint.analyzed_batches == 0:
            self.fingerprint.formality_level = new_metrics.get("formality_level", FormalityLevel.SEMI_FORMAL)
            self.fingerprint.personal_pronouns = new_metrics.get("personal_pronouns", PersonalPronouns.BEZOSOBOWO)
    
    def _find_example_sentences(self, sentences: List[str]):
        """Znajd≈∫ wzorcowe zdania (dobrze napisane)"""
        good_sentences = []
        
        for sentence in sentences:
            words = sentence.split()
            word_count = len(words)
            
            # Kryteria dobrego zdania:
            # - 12-25 s≈Ç√≥w
            # - Zawiera s≈Çowo przej≈õciowe lub przyk≈Çad
            # - Nie zaczyna siƒô od "I" (lista)
            
            if 12 <= word_count <= 25:
                has_transition = any(t in sentence.lower() for t in self.TRANSITION_WORDS[:10])
                has_example = any(re.search(p, sentence.lower()) for p in self.EXAMPLE_PATTERNS)
                
                if has_transition or has_example:
                    good_sentences.append(sentence)
        
        # Zachowaj max 3 przyk≈Çadowe zdania
        if good_sentences:
            self.fingerprint.example_sentences = good_sentences[:3]
    
    def _find_preferred_transitions(self, text: str):
        """Znajd≈∫ preferowane s≈Çowa przej≈õciowe"""
        text_lower = text.lower()
        
        transition_counts = {}
        for t in self.TRANSITION_WORDS:
            count = text_lower.count(t)
            if count > 0:
                transition_counts[t] = count
        
        # Top 6 najczƒô≈õciej u≈ºywanych
        sorted_transitions = sorted(transition_counts.items(), key=lambda x: x[1], reverse=True)
        self.fingerprint.preferred_transitions = [t[0] for t in sorted_transitions[:6]]
    
    def check_style_deviation(self, new_batch_text: str) -> Dict:
        """
        Sprawd≈∫ czy nowy batch odbiega od ustalonego stylu.
        
        Returns:
            Dict z informacjami o odchyleniach
        """
        clean_text = self._clean_text(new_batch_text)
        sentences = self._split_sentences(clean_text)
        
        if len(sentences) < 3:
            return {"deviations": [], "severity": "NONE"}
        
        new_metrics = self._compute_metrics(clean_text, sentences)
        
        deviations = []
        
        # Sprawd≈∫ odchylenie d≈Çugo≈õci zda≈Ñ
        len_diff = abs(new_metrics["sentence_length_avg"] - self.fingerprint.sentence_length_avg)
        if len_diff > 5:
            deviations.append({
                "type": "sentence_length",
                "expected": f"{self.fingerprint.sentence_length_avg:.0f} s≈Ç√≥w",
                "actual": f"{new_metrics['sentence_length_avg']:.0f} s≈Ç√≥w",
                "suggestion": f"Dostosuj d≈Çugo≈õƒá zda≈Ñ (obecnie: {new_metrics['sentence_length_avg']:.0f}, cel: {self.fingerprint.sentence_length_avg:.0f})"
            })
        
        # Sprawd≈∫ zaimki
        if new_metrics["personal_pronouns"] != self.fingerprint.personal_pronouns:
            deviations.append({
                "type": "pronouns",
                "expected": self.fingerprint.personal_pronouns.value,
                "actual": new_metrics["personal_pronouns"].value,
                "suggestion": f"U≈ºywaj formy '{self.fingerprint.personal_pronouns.value}' zamiast '{new_metrics['personal_pronouns'].value}'"
            })
        
        # Sprawd≈∫ formalno≈õƒá
        form_diff = abs(new_metrics["formality_score"] - self.fingerprint.formality_score)
        if form_diff > 0.2:
            deviations.append({
                "type": "formality",
                "expected": f"{self.fingerprint.formality_score:.2f}",
                "actual": f"{new_metrics['formality_score']:.2f}",
                "suggestion": "Dostosuj poziom formalno≈õci do poprzednich batchy"
            })
        
        # Okre≈õl severity
        if len(deviations) >= 3:
            severity = "HIGH"
        elif len(deviations) >= 1:
            severity = "MEDIUM"
        else:
            severity = "NONE"
        
        return {
            "deviations": deviations,
            "severity": severity,
            "recommendation": "Popraw tekst zgodnie z sugestiami" if deviations else "Styl zgodny"
        }


def analyze_style(text: str, existing_fingerprint: Optional[dict] = None) -> dict:
    """
    G≈Ç√≥wna funkcja do analizy stylu.
    
    Args:
        text: Tekst do analizy
        existing_fingerprint: IstniejƒÖcy fingerprint (dict) do aktualizacji
        
    Returns:
        Dict z zaktualizowanym fingerprintem
    """
    fp = StyleFingerprint.from_dict(existing_fingerprint) if existing_fingerprint else StyleFingerprint()
    analyzer = StyleAnalyzer(fp)
    updated_fp = analyzer.analyze_batch(text)
    return updated_fp.to_dict()


def check_style_consistency(new_text: str, fingerprint_dict: dict) -> dict:
    """
    Sprawd≈∫ sp√≥jno≈õƒá stylu nowego tekstu z fingerprintem.
    
    Args:
        new_text: Nowy tekst do sprawdzenia
        fingerprint_dict: Fingerprint z poprzednich batchy
        
    Returns:
        Dict z informacjami o odchyleniach
    """
    fp = StyleFingerprint.from_dict(fingerprint_dict)
    analyzer = StyleAnalyzer(fp)
    return analyzer.check_style_deviation(new_text)


def generate_style_prompt(fingerprint_dict: dict) -> str:
    """
    Generuj instrukcje stylistyczne do wstrzykniƒôcia w prompt GPT.
    
    Args:
        fingerprint_dict: Fingerprint z poprzednich batchy
        
    Returns:
        String z instrukcjami stylistycznymi
    """
    fp = StyleFingerprint.from_dict(fingerprint_dict)
    return fp.generate_style_instructions()


# ============================================
# PRZYK≈ÅAD U≈ªYCIA
# ============================================
if __name__ == "__main__":
    # Przyk≈Çadowy tekst
    sample_text = """
    Ubezw≈Çasnowolnienie to instytucja prawna, kt√≥ra ma na celu ochronƒô os√≥b 
    niezdolnych do samodzielnego kierowania swoim postƒôpowaniem. Nale≈ºy pamiƒôtaƒá, 
    ≈ºe procedura ta wymaga spe≈Çnienia okre≈õlonych przes≈Çanek. 
    
    Po pierwsze, osoba musi cierpieƒá na chorobƒô psychicznƒÖ lub innƒÖ dysfunkcjƒô. 
    Po drugie, stan ten musi uniemo≈ºliwiaƒá jej samodzielne funkcjonowanie. 
    
    W praktyce oznacza to, ≈ºe mo≈ºna z≈Ço≈ºyƒá wniosek do sƒÖdu okrƒôgowego. 
    Wniosek powinien zawieraƒá dokumentacjƒô medycznƒÖ oraz uzasadnienie.
    """
    
    # Analizuj
    fingerprint = analyze_style(sample_text)
    
    print("=== STYLE FINGERPRINT ===")
    print(f"Formality: {fingerprint['formality_score']:.2f} ({fingerprint['formality_level']})")
    print(f"Sentence length: {fingerprint['sentence_length_avg']:.1f} ¬± {fingerprint['sentence_length_std']:.1f}")
    print(f"Passive voice: {fingerprint['passive_voice_ratio']:.1%}")
    print(f"Personal pronouns: {fingerprint['personal_pronouns']}")
    print(f"Transitions: {fingerprint['preferred_transitions']}")
    print()
    
    # Generuj instrukcje
    instructions = generate_style_prompt(fingerprint)
    print("=== STYLE INSTRUCTIONS FOR GPT ===")
    print(instructions)
