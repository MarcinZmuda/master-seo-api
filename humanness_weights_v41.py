"""
===============================================================================
âš–ï¸ HUMANNESS WEIGHTS v41.1 - Nowe wagi + Dynamiczne progi CV
===============================================================================

Aktualizacja wag w calculate_humanness_score() na podstawie:
1. Dodania nowej metryki: paragraph_cv
2. BadaÅ„ MDPI 2024 (Random Forest 98.3% dokÅ‚adnoÅ›ci)
3. Praktycznych obserwacji w BRAJEN v40.2

ZMIANY WZGLÄ˜DEM v36.5:
- DODANO: paragraph_cv (0.12) - #2 cecha wykrywania AI
- ZMNIEJSZONO: burstiness (0.18 â†’ 0.16) - wciÄ…Å¼ waÅ¼ne ale mniej dominujÄ…ce
- ZMNIEJSZONO: vocabulary (0.18 â†’ 0.14) - MATTR jest bardziej stabilny
- ZMNIEJSZONO: entropy (0.15 â†’ 0.12)
- ZMNIEJSZONO: repetition (0.12 â†’ 0.10)
- ZMNIEJSZONO: sophistication (0.10 â†’ 0.08)
- ZMNIEJSZONO: pos_diversity (0.07 â†’ 0.05)
- ZWIÄ˜KSZONO: template_diversity (0.15 â†’ 0.16) - waÅ¼ne dla wzorcÃ³w AI

SUMA WAG: 1.00 (bez zmian)

ğŸ†• v41.1 ZMIANY:
- DODANO: Dynamiczne progi CV w zaleÅ¼noÅ›ci od dÅ‚ugoÅ›ci tekstu
- DODANO: get_dynamic_cv_thresholds(word_count) - zwraca progi dla danej dÅ‚ugoÅ›ci
- DODANO: evaluate_cv_dynamic(cv_value, word_count) - ocena CV z dynamicznymi progami
- DODANO: DYNAMIC_CV_THRESHOLDS - lista progÃ³w per zakres sÅ‚Ã³w

UZASADNIENIE DYNAMICZNYCH PROGÃ“W:
- DÅ‚uÅ¼sze teksty AI majÄ… tendencjÄ™ do "wygÅ‚adzania" wariancji
- SHORT (<200 sÅ‚Ã³w): CV >= 0.35 (krÃ³tkie batche majÄ… naturalnie mniejszÄ… wariancjÄ™)
- MEDIUM (200-400 sÅ‚Ã³w): CV >= 0.40 (standardowy batch)
- LONG (400-600 sÅ‚Ã³w): CV >= 0.43 (wiÄ™ksze wymagania)
- EXTENDED (>600 sÅ‚Ã³w): CV >= 0.45 (najwyÅ¼sze wymagania - AI siÄ™ "wygÅ‚adza")

===============================================================================
"""

from typing import Dict, Any  # âœ… POPRAWIONE - dodano Any
from dataclasses import dataclass


# ============================================================================
# OBECNE WAGI (v36.5) - DLA PORÃ“WNANIA
# ============================================================================

WEIGHTS_V36_5 = {
    "burstiness": 0.18,
    "vocabulary": 0.18,
    "sophistication": 0.10,
    "entropy": 0.15,
    "repetition": 0.12,
    "pos_diversity": 0.07,
    "sentence_distribution": 0.05,
    "template_diversity": 0.15
}
# SUMA: 1.00


# ============================================================================
# NOWE WAGI v41.0
# ============================================================================

WEIGHTS_V41 = {
    # ===============================================
    # NAJWAÅ»NIEJSZE METRYKI (Å‚Ä…cznie 0.44)
    # ===============================================
    
    # Burstiness (CV zdaÅ„) - nadal waÅ¼ne, ale mniej dominujÄ…ce
    # Badania: #1 cecha rozrÃ³Å¼niajÄ…ca AI od ludzi
    "burstiness": 0.16,  # byÅ‚o 0.18
    
    # ğŸ†• Paragraph CV - NOWA METRYKA
    # Badania MDPI 2024: #2 cecha po CV zdaÅ„
    # CV dÅ‚ugoÅ›ci akapitÃ³w - AI produkuje jednolite akapity
    "paragraph_cv": 0.12,  # NOWE
    
    # Template Diversity - wzorce AI
    # Wykrywa powtarzalne struktury zdaÅ„
    "template_diversity": 0.16,  # byÅ‚o 0.15
    
    # ===============================================
    # WAÅ»NE METRYKI (Å‚Ä…cznie 0.36)
    # ===============================================
    
    # Vocabulary Richness (MATTR zamiast TTR)
    # MATTR jest bardziej stabilny dla rÃ³Å¼nych dÅ‚ugoÅ›ci
    "vocabulary": 0.14,  # byÅ‚o 0.18
    
    # Starter Entropy - rÃ³Å¼norodnoÅ›Ä‡ poczÄ…tkÃ³w zdaÅ„
    # AI czÄ™sto zaczyna zdania podobnie
    "entropy": 0.12,  # byÅ‚o 0.15
    
    # Word Repetition - nadmierne powtÃ³rzenia
    "repetition": 0.10,  # byÅ‚o 0.12
    
    # ===============================================
    # DRUGORZÄ˜DNE METRYKI (Å‚Ä…cznie 0.20)
    # ===============================================
    
    # Lexical Sophistication (Zipf frequency)
    # Mniej wiarygodne dla polskiego
    "sophistication": 0.08,  # byÅ‚o 0.10
    
    # POS Diversity - rÃ³Å¼norodnoÅ›Ä‡ czÄ™Å›ci mowy
    # Wymaga spaCy, nie zawsze dostÄ™pne
    "pos_diversity": 0.05,  # byÅ‚o 0.07
    
    # Sentence Distribution - rozkÅ‚ad dÅ‚ugoÅ›ci
    # CzÄ™Å›ciowo pokrywa siÄ™ z burstiness
    "sentence_distribution": 0.07,  # byÅ‚o 0.05
}

# Weryfikacja sumy
assert abs(sum(WEIGHTS_V41.values()) - 1.0) < 0.001, "Wagi muszÄ… sumowaÄ‡ siÄ™ do 1.0!"


# ============================================================================
# PROGI DLA NOWYCH METRYK
# ============================================================================

@dataclass
class ThresholdsV41:
    """Progi dla metryk v41 (statyczne - legacy)."""
    
    # Paragraph CV (NOWE)
    PARAGRAPH_CV_CRITICAL_LOW: float = 0.25
    PARAGRAPH_CV_WARNING_LOW: float = 0.35
    PARAGRAPH_CV_OK_MIN: float = 0.35
    PARAGRAPH_CV_OK_MAX: float = 0.70
    
    # MATTR (zastÄ™puje proste TTR)
    MATTR_CRITICAL: float = 0.35
    MATTR_WARNING: float = 0.42
    MATTR_OK: float = 0.42
    
    # PozostaÅ‚e bez zmian (z AIDetectionConfig)


THRESHOLDS_V41 = ThresholdsV41()


# ============================================================================
# ğŸ†• v41.1: DYNAMICZNE PROGI CV (w zaleÅ¼noÅ›ci od dÅ‚ugoÅ›ci tekstu)
# ============================================================================
# Uzasadnienie: DÅ‚uÅ¼sze teksty AI majÄ… tendencjÄ™ do "wygÅ‚adzania" wariancji.
# Im dÅ‚uÅ¼szy tekst, tym wyÅ¼sze wymagania dla naturalnoÅ›ci (CV).
#
# Badania empiryczne (BRAJEN v40.2):
# - SHORT (<200 sÅ‚Ã³w): CV 0.35 wystarcza (krÃ³tkie batche majÄ… naturalnie mniejszÄ… wariancjÄ™)
# - MEDIUM (200-400 sÅ‚Ã³w): CV 0.40 wymagane (standardowy batch)
# - EXTENDED (>400 sÅ‚Ã³w): CV 0.45 wymagane (dÅ‚ugie teksty AI "wygÅ‚adzajÄ… siÄ™")
# ============================================================================

@dataclass
class DynamicCVThresholds:
    """Dynamiczne progi CV dla danego zakresu sÅ‚Ã³w."""
    word_count_min: int
    word_count_max: int
    cv_critical: float      # PoniÅ¼ej = REWRITE
    cv_warning: float       # PoniÅ¼ej = WARNING
    cv_ok_min: float        # PowyÅ¼ej = OK
    cv_excellent: float     # PowyÅ¼ej = EXCELLENT
    label: str


# Definicja progÃ³w per zakres dÅ‚ugoÅ›ci
DYNAMIC_CV_THRESHOLDS = [
    DynamicCVThresholds(
        word_count_min=0,
        word_count_max=199,
        cv_critical=0.25,
        cv_warning=0.30,
        cv_ok_min=0.35,
        cv_excellent=0.50,
        label="SHORT"
    ),
    DynamicCVThresholds(
        word_count_min=200,
        word_count_max=399,
        cv_critical=0.26,
        cv_warning=0.33,
        cv_ok_min=0.40,
        cv_excellent=0.55,
        label="MEDIUM"
    ),
    DynamicCVThresholds(
        word_count_min=400,
        word_count_max=599,
        cv_critical=0.28,
        cv_warning=0.36,
        cv_ok_min=0.43,
        cv_excellent=0.58,
        label="LONG"
    ),
    DynamicCVThresholds(
        word_count_min=600,
        word_count_max=99999,
        cv_critical=0.30,
        cv_warning=0.38,
        cv_ok_min=0.45,
        cv_excellent=0.60,
        label="EXTENDED"
    ),
]


def get_dynamic_cv_thresholds(word_count: int) -> Dict[str, Any]:
    """
    Zwraca dynamiczne progi CV w zaleÅ¼noÅ›ci od dÅ‚ugoÅ›ci tekstu.
    
    Args:
        word_count: Liczba sÅ‚Ã³w w tekÅ›cie/batchu
        
    Returns:
        Dict z progami i etykietÄ… zakresu:
        {
            "critical": float,    # PoniÅ¼ej = REWRITE required
            "warning": float,     # PoniÅ¼ej = WARNING
            "ok_min": float,      # PowyÅ¼ej = PASS
            "excellent": float,   # PowyÅ¼ej = EXCELLENT
            "label": str,         # "SHORT" | "MEDIUM" | "LONG" | "EXTENDED"
            "word_count": int,
            "rationale": str
        }
    
    Example:
        >>> get_dynamic_cv_thresholds(150)
        {"critical": 0.25, "warning": 0.30, "ok_min": 0.35, "label": "SHORT", ...}
        
        >>> get_dynamic_cv_thresholds(450)
        {"critical": 0.28, "warning": 0.36, "ok_min": 0.43, "label": "LONG", ...}
    """
    for threshold in DYNAMIC_CV_THRESHOLDS:
        if threshold.word_count_min <= word_count <= threshold.word_count_max:
            return {
                "critical": threshold.cv_critical,
                "warning": threshold.cv_warning,
                "ok_min": threshold.cv_ok_min,
                "excellent": threshold.cv_excellent,
                "label": threshold.label,
                "word_count": word_count,
                "rationale": f"Batch {threshold.label} ({word_count} sÅ‚Ã³w): "
                            f"CV >= {threshold.cv_ok_min} required for PASS"
            }
    
    # Fallback (nie powinno wystÄ…piÄ‡)
    return {
        "critical": 0.26,
        "warning": 0.33,
        "ok_min": 0.40,
        "excellent": 0.55,
        "label": "MEDIUM",
        "word_count": word_count,
        "rationale": "Fallback to MEDIUM thresholds"
    }


def evaluate_cv_dynamic(cv_value: float, word_count: int) -> Dict[str, Any]:
    """
    Ocenia wartoÅ›Ä‡ CV wzglÄ™dem dynamicznych progÃ³w.
    
    Args:
        cv_value: Obliczona wartoÅ›Ä‡ CV (Coefficient of Variation)
        word_count: Liczba sÅ‚Ã³w w tekÅ›cie
        
    Returns:
        Dict z ocenÄ…:
        {
            "status": "CRITICAL" | "WARNING" | "OK" | "EXCELLENT",
            "passed": bool,
            "cv_value": float,
            "threshold_used": float,
            "margin": float,        # RÃ³Å¼nica od progu ok_min
            "action": str,          # "REWRITE" | "IMPROVE" | "CONTINUE"
            "details": str
        }
    """
    thresholds = get_dynamic_cv_thresholds(word_count)
    
    if cv_value < thresholds["critical"]:
        status = "CRITICAL"
        passed = False
        action = "REWRITE"
        details = (f"CV {cv_value:.3f} < {thresholds['critical']} (CRITICAL dla {thresholds['label']}). "
                   f"Tekst zbyt monotonny - wymaga przepisania z wiÄ™kszÄ… wariancjÄ… zdaÅ„.")
    elif cv_value < thresholds["warning"]:
        status = "WARNING"
        passed = False
        action = "IMPROVE"
        details = (f"CV {cv_value:.3f} < {thresholds['warning']} (WARNING dla {thresholds['label']}). "
                   f"Dodaj krÃ³tkie zdania (3-8 sÅ‚Ã³w) i zrÃ³Å¼nicuj dÅ‚ugoÅ›ci.")
    elif cv_value < thresholds["ok_min"]:
        status = "OK_LOW"
        passed = True
        action = "CONTINUE"
        details = (f"CV {cv_value:.3f} - minimalnie akceptowalne dla {thresholds['label']}. "
                   f"RozwaÅ¼ poprawÄ™ wariancji.")
    elif cv_value >= thresholds["excellent"]:
        status = "EXCELLENT"
        passed = True
        action = "CONTINUE"
        details = f"CV {cv_value:.3f} - doskonaÅ‚a wariancja dla {thresholds['label']}."
    else:
        status = "OK"
        passed = True
        action = "CONTINUE"
        details = f"CV {cv_value:.3f} - dobra wariancja dla {thresholds['label']}."
    
    return {
        "status": status,
        "passed": passed,
        "cv_value": round(cv_value, 4),
        "threshold_used": thresholds["ok_min"],
        "margin": round(cv_value - thresholds["ok_min"], 4),
        "action": action,
        "details": details,
        "thresholds": thresholds
    }


# ============================================================================
# FUNKCJA AKTUALIZACJI
# ============================================================================

def get_weights_v41() -> Dict[str, float]:
    """Zwraca nowe wagi v41."""
    return WEIGHTS_V41.copy()


def get_weight_changes() -> Dict[str, Dict]:
    """Zwraca porÃ³wnanie zmian wag."""
    changes = {}
    
    all_keys = set(WEIGHTS_V36_5.keys()) | set(WEIGHTS_V41.keys())
    
    for key in all_keys:
        old = WEIGHTS_V36_5.get(key, 0)
        new = WEIGHTS_V41.get(key, 0)
        diff = new - old
        
        if diff != 0 or key not in WEIGHTS_V36_5:
            changes[key] = {
                "old": old,
                "new": new,
                "diff": round(diff, 3),
                "change": "NEW" if old == 0 else ("â†‘" if diff > 0 else "â†“")
            }
    
    return changes


# ============================================================================
# INSTRUKCJA INTEGRACJI
# ============================================================================

"""
INTEGRACJA Z ai_detection_metrics.py:

1. ZamieÅ„ definicjÄ™ WEIGHTS w AIDetectionConfig:

   from humanness_weights_v41 import WEIGHTS_V41
   
   class AIDetectionConfig:
       # ...
       WEIGHTS = WEIGHTS_V41

2. Dodaj import paragraph_cv w calculate_humanness_score():

   from paragraph_cv_analyzer_v41 import calculate_paragraph_cv
   
   # W funkcji calculate_humanness_score():
   paragraph_cv = calculate_paragraph_cv(text)
   scores["paragraph_cv"] = paragraph_cv["score"] / 100  # normalize 0-1

3. Dodaj import MATTR:

   from mattr_calculator_v41 import calculate_mattr
   
   # ZamieÅ„ calculate_vocabulary_richness() na MATTR dla dÅ‚ugich tekstÃ³w:
   if len(text.split()) >= 500:
       vocab_result = calculate_mattr(text)
   else:
       vocab_result = calculate_vocabulary_richness(text)  # fallback

4. Aktualizuj funkcjÄ™ Å‚Ä…czÄ…cÄ… scores:

   # W calculate_humanness_score(), po obliczeniu wszystkich metryk:
   weighted_sum = 0
   for metric, weight in WEIGHTS_V41.items():
       if metric in scores:
           weighted_sum += scores[metric] * weight
   
   humanness_score = weighted_sum * 100

5. WAÅ»NE: Upewnij siÄ™ Å¼e wszystkie metryki zwracajÄ… wartoÅ›Ä‡ 0-1 (normalized).
"""


# ============================================================================
# WALIDACJA KONFIGURACJI
# ============================================================================

def validate_weights_config() -> Dict[str, Any]:
    """
    Waliduje konfiguracjÄ™ wag.
    
    Returns:
        Dict z wynikami walidacji
    """
    issues = []
    warnings = []
    
    # SprawdÅº sumÄ™
    total = sum(WEIGHTS_V41.values())
    if abs(total - 1.0) > 0.001:
        issues.append(f"Suma wag = {total}, powinno byÄ‡ 1.0")
    
    # SprawdÅº czy sÄ… wszystkie wymagane metryki
    required = ["burstiness", "vocabulary", "entropy", "repetition"]
    for metric in required:
        if metric not in WEIGHTS_V41:
            issues.append(f"Brak wymaganej metryki: {metric}")
    
    # SprawdÅº czy paragraph_cv ma rozsÄ…dnÄ… wagÄ™
    if WEIGHTS_V41.get("paragraph_cv", 0) < 0.05:
        warnings.append("paragraph_cv ma niskÄ… wagÄ™ - rozwaÅ¼ zwiÄ™kszenie")
    
    # SprawdÅº czy Å¼adna waga nie dominuje
    max_weight = max(WEIGHTS_V41.values())
    if max_weight > 0.25:
        warnings.append(f"Jedna metryka ma wagÄ™ > 0.25 ({max_weight}) - moÅ¼e dominowaÄ‡")
    
    return {
        "valid": len(issues) == 0,
        "issues": issues,
        "warnings": warnings,
        "total_weight": round(total, 4),
        "metrics_count": len(WEIGHTS_V41)
    }


# ============================================================================
# TEST
# ============================================================================

if __name__ == "__main__":
    print("âš–ï¸ HUMANNESS WEIGHTS v41.1 (+ Dynamic CV Thresholds)")
    print("=" * 60)
    
    print("\nğŸ“Š Nowe wagi:")
    for metric, weight in sorted(WEIGHTS_V41.items(), key=lambda x: -x[1]):
        print(f"   {metric}: {weight:.2f}")
    
    print(f"\n   SUMA: {sum(WEIGHTS_V41.values()):.2f}")
    
    print("\nğŸ”„ Zmiany wzglÄ™dem v36.5:")
    changes = get_weight_changes()
    for metric, change in sorted(changes.items(), key=lambda x: -abs(x[1]["diff"])):
        if change["change"] == "NEW":
            print(f"   {metric}: {change['change']} ({change['new']:.2f})")
        else:
            print(f"   {metric}: {change['old']:.2f} â†’ {change['new']:.2f} ({change['change']})")
    
    print("\nâœ… Walidacja wag:")
    validation = validate_weights_config()
    print(f"   Valid: {validation['valid']}")
    if validation['issues']:
        print(f"   Issues: {validation['issues']}")
    if validation['warnings']:
        print(f"   Warnings: {validation['warnings']}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ğŸ†• TEST DYNAMICZNYCH PROGÃ“W CV
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\n" + "=" * 60)
    print("ğŸ†• DYNAMICZNE PROGI CV (v41.1)")
    print("=" * 60)
    
    print("\nğŸ“ Progi per zakres dÅ‚ugoÅ›ci:")
    print(f"   {'Zakres':<12} {'Label':<10} {'Critical':<10} {'Warning':<10} {'OK min':<10} {'Excellent':<10}")
    print("   " + "-" * 62)
    for t in DYNAMIC_CV_THRESHOLDS:
        range_str = f"{t.word_count_min}-{t.word_count_max}"
        print(f"   {range_str:<12} {t.label:<10} {t.cv_critical:<10.2f} {t.cv_warning:<10.2f} {t.cv_ok_min:<10.2f} {t.cv_excellent:<10.2f}")
    
    print("\nğŸ§ª Test evaluate_cv_dynamic():")
    test_cases = [
        (0.22, 150),   # SHORT, CRITICAL
        (0.32, 150),   # SHORT, OK
        (0.35, 300),   # MEDIUM, WARNING
        (0.42, 300),   # MEDIUM, OK
        (0.38, 500),   # LONG, WARNING
        (0.48, 500),   # LONG, OK
        (0.40, 700),   # EXTENDED, WARNING
        (0.52, 700),   # EXTENDED, OK
    ]
    
    for cv, words in test_cases:
        result = evaluate_cv_dynamic(cv, words)
        icon = "âœ…" if result["passed"] else "âŒ"
        print(f"   {icon} CV={cv:.2f}, {words}w â†’ {result['status']:<10} ({result['thresholds']['label']}) | {result['action']}")
